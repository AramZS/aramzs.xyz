---
author: Tuan Pham
cover_image: >-
  https://cdn.sanity.io/images/3tzzh18d/production/91235808ce2de3f9c1ae93542dfc412cd5d742c8-1200x675.png
date: '2026-01-10T17:25:21.438Z'
dateFolder: 2026/01/10
description: >-
  A new report examines how to use computational tools to evaluate policy, with
  AI policy as a case study.
isBasedOn: >-
  https://www.techpolicy.press/making-sense-of-ai-policy-using-computational-tools/
link: >-
  https://www.techpolicy.press/making-sense-of-ai-policy-using-computational-tools/
slug: >-
  2026-01-10-httpswwwtechpolicypressmaking-sense-of-ai-policy-using-computational-tools
tags:
  - ai
  - policy
title: Making Sense of AI Policy Using Computational Tools
---
<p>Perspective</p>
<figure><img alt=" " data-nimg="1" src="https://cdn.sanity.io/images/3tzzh18d/production/91235808ce2de3f9c1ae93542dfc412cd5d742c8-1200x675.png"/><figcaption>"Analog Lecture on Computing" (<a href="https://betterimagesofai.org/images?artist=HannaBarakat&amp;title=AnalogLectureonComputing">Hanna Barakat &amp; Cambridge Diversity Fund / Better Images of AI</a>)</figcaption></figure>
<p>In recent years, policymakers have rapidly increased their efforts to regulate artificial intelligence and automated decision systems through new legislation. These legislative approaches, however, are not advancing in isolation and often borrow and refine language from one another, creating interactions between proposals that otherwise appear to be moving in parallel.</p>
<p>To better understand this complex legislative landscape, the <a href="https://cntr.brown.edu/">Center for Tech Responsibility</a> at Brown University and the <a href="https://www.aclu.org/">American Civil Liberties Union</a> deployed carefully selected computational methods to analyze legislative trends across 1,804 state and federal bills related to AI and automated decision systems introduced between 2023 and April 2025.</p>
<p>The bills in this sample — which we selected based on the presence of various curated keywords related to AI — have varying degrees of substantive requirements and applicability; for example, roughly 30% relate to establishing task forces, and many bills focus only on uses of AI in particular sectors, such as health care.</p>
<p>The culmination of this effort, a <a href="https://www.aclu.org/publications/using-ai-to-make-sense-of-ai-policy">new report released today</a>, demonstrates not only how computational methods can be used to analyze trends across multiple bills, but also how to investigate a given bill in-depth. It also offers recommendations on how to improve computational policy analysis.</p>
<p>Throughout the report, we carefully chose the tool — computational or otherwise — to match the job at hand, rather than more haphazardly applying AI-based approaches without careful oversight, illustrating how organizations and researchers can thoughtfully harness computational tools for policy analysis.</p>
<p>Here is a summary of our findings:</p>
<h2>Analyzing AI policy across bills</h2>
<p>Our research showed how computational tools can help policy staff quickly track trends over time and across states, as well as visualize similarities across bills to trace the overall reach of potential model legislation.</p>
<p>Using a technique called <a href="https://en.wikipedia.org/wiki/Topic_model">topic modeling</a>, we identified common themes in AI-related legislation nationwide. We found almost 500 state bills focused on generative AI, with at least one bill from every state and more than 50 from New York alone, reflecting widespread state-level interest in regulating this technology. These bills often target <a href="https://www.legislature.ohio.gov/legislation/135/hb410">deepfakes in elections</a> or the <a href="https://www.cga.ct.gov/asp/CGABillStatus/cgabillstatus.asp?selBillType=Bill&amp;bill_num=SB01440">dissemination of explicit synthetic imagery</a>, sometimes through <a href="https://www.nysenate.gov/legislation/bills/2025/A6540/amendment/A">requirements</a> like watermarking or disclosure of the origin of AI-generated content.</p>
<figure><img alt=" " data-nimg="1" src="https://cdn.sanity.io/images/3tzzh18d/production/66b9e1e02a9318b0275d08056408ebd38349b04f-681x185.png"/><figcaption>(Center for Tech Responsibility at Brown University and the American Civil Liberties Union)</figcaption></figure>
<p>We also observed a strong focus on establishing task forces to assess the impacts of AI, with over 400 state bills — many from <a href="https://malegislature.gov/Bills/193/H4406">Massachusetts</a> and <a href="https://www.nysenate.gov/legislation/bills/2025/S2487">New York</a> — and more than 100 congressional bills, demonstrating significant federal interest in creating AI-related task forces.</p>
<p>Computational analysis also illuminated how policy diffusion has taken shape in the AI policy sphere. Legislative bills often copy language from other bills or from model bills — template legislation drafted by advocacy, policy or industry organizations — with small but sometimes significant tweaks. For example, scholars have noted how the “<a href="https://iapp.org/news/a/new-laws-in-california-look-to-the-future-of-privacy-and-ai">California effect</a>,” where laws in California ripple to other states, will likely play out in the context of privacy and AI.</p>
<p>To better understand such policy diffusion, we compared legislative texts to see how bills may share language with model bills. For instance, the <a href="https://www.lawyerscommittee.org/online-civil-rights-act/">Lawyers’ Committee Model Bill</a> <a href="https://www.markey.senate.gov/news/press-releases/senator-markey-introduces-ai-civil-rights-act-to-eliminate-ai-bias-enact-guardrails-on-use-of-algorithms-in-decisions-impacting-peoples-rights-civil-liberties-livelihoods">explicitly</a> served as the foundation for the <a href="https://www.congress.gov/bill/118th-congress/senate-bill/5152">AI Civil Rights Act of 2024</a>, but we found that it also shares substantial language with 11 other bills in <a href="https://www.congress.gov/bill/118th-congress/senate-bill/3975/text">Congress</a> and states like <a href="https://www.ilga.gov/Legislation/BillStatus?DocNum=3041&amp;GAID=18&amp;DocTypeID=HB&amp;SessionID=114&amp;GA=104">Illinois</a>, <a href="https://malegislature.gov/Bills/194/S301">Massachusetts</a>, <a href="https://www.nysenate.gov/legislation/bills/2025/A5827">New York</a> and <a href="https://app.leg.wa.gov/billsummary?BillNumber=1671&amp;Year=2025&amp;Initiative=false">Washington</a>.</p>
<p>We also examined another model bill that was reportedly developed and promoted by the large human resources company Workday, obtained by <a href="https://therecord.media/human-resources-artificial-intelligence-state-legislation-workday">Recorded Future News</a>. In addition to the six state bills identified by the publication, we identified <a href="https://www.oklegislature.gov/BillInfo.aspx?Bill=HB3835&amp;session=2400">another bill from Oklahoma</a> that mirrors this model bill from the large sample of legislation.</p>
<h2>Analyzing AI policy within a given bill</h2>
<p>Our report also explores applying computational methods to explore a single bill.</p>
<p>Bills often define key terms that are used throughout their texts and that significantly shape the bills’ scope and impact. In AI-related legislation, these definitions — of AI, AI's scope of use and the entities held accountable — have often been a <a href="https://www.brookings.edu/articles/misrepresentations-of-californias-ai-safety-bill/">subject of contention</a>, as they establish the scope of the bill and boundaries for AI governance.</p>
<p>However, a single bill may include dozens of definitions that reference each other, and computational methods may make understanding those interlocking definitions easier.</p>
<p>We examined definitions from several bills, including the <a href="https://www.congress.gov/bill/118th-congress/house-bill/8818/text#toc-H3123193BF6744CFD9DEF06BE803EBBBC">American Privacy Rights Act of 2024</a> and the AI Civil Rights Act of 2024. To better understand the relationships between definitions, we visualized them as a graph, as shown in the figure below with a sample of the definitions from the AI Civil Rights Act of 2024.</p>
<figure><img alt=" " data-nimg="1" src="https://cdn.sanity.io/images/3tzzh18d/production/f501fa24331a8a05fd5e7c26fc3cf7a0554e4721-1200x675.png"/><figcaption>(Center for Tech Responsibility at Brown University and the American Civil Liberties Union)</figcaption></figure>
<p>Using methods from <a href="https://en.wikipedia.org/wiki/Graph_theory">graph theory</a>, we then investigated cyclical references in definitions — for instance, where term A references term B, term B references term C and so on — as such cycles can contribute to ambiguity and unintended loopholes in a bill’s application.</p>
<p>For example, the <a href="https://www.ftc.gov/legal-library/browse/statutes/fair-credit-reporting-act">Fair Credit Reporting Act</a> — a law that provides important protections related to credit reports — contains a cycle between two terms, “consumer report” and “consumer reporting agency.” These terms have been a source of <a href="https://epic.org/fcra/">significant debate</a> in part due to ambiguities created by the cyclical reference.</p>
<p>This example illustrates how cycles can contribute to ambiguity and unintended loopholes where regulated behavior or entities are excluded from certain requirements. Identifying and potentially addressing such cycles in definitions can help policymakers improve a bill’s clarity and prevent loopholes before it becomes law.</p>
<p>Finally, we applied graph theory methods to identify key terms in a given bill. From the 60 defined terms in the American Privacy Rights Act, we found that the term “sensitive covered data” heavily relies on other terms and is likely central to the bill. As an umbrella that ties other terms together, “sensitive covered data” should have a clear and robust definition.</p>
<p>This type of analysis can help identify the terms most important to a bill, enabling policy staff to focus their attention and resources on strengthening these key definitions.</p>
<h2>Recommendations</h2>
<p>Our research unearthed two key recommendations to address the challenges that emerge when conducting computational AI policy analysis.</p>
<p>First, we urge researchers and policy staff to work together to create standardized formats and structures for legislative texts across jurisdictions. Establishing consistent file formats, structures of definitions and sections, annotation conventions and references would facilitate computational analysis of legislative data and make it easier for policy staff to track changes over time. The <a href="https://uscode.house.gov/download/resources/USLM-User-Guide.pdf">United States Legislative Markup</a> data format and the <a href="https://congressionaldata.org/about-the-coalition/">Congressional Data Coalition</a> group could serve as good starting points for cross-jurisdiction standardization efforts, for example.</p>
<p>Second, we encourage researchers and advocates to incorporate a multilingual perspective when analyzing AI legislation introduced in regions that, <a href="https://www.aclu.org/issues/racial-justice/anti-colonialism">due to the history and ongoing reality of United States imperialism</a>, are under US jurisdiction.</p>
<p>English-only analyses can overlook important policy developments, such <a href="https://sutra.oslpr.org/medidas/153856">bills</a> in <a href="https://sutra.oslpr.org/medidas/152457">Puerto</a> <a href="https://sutra.oslpr.org/medidas/155166">Rico</a> that are written in Spanish and bills in Hawai’i that are sometimes written in Hawaiian. Computational methods, such as topic modeling, should be tailored to specific languages and incorporate social, cultural and legal context through engagement with native speakers and regional AI policy experts. Leveraging such context-specific language technologies would help provide insights into the diverse approaches to AI policy.</p>
<p>While our focus here is AI legislation, our research and recommendations can be applied to other policy areas seeing a surge in bills across jurisdictions, thus helping to understand and strengthen emerging legislation.</p>
