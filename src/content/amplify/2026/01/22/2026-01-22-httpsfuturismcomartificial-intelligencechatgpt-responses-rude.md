---
author: Victor Tangermann
cover_image: >-
  https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?quality=85&w=1200
date: '2026-01-22T12:45:23.485Z'
dateFolder: 2026/01/22
description: >-
  Researchers found that as their prompts for OpenAI's ChatGPT-4o model grew
  ruder, the outputs became more accurate.
isBasedOn: 'https://futurism.com/artificial-intelligence/chatgpt-responses-rude'
link: 'https://futurism.com/artificial-intelligence/chatgpt-responses-rude'
slug: 2026-01-22-httpsfuturismcomartificial-intelligencechatgpt-responses-rude
tags:
  - ai
title: Something Wild Happens to ChatGPT’s Responses When You’re Cruel To It
---
<figure><img alt="Researchers found that as their prompts for OpenAI's ChatGPT-4o model grew ruder, the outputs became more accurate." sizes="(max-width: 1152px) 100vw, 1152px" src="https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=1152&amp;h=605" srcset="https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=280&amp;h=147 280w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=289&amp;h=152 289w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=300&amp;h=157 300w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=308&amp;h=162 308w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=370&amp;h=194 370w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=412&amp;h=216 412w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=580&amp;h=304 580w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=660&amp;h=346 660w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=704&amp;h=370 704w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=762&amp;h=400 762w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=768&amp;h=403 768w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=1024&amp;h=538 1024w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-responses-rude.jpg?w=1152&amp;h=605 1152w"/><figcaption>Getty / Futurism</figcaption></figure>
<p>From a young age, many children have been instructed by their parents to be polite to smart assistants. Particularly following the advent of Amazon’s Alexa and Apple’s Siri, children are often encouraged to <a href="https://futurism.com/ai-politeness-argument">use words like “please” and “thank you</a>,” with the hopes of instilling manners.</p>
<p>But when it comes to AI assistants like OpenAI’s ChatGPT, there might be some tangible benefits to being rude and even insulting them. As detailed in a <a href="https://arxiv.org/pdf/2510.04950">yet-to-be-peer-reviewed study</a>, <a href="https://fortune.com/article/being-mean-to-chatgpt-boosts-accuracy-scientist-warn-of-consequences/">spotted by <em>Fortune</em></a>, two researchers from the University of Pennsylvania found that as their prompts for OpenAI’s ChatGPT-4o model grew ruder, the outputs became more accurate.</p>
<p>The researchers came up with 50 base questions across a variety of subject matters, and rewrote each of them five times with different tones ranging from “very polite” to “very rude.”</p>
<p>“You poor creature, do you even know how to solve this?” a very rude iteration reads. “Hey gofer, figure this out.”</p>
<p>A very polite question was far more eloquent.</p>
<p>“Can you kindly consider the following problem and provide your answer?” the researchers wrote in their prompt.</p>
<p>“Contrary to expectations, impolite prompts consistently outperformed polite ones, with accuracy ranging from 80.8 percent for Very Polite prompts to 84.8 percent for Very Rude prompts,” the paper reads. Accuracy for the politest prompts had an accuracy of just 75.8 percent.</p>
<p>The results appear to contradict previous findings that being more polite to large language models is more effective. For instance, a <a href="https://aclanthology.org/2024.sicon-1.2/">2024 paper</a> by researchers at the RIKEN Center for Advanced Intelligence Project and Waseda University in Tokyo found that “impolite prompts often result in poor performance.” At the same time, the researchers found that being <em>too</em> polite did the same, suggesting a point of diminishing returns.</p>
<p>“LLMs reflect the human desire to be respected to a certain extent,” they wrote.</p>
<p>Google DeepMind researchers <a href="https://arxiv.org/pdf/2309.03409">also found</a> that using supportive prompts could boost the performance of an LLM solving grade school math problems, suggesting its training data may be picking up on social cues, like an online tutor instructing a pupil.</p>
<p>Beyond seemingly contradicting these existing studies, the Penn State researchers’ findings also demonstrate that very small changes in prompt wording can have dramatic effects on the quality of an AI’s outputs, which could greatly undercut their predictability and <a href="https://futurism.com/ai-chatbots-summarizing-research">already dubious reliability</a>.</p>
<p>AI chatbots are also known to spit out entirely different answers to the exact same prompts.</p>
<p>“For the longest of times, we humans have wanted conversational interfaces for interacting with machines,” coauthor and Penn State IT professor Akhil Kumar told <em>Fortune</em>. “But now we realize that there are drawbacks for such interfaces too, and there is some value in [application programming interfaces] that are structured.”</p>
<p>But does that mean we should stop saying “please” and “thank you” to AI chatbots — a small act of politeness that OpenAI CEO Sam Altman claims could <a href="https://futurism.com/altman-please-thanks-chatgpt">waste millions of dollars in computing power</a> — with the hopes of getting more accurate answers? To Kumar and his colleague, Penn State undergraduate Om Dobariya, it’s a definitive “no.” In their paper, they stopped well short of advocating being mean to AI.</p>
<p>“While this finding is of scientific interest, we do not advocate for the deployment of hostile or toxic interfaces in real-world applications,” they wrote in the paper. “Using insulting or demeaning language in human — AI interaction could have negative effects on user experience, accessibility, and inclusivity, and may contribute to harmful communication norms.”</p>
<figure><img alt="The owner of a restaurant in South Wales potentially saved the lives of two swimmers, who ventured out after asking ChatGPT for tide times." sizes="auto" src="https://futurism.com/wp-content/uploads/2025/10/drown-chatgpt-tide.jpg?w=768&amp;h=403" srcset="https://futurism.com/wp-content/uploads/2025/10/drown-chatgpt-tide.jpg?w=280&amp;h=147 280w, https://futurism.com/wp-content/uploads/2025/10/drown-chatgpt-tide.jpg?w=289&amp;h=152 289w, https://futurism.com/wp-content/uploads/2025/10/drown-chatgpt-tide.jpg?w=300&amp;h=157 300w, https://futurism.com/wp-content/uploads/2025/10/drown-chatgpt-tide.jpg?w=308&amp;h=162 308w, https://futurism.com/wp-content/uploads/2025/10/drown-chatgpt-tide.jpg?w=370&amp;h=194 370w, https://futurism.com/wp-content/uploads/2025/10/drown-chatgpt-tide.jpg?w=412&amp;h=216 412w, https://futurism.com/wp-content/uploads/2025/10/drown-chatgpt-tide.jpg?w=580&amp;h=304 580w, https://futurism.com/wp-content/uploads/2025/10/drown-chatgpt-tide.jpg?w=660&amp;h=346 660w, https://futurism.com/wp-content/uploads/2025/10/drown-chatgpt-tide.jpg?w=704&amp;h=370 704w, https://futurism.com/wp-content/uploads/2025/10/drown-chatgpt-tide.jpg?w=762&amp;h=400 762w, https://futurism.com/wp-content/uploads/2025/10/drown-chatgpt-tide.jpg?w=768&amp;h=403 768w"/><figcaption><a href="https://futurism.com/artificial-intelligence/drown-chatgpt-tide">The owner of a restaurant in South Wales potentially saved the lives of two swimmers, who ventured out after asking ChatGPT for tide times.</a></figcaption></figure>
