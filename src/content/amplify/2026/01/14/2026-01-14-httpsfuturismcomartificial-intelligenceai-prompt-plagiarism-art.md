---
author: Joe Wilkins Published Jan 10
cover_image: >-
  https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?quality=85&w=1200
date: '2026-01-14T13:06:22.240Z'
dateFolder: 2026/01/14
description: >-
  A self-described AI ambassador is in shambles after she says other AI
  prompters have been plagiarizing her instructions.
isBasedOn: 'https://futurism.com/artificial-intelligence/ai-prompt-plagiarism-art'
link: 'https://futurism.com/artificial-intelligence/ai-prompt-plagiarism-art'
slug: 2026-01-14-httpsfuturismcomartificial-intelligenceai-prompt-plagiarism-art
tags:
  - ai
  - lol
title: Furious AI Users Say Their Prompts Are Being Plagiarized
---
<figure><img alt="A self-described AI ambassador is in shambles after she says other AI prompters have been plagiarizing her instructions." sizes="(max-width: 1152px) 100vw, 1152px" src="https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=1152&amp;h=768" srcset="https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=280&amp;h=187 280w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=289&amp;h=193 289w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=300&amp;h=200 300w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=308&amp;h=205 308w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=324&amp;h=216 324w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=370&amp;h=247 370w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=580&amp;h=387 580w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=594&amp;h=396 594w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=600&amp;h=400 600w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=660&amp;h=440 660w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=768&amp;h=512 768w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=1024&amp;h=683 1024w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=1041&amp;h=694 1041w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=1128&amp;h=752 1128w, https://futurism.com/wp-content/uploads/2026/01/ai-prompt-plagiarism-art.jpg?w=1152&amp;h=768 1152w"/><figcaption>Illustration by Tag Hartman-Simkins / Futurism. Source: Getty Images</figcaption></figure>
<p>Move over, <a href="https://open.library.okstate.edu/introphilosophy/chapter/ship-of-theseus/">Ship of Theseus</a> — there’s a new paradoxical thought experiment in town.</p>
<p>Some power users of generative AI have grown so comfortable with their new tools — especially image-generating ones — that they now feel entitled to the specific prompts they use to churn out slop, as if the <em>entire technology</em> wasn’t based on the work of human artists that had been ingested without consent.</p>
<p>Consider Amira Zairi, a self-professed “AI educator” and “ambassador” for Adobe, LeonardoAI, and TripoAI, who <a href="https://x.com/azed_ai/status/2008468458933989559?s=20">posted a scathing rant</a> this week on X-formerly-Twitter to her 49,000 followers. Her complaint? Other people were “plagiarizing” her unique AI prompts.</p>
<p>“‘Make your own prompts’ isn’t advice. It’s basic integrity,” Zairi wrote, using syntax that reads suspiciously like text <a href="https://futurism.com/chatgpt-weird-way-talking-see-it-everywhere">generated by ChatGPT</a>. “I’m honestly fed up. Changing a few words, renaming the prompt, or slightly rephrasing it doesn’t make it yours, the idea is still the same, the vibe is the same, and the results are obviously similar.”</p>
<p>“And no, this isn’t about one or two people, and it didn’t happen once!!!!” Zairi continued. “Creating your own prompts is actually easier than copying someone else’s work! Try it.”</p>
<blockquote data-dnt="true" data-tweet-id="2008468458933989559" data-width="550"><p>“Make your own prompts” isn’t advice. It’s basic integrity.<br/><br/>I’m honestly fed up.<br/>Changing a few words, renaming the prompt, or slightly rephrasing it doesn’t make it yours, the idea is still the same, the vibe is the same, and the results are obviously similar.<br/><br/>And no, this…</p>— Amira Zairi (@azed_ai) <a href="https://twitter.com/azed_ai/status/2008468458933989559?ref_src=twsrc%5Etfw">January 6, 2026</a></blockquote>
<p>While Zairi is only the latest AI hound to bark about stolen prompts, she’s certainly not the first. Examples abound, as the <a href="https://www.dailydot.com/culture/ai-prompt-thieves-stealing/"><em>Daily Dot </em>pointed out</a> back in December: consider a poster <a href="https://www.dailydot.com/culture/ai-prompt-thieves-stealing/">who railed</a> about “prompt thieves in the AI art community,” or the “AI artist” who went on a tangent after someone <a href="https://x.com/Artedeingenio/status/1758256254349189414?s=20">aped his prompt</a> “without knowing it’s mine.”</p>
<p>There’s even a niche market for preventative tools among cybersecurity developers. Late in 2024, an AI researcher named Xinyue Shen <a href="https://cispa.de/en/shen-promptstealing">developed a tool</a> called PromptShield to guard against so-called “prompt stealing.”</p>
<p>It’s all pretty rich, given that these AI tools were all trained on <a href="https://futurism.com/artists-sue-stabile-diffusion-midjourney">troves of human-made art</a> and media without permission. In order to create generative AI models, tech companies systematically scrape vast amounts of <a href="https://juliabausenhardt.com/how-ai-is-stealing-your-art/">copyrighted art</a> from the web without consent, licensure, or compensation for the artists. This data is then used to train generative AI models that synthesize and churn out derivative images, an outcome some ethicists argue amounts to <a href="https://www.researchgate.net/publication/380577953_AI_Art_is_Theft_Labour_Extraction_and_Exploitation_Or_On_the_Dangers_of_Stochastic_Pollocks">labor exploitation</a>.</p>
<p>Put simply, AI bros are mad that people are stealing their recipe for the plagiarism machine — an irony which is pretty hard to ignore.</p>
<p>“What you are describing and complaining about is the fundamental function of the tech you’re advocating for, inextricable from it,” digital artist <a href="https://x.com/BoneJail/status/2008976302494404914?s=20">Rory Blank replied</a> under Amira Zairi’s post. “Hope that helps.”</p>
<figure><img alt="Experts confirmed almost immediately that OpenAI's latest AI browser, dubbed Atlas, is &quot;definitely vulnerable to prompt injection.&quot;" sizes="auto" src="https://futurism.com/wp-content/uploads/2025/10/openai-browser-victim-prompt-injection-attacks.jpg?w=768&amp;h=403" srcset="https://futurism.com/wp-content/uploads/2025/10/openai-browser-victim-prompt-injection-attacks.jpg?w=280&amp;h=147 280w, https://futurism.com/wp-content/uploads/2025/10/openai-browser-victim-prompt-injection-attacks.jpg?w=289&amp;h=152 289w, https://futurism.com/wp-content/uploads/2025/10/openai-browser-victim-prompt-injection-attacks.jpg?w=300&amp;h=157 300w, https://futurism.com/wp-content/uploads/2025/10/openai-browser-victim-prompt-injection-attacks.jpg?w=308&amp;h=162 308w, https://futurism.com/wp-content/uploads/2025/10/openai-browser-victim-prompt-injection-attacks.jpg?w=370&amp;h=194 370w, https://futurism.com/wp-content/uploads/2025/10/openai-browser-victim-prompt-injection-attacks.jpg?w=412&amp;h=216 412w, https://futurism.com/wp-content/uploads/2025/10/openai-browser-victim-prompt-injection-attacks.jpg?w=580&amp;h=304 580w, https://futurism.com/wp-content/uploads/2025/10/openai-browser-victim-prompt-injection-attacks.jpg?w=660&amp;h=346 660w, https://futurism.com/wp-content/uploads/2025/10/openai-browser-victim-prompt-injection-attacks.jpg?w=704&amp;h=370 704w, https://futurism.com/wp-content/uploads/2025/10/openai-browser-victim-prompt-injection-attacks.jpg?w=762&amp;h=400 762w, https://futurism.com/wp-content/uploads/2025/10/openai-browser-victim-prompt-injection-attacks.jpg?w=768&amp;h=403 768w"/><figcaption><a href="https://futurism.com/artificial-intelligence/openai-browser-victim-prompt-injection-attacks">Experts confirmed almost immediately that OpenAI's latest AI browser, dubbed Atlas, is "definitely vulnerable to prompt injection."</a></figcaption></figure>
