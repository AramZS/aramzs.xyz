---
author: Dan Goodin
cover_image: >-
  https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion-1152x648.jpg
date: '2026-01-14T23:34:08.526Z'
dateFolder: 2026/01/14
description: 'Introducing Confer, an end-to-end AI assistant that just works.'
isBasedOn: >-
  https://arstechnica.com/security/2026/01/signal-creator-moxie-marlinspike-wants-to-do-for-ai-what-he-did-for-messaging/
link: >-
  https://arstechnica.com/security/2026/01/signal-creator-moxie-marlinspike-wants-to-do-for-ai-what-he-did-for-messaging/
slug: >-
  2026-01-14-httpsarstechnicacomsecurity202601signal-creator-moxie-marlinspike-wants-to-do-for-ai-what-he-did-for-messaging
tags:
  - ai
  - privacy
title: AI is an “inherent” privacy invader. Signal’s creator has a remedy.
---
<figure></figure><p> <em> LLM E2EE made simple </em></p>
<p>Introducing Confer, an end-to-end AI assistant that just works.</p>
<p><a href="https://arstechnica.com/author/dan-goodin/"> Dan Goodin </a> –  Jan 13, 2026 12:00 PM |</p>
<figure><a data-cropped="true" data-pswp-height="840" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion.jpg 1200w, https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion-640x448.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion-1024x717.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion-768x538.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion-980x686.jpg 980w" data-pswp-width="1200" href="https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion.jpg"><img alt="" sizes="(max-width: 1152px) 100vw, 1152px" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion-1152x648.jpg" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/12/electronic-privacy-invasion-768x432.jpg 768w"/></a></figure>
<p> / Credit: Getty Images</p>
<figure></figure><p>Text settings</p>
<figure></figure><p>Moxie Marlinspike—the pseudonym of an engineer who set a new standard for private messaging with the creation of the Signal Messenger—is now aiming to revolutionize AI chatbots in a similar way.</p>
<p>His latest brainchild is <a href="https://confer.to/">Confer</a>, an open source AI assistant that provides strong assurances that user data is unreadable to the platform operator, hackers, law enforcement, or any other party other than account holders. The service—including its large language models and back-end components—runs entirely on open source software that users can cryptographically verify is in place.</p>
<p>Data and conversations originating from users and the resulting responses from the LLMs are encrypted in a trusted execution environment (TEE) that prevents even server administrators from peeking at or tampering with them. Conversations are stored by Confer in the same encrypted form, which uses a key that remains securely on users’ devices.</p>
<p>Like Signal, the under-the-hood workings of Confer are elegant in their design and simplicity. Signal was the first end-user privacy tool that made using it a snap. Prior to that, using PGP email or other options to establish encrypted channels between two users was a cumbersome process that was easy to botch. Signal broke that mold. Key management was no longer a task users had to worry about. Signal was designed to prevent even the platform operators from peering into messages or identifying users’ real-world identities.</p>
<h2>“Inherent data collectors”</h2>
<p>All major platforms are required to turn over user data to law enforcement or private parties in a lawsuit when either provides a valid subpoena. Even when users opt out of having their data stored long term, parties to a lawsuit can compel the platform to store it, as the world learned last May when a court ordered OpenAI to <a href="https://arstechnica.com/tech-policy/2025/06/openai-says-court-forcing-it-to-save-all-chatgpt-logs-is-a-privacy-nightmare/">preserve all ChatGPT users’ logs</a>—including deleted chats and sensitive chats logged through its API business offering. Sam Altman, CEO of OpenAI, <a href="https://ca.news.yahoo.com/sam-altman-says-chatgpt-therapy-115344758.html">has said</a> such rulings mean even psychotherapy sessions on the platform may not stay private. Another carve out to opting out: AI platforms like Google Gemini may have <a href="https://support.google.com/gemini/answer/13594961?hl=en">humans read chats</a>.</p>
<p>Data privacy expert <a href="https://infosec.exchange/deck/@Em0nM4stodon">Em</a> (she keeps her last name off the Internet) called AI assistants the “archnemesis” of data privacy because their utility relies on assembling massive amounts of data from myriad sources, including individuals.</p>
<p>“AI models are inherent data collectors,” she told Ars. “They rely on large data collection for training, improvements, operations, and customizations. More often than not, this data is collected without clear and informed consent (from unknowing training subjects or from platform users), and is sent to and accessed by a private company with many incentives to share and monetize this data.”</p>
<p>The lack of user-control is especially problematic given the nature of LLM interactions, Marlinspike <a href="https://confer.to/blog/2025/12/confessions-to-a-data-lake/">says</a>. Users often treat dialogue as an intimate conversation. Users share their thoughts, fears, transgressions, business dealings, and deepest, darkest secrets as if AI assistants are trusted confidants or personal journals. The interactions are fundamentally different from traditional web search queries, which usually adhere to a transactional model of keywords in and links out.</p>
<p>He likens AI use to confessing into a “data lake.”</p>
<h2>Awaking from the nightmare that is today’s AI landscape</h2>
<p>In response, Marlinspike has developed and is now trialing <a href="https://confer.to/">Confer</a>. In much the way Signal uses encryption to make messages readable only to parties participating in a conversation, Confer protects user prompts, AI responses, and all data included in them. And just like Signal, there’s no way to tie individual users to their real-world identity through their email address, IP address, or other details.</p>
<p>“The character of the interaction is fundamentally different because it’s a private interaction,” Marlinspike told Ars. “It’s been really interesting and encouraging and amazing to hear stories from people who have used Confer and had life-changing conversations. In part because they haven’t felt free to include information in those conversations with sources like ChatGPT or they had insights using data that they weren’t really free to share with ChatGPT before but can using an environment like Confer.”</p>
<p>One of the main ingredients of Confer encryption is <a href="https://arstechnica.com/information-technology/2023/05/passkeys-may-not-be-for-you-but-they-are-safe-and-easy-heres-why/">passkeys</a>. The industry-wide standard generates a 32-byte encryption keypair that’s unique to each service a user logs into. The public key is sent to the server. The private key is stored only on the user device, inside protected storage hardware that hackers (even those with physical access) can’t access. Passkeys provide two-factor authentication and can be configured to log in to an account with a fingerprint, face scan (both of which also stay securely on a device), or a device unlock PIN or passcode.</p>
<p>The private key allows the device to log in to Confer and encrypt all input and output with encryption that’s widely believed to be impossible to break. That allows users to store conversations on Confer servers with confidence that they can’t be read by anyone other than themselves. The storage allows conversations to sync across other devices the user owns. The code making this all work is available for anyone to inspect. It looks like this:</p>
<pre><code>
  const assertion = await navigator.credentials.get({
    mediation: "optional",
    publicKey: {
      challenge: crypto.getRandomValues(new Uint8Array(32)),
      allowCredentials: [{ id: credId, type: "public-key" }],
      userVerification: "required",
      extensions: { prf: { eval: { first: new Uint8Array(salt) } } }
    }
  }) as PublicKeyCredential;

  const { prf } = assertion.getClientExtensionResults();
  const rawKey  = new Uint8Array(prf.results.first); 
</code></pre>
<figure><a data-cropped="false" data-pswp-height="2796" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface.png 1419w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-640x1261.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-1024x2018.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-768x1513.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-780x1536.png 780w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-1039x2048.png 1039w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-980x1931.png 980w" data-pswp-width="1419" href="https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface.png"><img alt="" sizes="auto, (max-width: 1024px) 100vw, 1024px" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface.png" srcset="https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-1024x2018.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-640x1261.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-768x1513.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-780x1536.png 780w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-1039x2048.png 1039w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-980x1931.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface.png 1419w"/></a><p> </p><p> </p><p> </p><figcaption>/ Credit: Confer</figcaption></figure>
<figure><a data-cropped="false" data-pswp-height="2796" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2.png 1419w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-640x1261.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-1024x2018.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-768x1513.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-780x1536.png 780w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-1039x2048.png 1039w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-980x1931.png 980w" data-pswp-width="1419" href="https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2.png"><img alt="" sizes="auto, (max-width: 1024px) 100vw, 1024px" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2.png" srcset="https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-1024x2018.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-640x1261.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-768x1513.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-780x1536.png 780w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-1039x2048.png 1039w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2-980x1931.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/confer-interface-2.png 1419w"/></a><p> </p><p> </p><p> </p><figcaption>/ Credit: Confer</figcaption></figure>
<p>This robust internal engine is fronted by a user interface (shown in the two images above) that’s deceptively simple. In just two strokes, a user is logged in, and all previous chats are decrypted. These chats are then available to any device logged into the same account. This way, Confer can sync chats without compromising privacy. The ample 32 bytes of key material allow the private key to change regularly, a feature that allows for <a href="https://en.wikipedia.org/wiki/Forward_secrecy">forward secrecy</a>, meaning that in the event a key is compromised, an attacker cannot read previous or future chats.</p>
<p>The other main Confer ingredient is a TEE on the platform servers. TEEs encrypt all data and code flowing through the server CPU, protecting them from being read or modified by someone with administrative access to the machine. The Confer TEE also provides remote attestation. Remote attestation is a digital certificate sent by the server that cryptographically verifies that data and software are running inside the TEE and lists all software running on it.</p>
<p>On Confer, remote attestation allows anyone to reproduce the bit-by-bit outputs that confirm that the publicly available <a href="https://github.com/conferlabs/confer-proxy">proxy</a> and <a href="https://github.com/conferlabs/confer-image">image</a> software—and only that software—is running on the server. To further verify Confer is running as promised, each release is digitally signed and published in a <a href="https://search.sigstore.dev/?email=releases%40conferlabs.iam.gserviceaccount.com">transparency log</a>.</p>
<p>Native support for Confer is available in the most recent versions of macOS, iOS, and Android. On Windows, users must install a third-party authenticator. Linux support also doesn’t exist, although <a href="https://vitorpy.com/blog/2025-12-25-confer-to-linux-tpm-fido2-prf/">this extension</a> bridges that gap.</p>
<h2>There are other private LLMs, but none from the big players</h2>
<p>Another publicly available LLM offering E2EE is <a data-ml="true" data-ml-dynamic="true" data-ml-dynamic-type="sl" data-ml-id="0" data-orig-url="https://proton.me/blog/lumo-security-model" data-skimlinks-tracking="xid:fr1768306063002cch" data-xid="fr1768306063002cch" href="https://proton.me/blog/lumo-security-model">Lumo</a>, provided by Proton, a European company that’s behind the popular encrypted email service. It adopts the same encryption engine used by Proton Mail, Drive, and Calendar. The internals of the engine are considerably more complicated than Confer because they rely on a series of both symmetric and asymmetric keys. The end result for the user is largely the same, however.</p>
<p>Once a user authenticates to their account, Proton says, all conversations, data, and metadata is encrypted with a symmetrical key that only the user has. Users can opt to store the encrypted data on Proton servers for device syncing or have it wiped immediately after the conversation is finished.</p>
<p>A third LLM provider promising privacy is <a href="https://venice.ai/privacy">Venice</a>. It stores all data locally, meaning on the user device. No data is stored on the remote server.</p>
<p>Most of the big LLM platforms offer a means for users to exempt their conversations and data for marketing and training purposes. But as noted earlier, these promises often come with major carve-outs. Besides selected review by humans, personal data may still be used to enforce terms of service or for other internal purposes, even when users have opted out of default storage.</p>
<p>Given today’s legal landscape—which allows most data stored online to be obtained with a subpoena—and the regular occurrence of blockbuster data breaches by hackers, there can be no reasonable expectation that personal data remains private.</p>
<p>It would be great if big providers offered end-to-end encryption protections, but there’s currently no indication they plan to do so. Until then, there are a handful of smaller alternatives that will keep user data out of the ever-growing data lake.</p>
