---
author: amazon.com
cover_image: ''
date: '2026-01-19T03:18:21.637Z'
dateFolder: 2026/01/18
description: >-
  The Amazon Glacier storage classes are purpose-built for data archiving,
  providing you with the highest performance, most retrieval flexibility, and
  the lowest cost archive storage in the cloud. To keep costs low yet suitable
  for varying retrieval needs, these storage classes support flexible retrieval
  options from milliseconds to several hours.
isBasedOn: >-
  https://docs.aws.amazon.com/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/getting-started-using-amazon-s3-glacier-storage-classes.html
link: >-
  https://docs.aws.amazon.com/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/getting-started-using-amazon-s3-glacier-storage-classes.html
slug: >-
  2026-01-18-httpsdocsawsamazoncomhands-onlatestgetting-started-using-amazon-s3-glacier-storage-classesgetting-started-using-amazon-s3-glacier-storage-classeshtml
tags:
  - archiving
title: Getting started using the Amazon Glacier storage classes
---
<ol><li><figure></figure></li><li><figure></figure></li><li><figure></figure></li></ol>
<ol><li><figure></figure></li><li><figure></figure></li></ol>
<p><a data-analytics-funnel-value="button:r18:" data-analytics-performance-mark="10-1768781974839-8774" href="https://docs.aws.amazon.com/pdfs/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/getting-started-using-amazon-s3-glacier-storage-classes.pdf#getting-started-using-amazon-s3-glacier-storage-classes"><figure></figure></a></p>
<p>Getting started using the Amazon Glacier storage classes - Getting started using the Amazon Glacier storage classes</p>
<h2>Overview<figure></figure></h2>
<p>The <a href="https://aws.amazon.com/s3/storage-classes/glacier/">Amazon Glacier storage classes<figure></figure></a> are purpose-built for data archiving, providing you with the highest performance, most retrieval flexibility, and the lowest cost archive storage in the cloud. To keep costs low yet suitable for varying retrieval needs, these storage classes support flexible retrieval options from milliseconds to several hours. The purpose of this tutorial is to show you how easy it is to begin storing your archive datasets in the Amazon Glacier storage classes.</p>
<p>You can choose from three archive storage classes optimized for different access patterns and storage duration. For archive data that needs immediate access, choose the <a href="https://aws.amazon.com/s3/storage-classes/glacier/instant-retrieval/">Amazon Glacier Instant Retrieval<figure></figure></a> storage class, an archive storage class that delivers the lowest cost storage with milliseconds retrieval. For archive data that does not require immediate access but needs the flexibility to retrieve large sets of data at no cost, choose Amazon Glacier Flexible Retrieval (formerly Amazon Glacier), with retrieval in minutes or free bulk retrievals in 5-12 hours. To save even more on long-lived archive storage, choose Amazon S3 Glacier Deep Archive, the lowest cost storage in the cloud with data retrieval within twelve hours.</p>
<p>By archiving on AWS you'll have access to very low cost cloud storage, you'll be able to digitally preserve and retain your data for the long term, and you'll be able to leverage comprehensive security and compliance capabilities. The Amazon Glacier storage classes are used by customers for their long-term enterprise archive data, media archives, backup data, and data lake archives.</p>
<p>Use the <a href="https://s3.console.aws.amazon.com/s3/home">S3 console<figure></figure></a> and S3 API to easily archive your data in <a href="https://aws.amazon.com/s3/">Amazon S3<figure></figure></a> . The S3 console and S3 API allow you to access all the features and functionality that the Amazon S3 service provides. Follow this tutorial to begin using the S3 console to store your archive datasets in the Amazon Glacier storage classes.</p>
<h2><figure></figure></h2>
<ul><li> <p>Create an Amazon S3 bucket </p> </li><li> <p>Upload objects to the Amazon Glacier storage classes </p> </li><li> <p>Restore your objects stored in the Amazon Glacier Flexible Retrieval or S3 Glacier Deep Archive storage classes </p> </li></ul>
<h2><figure></figure></h2>
<ol><li> <p>Sign into the Amazon S3 console</p> <ul><li> <p>From the AWS console services search bar, enter ‘<b>S3</b>’. Under the services search results section, select <b>S3</b>. You may notice an option for Amazon Glacier. This option is for the Glacier service prior to integration with Amazon S3. We recommend all new Amazon Glacier users use the S3 console. </p> </li></ul> <figure><img alt="The AWS Management Console showing search results for 'S3', highlighting Amazon S3 (Scalable Storage in the Cloud) and Amazon Glacier (Archive Storage in the Cloud) services." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/ltjfi-console-ffde-search-results.png"/><figcaption>The AWS Management Console showing search results for 'S3', highlighting Amazon S3 (Scalable Storage in the Cloud) and Amazon Glacier (Archive Storage in the Cloud) services.</figcaption></figure> </li><li><figure><img alt="The Amazon S3 web console showing the Buckets overview, account storage snapshot, and the option to create a new bucket. The interface displays total storage, object count, and average object size, along with account navigation and Storage Lens dashboard options." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/console-buckets-overview-account-snapshot.png"/><figcaption>The Amazon S3 web console showing the Buckets overview, account storage snapshot, and the option to create a new bucket. The interface displays total storage, object count, and average object size, along with account navigation and Storage Lens dashboard options.</figcaption></figure></li><li><figure><img alt="The AWS Management Console showing configuration of a new S3 bucket named 'glacier-accounting-archive-1001', with the AWS Region set to US East (N. Virginia) us-east-1. Part of a tutorial for using Glacier storage classes." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/configure-bucket-adc-console-configuration.png"/><figcaption>The AWS Management Console showing configuration of a new S3 bucket named 'glacier-accounting-archive-1001', with the AWS Region set to US East (N. Virginia) us-east-1. Part of a tutorial for using Glacier storage classes.</figcaption></figure></li><li> <p>Next, enable bucket versioning to protect your data from accidental or malicious user deletes or overwrites. </p> <p><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html">Read more about bucket versioning here</a>. Then, add some tags to help track costs associated with our archive data over time. </p> <figure><img alt="The AWS S3 console with bucket versioning enabled and example tags (dept: accounting, archive: true) being added to an S3 bucket. Demonstrates how to configure versioning and tagging for an S3 bucket in Amazon Web Services." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/bucket-versioning-acfd-console-enabled.png"/><figcaption>The AWS S3 console with bucket versioning enabled and example tags (dept: accounting, archive: true) being added to an S3 bucket. Demonstrates how to configure versioning and tagging for an S3 bucket in Amazon Web Services.</figcaption></figure> </li><li> <p>Enable default encryption</p> <p>Next, you have the option of enabling default ‘at-rest’ encryption for the bucket. The settings here will apply to any objects uploaded to the bucket where you have not defined at-rest encryption details during the upload process. </p> <p>For this example, enable server-side encryption leveraging S3 service managed keys (SSE-S3). If your workload requirements are not satisfied by SSE-S3, you can also leverage AWS Key Management Service (KMS). <a href="https://docs.aws.amazon.com/kms/latest/developerguide/services-s3.html">More information about Amazon S3 and AWS KMS can be found here</a>. </p> <figure><img alt="The default encryption settings for an S3 bucket in the AWS Management Console, with server-side encryption enabled using the Amazon S3 key (SSE-S3) option." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/encryption-default-settings-bucket-console.png"/><figcaption>The default encryption settings for an S3 bucket in the AWS Management Console, with server-side encryption enabled using the Amazon S3 key (SSE-S3) option.</figcaption></figure> </li><li> <p>Enable S3 Object Lock</p> <p>Now you have the option to enable <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock.html">S3 Object Lock</a> in the <b>Advanced settings</b> section. With S3 Object Lock, you can store objects using a write-once-read-many (WORM) model. S3 Object Lock can help prevent objects from being deleted or overwritten for a fixed amount of time, or indefinitely. </p> <p>S3 Object Lock can be used to help meet regulatory requirements that require WORM storage, or to simply add another layer of protection against object changes and deletion. </p> <p>For this workload, it is appropriate to enable S3 Object Lock to ensure important archived data is not deleted prematurely by unauthorized users. </p> <ul><li> <p>Choose <b>Enable.</b> </p> </li><li> <p>Select the check box to acknowledge enabling the S3 Object Lock settings </p> </li><li> <p>Select the <b>Create bucket</b> button. </p> </li></ul> <figure><img alt="The AWS Management Console showing the advanced settings for enabling Object Lock on an S3 bucket. The 'Enable' option is selected, and a warning informs users that enabling Object Lock will permanently allow objects in the bucket to be locked, ensuring data integrity and regulatory compliance. The interface includes options, acknowledgments, and the 'Create bucket' button." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/object-lock-ebeff-console-advanced.png"/><figcaption>The AWS Management Console showing the advanced settings for enabling Object Lock on an S3 bucket. The 'Enable' option is selected, and a warning informs users that enabling Object Lock will permanently allow objects in the bucket to be locked, ensuring data integrity and regulatory compliance. The interface includes options, acknowledgments, and the 'Create bucket' button.</figcaption></figure> </li><li> <p>Configure S3 Object Lock</p> <p>Next, the S3 console will present a banner indicating the bucket creation was successful. The S3 console will also present a prompt informing you that additional configuration is needed to enable the S3 Object Lock feature. </p> <p>Select the <b>bucket details</b> link presented in the prompt. Making this selection will open the <b>Properties</b> tab for your newly created bucket. </p> <p>For this exercise, use <b>Governance</b> mode for the S3 Object Lock configuration. This will allow you to permanently delete your test object using an admin user after this tutorial has completed.</p> <p>For more information about S3 Object Lock, read the blog featuring "<a href="https://aws.amazon.com/blogs/storage/protecting-data-with-amazon-s3-object-lock/">Protecting data with Amazon S3 Object Lock</a>." </p> <figure><img alt="A successful creation of an Amazon S3 bucket named 'glacier-accounting-archive-100101' in the AWS Management Console. The image also highlights an additional configuration notice about enabling Object Lock to protect objects from being deleted or overwritten." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/successful-acbc-dbfe-creation-bucket-named.png"/><figcaption>A successful creation of an Amazon S3 bucket named 'glacier-accounting-archive-100101' in the AWS Management Console. The image also highlights an additional configuration notice about enabling Object Lock to protect objects from being deleted or overwritten.</figcaption></figure> </li><li> <p>Edit the S3 Object Lock</p> <p>On the bucket <b>Properties</b> tab, navigate to the <b>Object Lock</b> section and select the <b>Edit</b> button. Here you can set your default values for objects uploaded to your bucket. </p> <p>For this example, you want to enable retention for all objects uploaded to this bucket for 5 years. Select <b>Enable</b> for the <b>Default retention</b> option, choose governance mode by selecting the <b>Governance</b> option under <b>Default retention</b> <b>mode</b> and enter <b>5</b> as the default retention period. </p> <p>Lastly, select <b>Years</b> for the unit of measure and then select the <b>Save changes</b> button. </p> <figure><img alt="The AWS Management Console showing how to enable and configure object lock settings for Amazon Glacier storage classes, including default retention mode, retention period, and governance options." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/umdn-edit-object-lock-console-how-enable.png"/><figcaption>The AWS Management Console showing how to enable and configure object lock settings for Amazon Glacier storage classes, including default retention mode, retention period, and governance options.</figcaption></figure> </li></ol>
<h2><figure></figure></h2>
<ol><li> <p>Sign into the Amazon S3 console</p> <ul><li><p><a href="https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/"><figure></figure></a></p></li></ul> <ul><li><p><a href="https://console.aws.amazon.com/"><figure></figure></a></p></li></ul> <ul><li> <p>From the AWS console services search bar, enter ‘<b>S3</b>’. Under the services search results section, select <b>S3</b>. You may notice an option for Amazon Glacier. This option is for the Glacier service prior to integration with Amazon S3. We recommend all new Amazon Glacier users use the S3 console. </p> </li></ul> <figure></figure> </li><li><figure></figure></li><li><figure></figure></li><li><figure></figure></li><li> <p>Enable default encryption</p> <p>Next, you have the option of enabling default ‘at-rest’ encryption for the bucket. The settings here will apply to any objects uploaded to the bucket where you have not defined at-rest encryption details during the upload process. </p> <p>For this example, enable server-side encryption leveraging S3 service managed keys (SSE-S3). If your workload requirements are not satisfied by SSE-S3, you can also leverage AWS Key Management Service (KMS). <a href="https://docs.aws.amazon.com/kms/latest/developerguide/services-s3.html">More information about Amazon S3 and AWS KMS can be found here</a>. </p> <figure></figure> </li><li> <p>Enable S3 Object Lock</p> <p>Now you have the option to enable <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock.html">S3 Object Lock</a> in the <b>Advanced settings</b> section. With S3 Object Lock, you can store objects using a write-once-read-many (WORM) model. S3 Object Lock can help prevent objects from being deleted or overwritten for a fixed amount of time, or indefinitely. </p> <p>S3 Object Lock can be used to help meet regulatory requirements that require WORM storage, or to simply add another layer of protection against object changes and deletion. </p> <p>For this workload, it is appropriate to enable S3 Object Lock to ensure important archived data is not deleted prematurely by unauthorized users. </p> <ul><li> <p>Choose <b>Enable.</b> </p> </li><li> <p>Select the check box to acknowledge enabling the S3 Object Lock settings </p> </li><li> <p>Select the <b>Create bucket</b> button. </p> </li></ul> <figure></figure> </li><li> <p>Configure S3 Object Lock</p> <p>Next, the S3 console will present a banner indicating the bucket creation was successful. The S3 console will also present a prompt informing you that additional configuration is needed to enable the S3 Object Lock feature. </p> <p>Select the <b>bucket details</b> link presented in the prompt. Making this selection will open the <b>Properties</b> tab for your newly created bucket. </p> <figure></figure> <p><a href="https://aws.amazon.com/blogs/storage/protecting-data-with-amazon-s3-object-lock/"><figure></figure></a></p> <figure></figure> </li><li> <p>Edit the S3 Object Lock</p> <p>On the bucket <b>Properties</b> tab, navigate to the <b>Object Lock</b> section and select the <b>Edit</b> button. Here you can set your default values for objects uploaded to your bucket. </p> <p>For this example, you want to enable retention for all objects uploaded to this bucket for 5 years. Select <b>Enable</b> for the <b>Default retention</b> option, choose governance mode by selecting the <b>Governance</b> option under <b>Default retention</b> <b>mode</b> and enter <b>5</b> as the default retention period. </p> <p>Lastly, select <b>Years</b> for the unit of measure and then select the <b>Save changes</b> button. </p> <figure></figure> </li></ol>
<p>Now that your bucket has been created and configured, you are ready to upload archive data to the Amazon Glacier storage classes.</p>
<ol><li> <p>Select the bucket</p> <p>If you have logged out of your AWS Management Console session, log back in. </p> <figure><img alt="The Amazon S3 console showing the Buckets section, an account snapshot, and a list of buckets including a Glacier storage class archive, used in a tutorial for uploading objects to Amazon Glacier." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/object-upload-cdeaecb-console-buckets.png"/><figcaption>The Amazon S3 console showing the Buckets section, an account snapshot, and a list of buckets including a Glacier storage class archive, used in a tutorial for uploading objects to Amazon Glacier.</figcaption></figure> </li><li><figure><img alt="The Amazon S3 console showing the 'glacier-accounting-archive-100101' bucket with the Objects tab selected, highlighting the 'Upload' button for uploading an object in a Glacier storage class tutorial." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/upload-object-console-accounting-archive.png"/><figcaption>The Amazon S3 console showing the 'glacier-accounting-archive-100101' bucket with the Objects tab selected, highlighting the 'Upload' button for uploading an object in a Glacier storage class tutorial.</figcaption></figure></li><li> <p>Select the file to upload</p> <p>Then, select the <b>Add files</b> button. </p> <p>Select the appropriate file and then select <b>Open</b>. </p> <p>Your file will be listed in the <b>Files and folders</b> section. </p> <figure><img alt="The Amazon S3 web console showing the Upload interface for Glacier storage classes, with the option to add files and folders. The interface highlights the process of uploading a file named '1G_tf_1.dat' with a size of 1.0 GB using the 'Add files' button." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/files-fdca-ebeff-console-upload-interface.png"/><figcaption>The Amazon S3 web console showing the Upload interface for Glacier storage classes, with the option to add files and folders. The interface highlights the process of uploading a file named '1G_tf_1.dat' with a size of 1.0 GB using the 'Add files' button.</figcaption></figure> </li><li> <p>Select the storage class</p> <p>In the <b>Properties</b> section, select the S3 storage class you would like to upload your archive to. </p> <p>Select <b>Glacier Deep Archive</b>, as the example dataset needs to be retained for 5 years and there is a low probability the data will be accessed often. </p> <p>Leave the rest of the options on the default settings and select the <b>Upload</b> button. </p> <p>Objects stored in many S3 storage classes have minimum object durations associated with them. In this case, uploading the test file to Glacier Deep Archive will result in 180 days of billing even if it is deleted early. Storing 1 GB in S3 Glacier Deep Archive for 180 days with the retrieval is ~$0.03. <a href="https://aws.amazon.com/s3/pricing/">You can read more about S3 pricing here</a>.</p> <figure><img alt="A table showing Amazon S3 storage classes, their use cases, availability zones, and minimum storage durations. The highlighted row describes 'Glacier Deep Archive', designed for long-lived archive data accessed less than once a year, with a minimum storage duration of 180 days." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/bnu-table-their-use-cases-availability.png"/><figcaption>A table showing Amazon S3 storage classes, their use cases, availability zones, and minimum storage durations. The highlighted row describes 'Glacier Deep Archive', designed for long-lived archive data accessed less than once a year, with a minimum storage duration of 180 days.</figcaption></figure> </li><li><figure><img alt="The upload status interface for Amazon Glacier storage classes in the AWS console, displaying uploading progress, remaining file size, estimated time, and transfer rate." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/por-upload-status-interface-console.png"/><figcaption>The upload status interface for Amazon Glacier storage classes in the AWS console, displaying uploading progress, remaining file size, estimated time, and transfer rate.</figcaption></figure></li><li> <p>Confirm the upload completed</p> <p>After your file upload operations have completed, you will be presented with a summary of the operations indicating if it has completed successfully or if it has failed. </p> <p>In this case, the file has uploaded successfully. Select the <b>Close</b> button. </p> <figure><img alt="The AWS Management Console showing a successful upload to an Amazon Glacier storage class, with 1 file (1.0 GB) uploaded and no failed uploads." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/glhqo-upload-successful-ecf-bda-console.png"/><figcaption>The AWS Management Console showing a successful upload to an Amazon Glacier storage class, with 1 file (1.0 GB) uploaded and no failed uploads.</figcaption></figure> </li></ol>
<h2><figure></figure></h2>
<p>Now that your bucket has been created and configured, you are ready to upload archive data to the Amazon Glacier storage classes.</p>
<ol><li><p><a href="https://s3.console.aws.amazon.com/s3/home"><figure></figure></a></p><figure></figure></li><li><figure></figure></li><li> <p>Select the file to upload</p> <p>Then, select the <b>Add files</b> button. </p> <p>Select the appropriate file and then select <b>Open</b>. </p> <p>Your file will be listed in the <b>Files and folders</b> section. </p> <figure></figure> </li><li> <p>Select the storage class</p> <p>In the <b>Properties</b> section, select the S3 storage class you would like to upload your archive to. </p> <p>Select <b>Glacier Deep Archive</b>, as the example dataset needs to be retained for 5 years and there is a low probability the data will be accessed often. </p> <figure></figure><p>If your workload requires milliseconds access and single API call access to your archived data, the Amazon Glacier Instant Retrieval storage class should be selected here instead. More information about the Amazon Glacier storage class options can be viewed <a href="https://aws.amazon.com/s3/storage-classes/glacier/">here<figure></figure></a>.</p> <p>Leave the rest of the options on the default settings and select the <b>Upload</b> button. </p> <figure></figure><p>Objects stored in many S3 storage classes have minimum object durations associated with them. In this case, uploading the test file to Glacier Deep Archive will result in 180 days of billing even if it is deleted early. Storing 1 GB in S3 Glacier Deep Archive for 180 days with the retrieval is ~$0.03. <a href="https://aws.amazon.com/s3/pricing/">You can read more about S3 pricing here<figure></figure></a>.</p> <figure></figure> </li><li><figure></figure></li><li> <p>Confirm the upload completed</p> <p>After your file upload operations have completed, you will be presented with a summary of the operations indicating if it has completed successfully or if it has failed. </p> <p>In this case, the file has uploaded successfully. Select the <b>Close</b> button. </p> <figure></figure> </li></ol>
<p>Now that you have successfully uploaded your data to S3 Glacier Deep Archive, let’s go over the process of restoring your data.</p>
<p>the process of restoring your data before it can be accessed, is required for data that is stored in the Amazon Glacier Flexible Retrieval and S3 Glacier Deep Archive storage classes. Data stored in the Amazon Glacier Instant Retrieval storge class does not require this restore request prior to being accessed. You can learn more about Amazon Glacier Instant Retrieval <a href="https://aws.amazon.com/s3/storage-classes/glacier/instant-retrieval/">here</a>.</p>
<ol><li><figure><img alt="The Amazon S3 management console showing a bucket named 'glacier-accounting-archive-100101' with objects stored in the Glacier Deep Archive storage class. The image demonstrates how to view and initiate the restore process for archived objects using Amazon Glacier storage classes." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/initiate-restore-management-console-bucket.png"/><figcaption>The Amazon S3 management console showing a bucket named 'glacier-accounting-archive-100101' with objects stored in the Glacier Deep Archive storage class. The image demonstrates how to view and initiate the restore process for archived objects using Amazon Glacier storage classes.</figcaption></figure></li><li> <p>After selecting your test file’s name, you will be presented with a banner indicating that your object is stored in the S3 Glacier Deep Archive storage class and that you need to restore it if you would like to access your data. </p> <p>You can initiate the restore process by simply selecting the <b>Initiate restore button</b> attached to the information banner, or you can choose <b>Initiate restore</b> from the <b>Object actions</b> menu. </p> <p>The restore process will create a copy of your archived data and will store that copy in the S3 Standard storage class. During the restore initiation process you will set the number of days that you wish to have your data available. During this time period, you will incur applicable storage charges for your data in both the archive storage class as well as in the active storage class.</p> <figure><img alt="The Amazon S3 console showing an object stored in the Glacier Deep Archive storage class with an 'Initiate restore' option highlighted. This page demonstrates how to restore an archived object in AWS S3." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/initiate-restore-page-console-object.png"/><figcaption>The Amazon S3 console showing an object stored in the Glacier Deep Archive storage class with an 'Initiate restore' option highlighted. This page demonstrates how to restore an archived object in AWS S3.</figcaption></figure> </li><li> <p>From the <b>Initiate restore</b> page, you will define the number of days you desire to make your restored copy available. </p> <p>Next, you will have a choice between standard or bulk retrieval. Data stored in the Amazon Glacier Flexible Retrieval storage class will additionally have an option to select expedited retrieval. <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects-retrieval-options.html">More information about restore options can be found here</a>. </p> <p>For this exercise, choose the <b>Standard retrieval</b> option. Then, select the <b>Initiate restore</b> button to continue. </p> <figure><img alt="The Amazon S3 console showing how to configure a restore request for objects stored in Glacier Deep Archive. The interface displays options to select the number of days the restored copy is available, retrieval tier (standard or bulk), and lists specified objects with details such as name, type, storage class, and last modified date." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/configure-restore-cda-caba-console-how.png"/><figcaption>The Amazon S3 console showing how to configure a restore request for objects stored in Glacier Deep Archive. The interface displays options to select the number of days the restored copy is available, retrieval tier (standard or bulk), and lists specified objects with details such as name, type, storage class, and last modified date.</figcaption></figure> </li><li> <p>A summary page will be displayed indicating if the restore request was successful or if any errors occurred. In this case, the restore request was successful. Select the <b>Close</b> button to continue. </p> <p>For this standard restore from S3 Glacier Deep Archive, you will need to wait about 12 hours for the temporary object to be restored to the Amazon S3 Standard-IA storage class. S3 Event notifications support alerting when an object restore event has completed. <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html">More information about S3 Event notifications can be found in the Amazon S3 documentation here</a>. </p> <figure><img alt="The restore status page in Amazon S3 for Glacier storage classes, indicating a successfully initiated restore with 1 object restored and no failed restore requests." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/azk-restore-status-page-indicating.png"/><figcaption>The restore status page in Amazon S3 for Glacier storage classes, indicating a successfully initiated restore with 1 object restored and no failed restore requests.</figcaption></figure> </li><li> <p>Verify restore has completed</p> <p>Now you can verify that your object has been restored. After waiting about twelve hours for the restore operation to complete, log back into your <a href="https://s3.console.aws.amazon.com/s3/home">S3 console</a>. </p> <p>Select <b>Buckets</b> from the left rail menu, and select the name of your bucket to view its contents. From the <b>Objects</b> section, select the file name of the object you have attempted to restore to see its current status. </p> <p>Here you can see that the object’s <b>Restore status</b> is listed as <b>Completed</b>. The <b>Restoration</b> <b>expiry date</b>, which is based on the number of days we defined in the restore process, is listed as well. You have successfully restored your archived object. This object will be available until the time specified in the <b>Restoration expiry date</b> section. </p> <p>You can now perform actions like run S3 select queries against this file, copy the object to another bucket in your account or to another account, or download the data to your local machine. </p> <figure><img alt="The Amazon S3 console showing a file stored in the Glacier Deep Archive storage class with restoration complete status and the restoration expiry date displayed." src="https://docs.aws.amazon.com/images/hands-on/latest/getting-started-using-amazon-s3-glacier-storage-classes/images/restore-complete-console-file-stored-deep.png"/><figcaption>The Amazon S3 console showing a file stored in the Glacier Deep Archive storage class with restoration complete status and the restoration expiry date displayed.</figcaption></figure> </li></ol>
<h2><figure></figure></h2>
<p>Now that you have successfully uploaded your data to S3 Glacier Deep Archive, let’s go over the process of restoring your data.</p>
<figure></figure><p>the process of restoring your data before it can be accessed, is required for data that is stored in the Amazon Glacier Flexible Retrieval and S3 Glacier Deep Archive storage classes. Data stored in the Amazon Glacier Instant Retrieval storge class does not require this restore request prior to being accessed. You can learn more about Amazon Glacier Instant Retrieval <a href="https://aws.amazon.com/s3/storage-classes/glacier/instant-retrieval/">here<figure></figure></a>.</p>
<ol><li><ul><li><p><a href="https://s3.console.aws.amazon.com/s3/home"><figure></figure></a></p></li></ul><figure></figure></li><li> <p>After selecting your test file’s name, you will be presented with a banner indicating that your object is stored in the S3 Glacier Deep Archive storage class and that you need to restore it if you would like to access your data. </p> <p>You can initiate the restore process by simply selecting the <b>Initiate restore button</b> attached to the information banner, or you can choose <b>Initiate restore</b> from the <b>Object actions</b> menu. </p> <figure></figure><p>The restore process will create a copy of your archived data and will store that copy in the S3 Standard storage class. During the restore initiation process you will set the number of days that you wish to have your data available. During this time period, you will incur applicable storage charges for your data in both the archive storage class as well as in the active storage class.</p> <figure></figure> </li><li> <p>From the <b>Initiate restore</b> page, you will define the number of days you desire to make your restored copy available. </p> <p>Next, you will have a choice between standard or bulk retrieval. Data stored in the Amazon Glacier Flexible Retrieval storage class will additionally have an option to select expedited retrieval. <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects-retrieval-options.html">More information about restore options can be found here</a>. </p> <p>For this exercise, choose the <b>Standard retrieval</b> option. Then, select the <b>Initiate restore</b> button to continue. </p> <figure></figure> </li><li> <p>A summary page will be displayed indicating if the restore request was successful or if any errors occurred. In this case, the restore request was successful. Select the <b>Close</b> button to continue. </p> <p>For this standard restore from S3 Glacier Deep Archive, you will need to wait about 12 hours for the temporary object to be restored to the Amazon S3 Standard-IA storage class. S3 Event notifications support alerting when an object restore event has completed. <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html">More information about S3 Event notifications can be found in the Amazon S3 documentation here</a>. </p> <figure></figure> </li><li> <p>Verify restore has completed</p> <p>Now you can verify that your object has been restored. After waiting about twelve hours for the restore operation to complete, log back into your <a href="https://s3.console.aws.amazon.com/s3/home">S3 console<figure></figure></a>. </p> <p>Select <b>Buckets</b> from the left rail menu, and select the name of your bucket to view its contents. From the <b>Objects</b> section, select the file name of the object you have attempted to restore to see its current status. </p> <p>Here you can see that the object’s <b>Restore status</b> is listed as <b>Completed</b>. The <b>Restoration</b> <b>expiry date</b>, which is based on the number of days we defined in the restore process, is listed as well. You have successfully restored your archived object. This object will be available until the time specified in the <b>Restoration expiry date</b> section. </p> <p>You can now perform actions like run S3 select queries against this file, copy the object to another bucket in your account or to another account, or download the data to your local machine. </p> <figure></figure> </li></ol>
<p>In the following steps, you clean up the resources you created in this tutorial. It is a best practice to delete resources that you are no longer using so that you do not incur unintended charges.</p>
<ol><li> <p>Delete your test object</p> <ol><li> <p>If you have logged out of your AWS Management Console session, log back in. </p> </li><li> <p>First you will need to delete the test object from your test bucket. Select the <b>name</b> of the bucket you have been working with for this tutorial. </p> </li><li> <p>Put a check mark in the checkbox to the left of your test object name, then select the <b>Delete</b> button. </p> </li><li> <p>On the <b>Delete objects</b> page, verify that you have selected the proper object to delete and type <b>permanently delete</b> into the <b>Permanently delete objects</b> confirmation box. </p> </li><li> <p>Then, select the <b>Delete object</b> button to continue. Next, you will be presented with a banner indicating if the deletion has been successful. </p> </li></ol> </li><li> <p>Delete your test bucket</p> <ol><li> <p>Finally, you need to delete the test bucket you have created. Return to the list of buckets in your account. </p> </li><li> <p>Select the radio button to the left of the bucket you created for this tutorial, and then select the <b>Delete</b> button. </p> </li><li> <p>Review the warning message. If you desire to continue deletion of this bucket, type the bucket name into the <b>Delete bucket</b> confirmation box and select <b>Delete bucket</b>. </p> </li></ol> </li></ol>
<h2><figure></figure></h2>
<p>In the following steps, you clean up the resources you created in this tutorial. It is a best practice to delete resources that you are no longer using so that you do not incur unintended charges.</p>
<ol><li> <p>Delete your test object</p> <ol><li> <p>If you have logged out of your AWS Management Console session, log back in. </p> </li><li><p><a href="https://s3.console.aws.amazon.com/s3/home"><figure></figure></a></p></li><li> <p>First you will need to delete the test object from your test bucket. Select the <b>name</b> of the bucket you have been working with for this tutorial. </p> </li><li> <p>Put a check mark in the checkbox to the left of your test object name, then select the <b>Delete</b> button. </p> </li><li> <p>On the <b>Delete objects</b> page, verify that you have selected the proper object to delete and type <b>permanently delete</b> into the <b>Permanently delete objects</b> confirmation box. </p> </li><li> <p>Then, select the <b>Delete object</b> button to continue. Next, you will be presented with a banner indicating if the deletion has been successful. </p> </li></ol> </li><li> <p>Delete your test bucket</p> <ol><li> <p>Finally, you need to delete the test bucket you have created. Return to the list of buckets in your account. </p> </li><li> <p>Select the radio button to the left of the bucket you created for this tutorial, and then select the <b>Delete</b> button. </p> </li><li> <p>Review the warning message. If you desire to continue deletion of this bucket, type the bucket name into the <b>Delete bucket</b> confirmation box and select <b>Delete bucket</b>. </p> </li></ol> </li></ol>
<h2><figure></figure></h2>
<p>You have learned how to create an Amazon S3 bucket, upload objects to the Amazon Glacier and S3 Glacier Deep Archive storage classes, and how to restore your objects so that they can be easily retrieved.</p>
<figure></figure><ul><li><figure></figure><figure></figure></li><li><figure></figure></li></ul>
