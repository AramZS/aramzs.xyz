---
author: Andrew Gregory
cover_image: >-
  https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=1324553f4cc6a17a16ec1317aeaf15d7
date: '2026-01-02T17:10:57.977Z'
dateFolder: 2026/01/02
description: >-
  Exclusive: Inaccurate information presented in summaries, Guardian
  investigation finds
isBasedOn: >-
  https://www.theguardian.com/technology/2026/jan/02/google-ai-overviews-risk-harm-misleading-health-information?CMP=Share_iOSApp_Other
link: >-
  https://www.theguardian.com/technology/2026/jan/02/google-ai-overviews-risk-harm-misleading-health-information?CMP=Share_iOSApp_Other
slug: >-
  2026-01-02-httpswwwtheguardiancomtechnology2026jan02google-ai-overviews-risk-harm-misleading-health-informationcmpshareiosappother
tags:
  - ai
  - health
title: Google AI Overviews put people at risk of harm with misleading health advice
---
<figure><picture><source media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 980px)" srcset="https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 740px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 740px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=700&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 740px)" srcset="https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=700&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 660px)" srcset="https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=645&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 480px)" srcset="https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=645&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=465&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 320px)" srcset="https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none"/><img alt="Man looking at smartphone in bed" src="https://i.guim.co.uk/img/media/3b66311fb2e902392b06cde7eb5350cc8f51fedb/0_0_4264_3413/master/4264.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none"/></picture><figcaption data-spacefinder-role="inline">The Guardian uncovered several cases of inaccurate health information in Google’s AI Overviews. Photograph: Caia Image/Alamy</figcaption></figure>
<h2 data-gu-name="standfirst">Exclusive: Inaccurate information presented in summaries, Guardian investigation finds</h2>
<p>People are being put at risk of harm by false and misleading health information in Google’s artificial intelligence summaries, a Guardian investigation has found.</p>
<p>The company has said its AI Overviews, which use generative AI to provide snapshots of essential information about a topic or question, are “<a data-link-name="in body link" href="https://blog.google/products/search/generative-ai-google-search-may-2024/">helpful</a>” and “<a data-link-name="in body link" href="https://search.google/intl/en-GB/ways-to-search/ai-overviews/">reliable</a>”.</p>
<p>But some of the summaries, which appear at the top of search results, served up inaccurate health information and put people at risk of harm.</p>
<p>In one case that experts described as “really dangerous”, Google wrongly advised people with pancreatic cancer to avoid high-fat foods. Experts said this was the exact opposite of what should be recommended, and may increase the risk of patients dying from the disease.</p>
<p>In another “alarming” example, the company provided bogus information about crucial liver function tests, which could leave people with serious liver disease wrongly thinking they are healthy.</p>
<p>Google searches for answers about women’s cancer tests also provided “completely wrong” information, which experts said could result in people dismissing genuine symptoms.</p>
<p>A Google spokesperson said that many of the health examples shared with them were “incomplete screenshots”, but from what they could assess they linked “to well-known, reputable sources and recommend seeking out expert advice”.</p>
<p>The Guardian investigation comes amid growing concern that AI data can confuse consumers who may assume that it is reliable. In November last year, a study found AI chatbots across a range of platforms <a data-link-name="in body link" href="https://www.theguardian.com/technology/2025/nov/18/warning-ai-chatbots-inaccurate-financial-advice-tips-chatgpt-copilot-uk">gave inaccurate financial advice</a>, while similar concerns have been raised about <a data-link-name="in body link" href="https://www.bbc.co.uk/news/articles/cq5ggew08eyo">summaries of news stories</a>.</p>
<p>Sophie Randall, director of the Patient Information Forum, which promotes evidence-based health information to patients, the public and healthcare professionals, said the examples showed “Google’s AI Overviews can put inaccurate health information at the top of online searches, presenting a risk to people’s health”.</p>
<p>Stephanie Parker, the director of digital at Marie Curie, an end-of-life charity, said: “People turn to the internet in moments of worry and crisis. If the information they receive is inaccurate or out of context, it can seriously harm their health.”</p>
<p>The Guardian uncovered several cases of inaccurate health information in Google’s AI Overviews after a number of health groups, charities and professionals raised concerns.</p>
<p>Anna Jewell, the director of support, research and influencing at Pancreatic Cancer UK, said advising patients to avoid high-fat foods was “completely incorrect”. Doing so “could be really dangerous and jeopardise a person’s chances of being well enough to have treatment”, she added.</p>
<p>Jewell said: “The Google AI response suggests that people with pancreatic cancer avoid high-fat foods and provides a list of examples. However, if someone followed what the search result told them then they might not take in enough calories, struggle to put on weight, and be unable to tolerate either chemotherapy or potentially life-saving surgery.”</p>
<p>Typing “what is the normal range for liver blood tests” also served up misleading information, with masses of numbers, little context and no accounting for nationality, sex, ethnicity or age of patients.</p>
<p>Pamela Healy, the chief executive of the British Liver Trust, said the AI summaries were alarming. “Many people with liver disease show no symptoms until the late stages, which is why it’s so important that they get tested. But what the Google AI Overviews say is ‘normal’ can vary drastically from what is actually considered normal.</p>
<p>“It’s dangerous because it means some people with serious liver disease may think they have a normal result then not bother to attend a follow-up healthcare meeting.”</p>
<p>A search for “vaginal cancer symptoms and tests” listed a pap test as a test for vaginal cancer, which is incorrect.</p>
<p>Athena Lamnisos, the chief executive of the Eve Appeal cancer charity, said: “It isn’t a test to detect cancer, and certainly isn’t a test to detect vaginal cancer – this is completely wrong information. Getting wrong information like this could potentially lead to someone not getting vaginal cancer symptoms checked because they had a clear result at a recent cervical screening.</p>
<p>“We were also worried by the fact that the AI summary changed when we did the exact same search, coming up with a different response each time that pulled from different sources. That means that people are getting a different answer depending on when they search, and that’s not good enough.”</p>
<p>Lamnisos said she was extremely concerned. “Some of the results we’ve seen are really worrying and can potentially put women in danger,” she said.</p>
<p>The Guardian also found Google AI Overviews delivered misleading results for searches about mental health conditions. “This is a huge concern for us as a charity,” said Stephen Buckley, the head of information at Mind.</p>
<p>Some of the AI summaries for conditions such as psychosis and eating disorders offered “very dangerous advice” and were “incorrect, harmful or could lead people to avoid seeking help”, Buckley said.</p>
<p>Some also missed out important context or nuance, he added. “They may suggest accessing information from sites that are inappropriate … and we know that when AI summarises information, it can often reflect existing biases, stereotypes or stigmatising narratives.”</p>
<p>Google said the vast majority of its AI Overviews were factual and helpful, and it continuously made quality improvements. The accuracy rate of AI Overviews was on a par with its other search features like featured snippets, which had existed for more than a decade, it added.</p>
<p>The company also said that when AI Overviews misinterpreted web content or missed context, it would take action as appropriate under its policies.</p>
<p>A Google spokesperson said: “We invest significantly in the quality of AI Overviews, particularly for topics like health, and the vast majority provide accurate information.”</p>
