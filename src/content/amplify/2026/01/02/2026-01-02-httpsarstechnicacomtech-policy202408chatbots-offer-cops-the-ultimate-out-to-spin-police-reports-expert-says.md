---
author: Ashley Belanger
cover_image: >-
  https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-1152x648.jpg
date: '2026-01-02T16:57:46.362Z'
dateFolder: 2026/01/02
description: Experts warn chatbots writing police reports can make serious errors.
isBasedOn: >-
  https://arstechnica.com/tech-policy/2024/08/chatbots-offer-cops-the-ultimate-out-to-spin-police-reports-expert-says/
link: >-
  https://arstechnica.com/tech-policy/2024/08/chatbots-offer-cops-the-ultimate-out-to-spin-police-reports-expert-says/
slug: >-
  2026-01-02-httpsarstechnicacomtech-policy202408chatbots-offer-cops-the-ultimate-out-to-spin-police-reports-expert-says
tags:
  - ai
  - media
  - law and order
title: 'Chatbots offer cops the “ultimate out” to spin police reports, expert says'
---
<figure></figure><p> <em> ChatG-PD? </em></p>
<p>Experts warn chatbots writing police reports can make serious errors.</p>
<p><a href="https://arstechnica.com/author/ashleybelanger/"> Ashley Belanger </a> –  Aug 29, 2024 10:38 AM |</p>
<figure><a data-cropped="false" data-pswp-height="1440" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-300x169.jpg 300w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-2048x1152.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-1440x810.jpg 1440w" data-pswp-width="2560" href="https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera.jpg"><img alt="" sizes="(max-width: 2560px) 100vw, 2560px" src="https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera.jpg" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-300x169.jpg 300w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-2048x1152.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/08/police-ai-body-camera-1440x810.jpg 1440w"/></a></figure>
<p> / Credit: Aurich Lawson | Getty Images</p>
<figure></figure><p>Text settings</p>
<figure></figure><p>If you were suspected of a crime, would you trust a chatbot to accurately explain what happened?</p>
<p>Some police departments think the tech is ready. And officers who have started using chatbots to quickly complete their most dreaded task of drafting police reports seemingly don’t want to go back to spending hours each week doing their own paperwork.</p>
<p>In June, a police department in Frederick, Colorado, boasted that it was the “first law enforcement agency in the world to go live with Axon Draft One,” a new kind of police tech that allows a chatbot to spit out AI-generated police reports almost immediately after a body camera stops recording a police interaction.</p>
<p>Powered by OpenAI’s GPT-4 model—which also fuels ChatGPT—Draft One was initially <a href="https://investor.axon.com/2024-04-23-Axon-reimagines-report-writing-with-Draft-One,-a-first-of-its-kind-AI-powered-force-multiplier-for-public-safety">pitched</a> in April to police departments globally. Axon, a billion-dollar company known for its tasers and body cameras, hyped it as “a revolutionary new software product that drafts high-quality police report narratives in seconds based on auto-transcribed body-worn camera audio.” And according to Axon, cops couldn’t wait to try it out, with some departments eagerly joining trials.</p>
<p>Ars confirmed that by May, Frederick’s police department was the first agency to purchase the product, soon followed by an untold number of departments around the US.</p>
<p>Relying exclusively on body camera audio—not video—Draft One essentially summarizes the key points of a recording, similar to how AI assistants summarize the audio of a Zoom meeting.</p>
<p>This may seem like an obvious use for AI, but legal and civil rights experts have warned that the humble police report is the root of the entire justice system, and tampering with it could have serious consequences. Police reports influence not just plea bargains, sentencing, discovery processes, and trial outcomes, but also how society holds police accountable.</p>
<p>“The forcing function of writing out a justification, and then swearing to its truth, and publicizing that record to other legal professionals (prosecutors/judges) is a check on police power,” law expert Andrew Ferguson wrote in the first law review <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4897632">article</a> analyzing Draft One’s potential impacts when compared to human reporting. Additionally, “police reports also serve as the factual grounding for civil lawsuits and insurance claims,” Ferguson noted.</p>
<p>By introducing chatbots that are known to hallucinate, confuse jokes for facts, or randomly add incorrect information, police tech like Draft One could be used to legitimize wrongful arrests, reinforce police suspicions, mislead courts, or even cover up police abuse, experts have cautioned.</p>
<p>Axon’s manager for AI products, Noah Spitzer-Williams, <a href="https://apnews.com/article/ai-writes-police-reports-axon-body-cameras-chatgpt-a24d1502b53faae4be0dac069243f418">told AP News</a> that unlike ChatGPT, Draft One is less prone to hallucinate because Axon has “access to more knobs and dials than an actual ChatGPT user would have.” Because Axon turned down the “creativity dial” on Draft One, the AI tool is supposedly better at resisting embellishments and sticking to the facts, Spitzer-Williams claimed.</p>
<p>Marketing Draft One as a way to save cops time when drafting police reports, Axon urged police departments to start slowly when learning to use the AI assistants, promising in its press release to “innovate responsibly.”</p>
<p>To minimize potential harms, early adopters like the Frederick PD were advised to restrict their use of chatbots to drafting reports only on minor incidents and charges. Only after officers have gained enough experience “in how to use the tool effectively” on “low severity reports first,” should they then “expand to more severe reports,” Axon’s press release recommended.</p>
<p>But although the official advice was to limit early uses, Axon’s CEO, Rick Smith, openly touted Draft One as having the potential to put an end to busywork bogging down increasingly under-resourced police departments everywhere.</p>
<p>“Every single officer in the US writes police reports, often every day and normally multiple times a day,” Smith said in the press release. “As we’ve done with Draft One, harnessing the power of AI will prove to be one of the most impactful technological advancements of our time to help scale police work and revolutionize the way public safety operates.”</p>
<p>Soon after police departments started implementing Draft One, a senior policy analyst who monitors police use of AI for the digital rights group the Electronic Frontier Foundation (EFF), Matthew Guariglia, wrote a <a href="https://www.eff.org/deeplinks/2024/05/what-can-go-wrong-when-police-use-ai-write-reports">blog post</a> warning that increasingly rampant use of Draft One required urgent scrutiny.</p>
<p>“We just don’t know how it works yet,” Guariglia told Ars.</p>
<p>Although Draft One seems like the “ultimate time-saver for police departments hoping to get officers out from behind their desks,” Guariglia wrote, the AI tool “could present new issues for those who encounter police.” Most significantly, “marginalized communities already subject to a disproportionate share of police interactions” in the US could face more harassment as cops spend more time on the streets, Guariglia suggested.</p>
<p>Because Axon is not really stopping cops from using Draft One in more severe cases that could trigger serious consequences based on AI mistakes, Guariglia said that civil rights experts are concerned about the technology’s widespread use in untested cases where the chatbots might act unpredictably.</p>
<p>It appears that many cops don’t share those concerns, though, with some quickly diving into AI-charted waters where chatbots are trusted to help convey more nuanced police narratives using technical legal terms that some cops may not typically use or fully understand. Just four months after Draft One’s rollout, AP News found that some police departments were already using the AI tool to draft police reports for a wider range of serious cases, not just reports on minor incidents and charges.</p>
<p>Some cops are mostly following Axon’s advice. Oklahoma City cops, for example, told AP News that Draft One isn’t used for arrests, felonies, or violent crimes yet, due to advice from prosecutors warning of risks from inaccuracies.</p>
<p>But other cops in Lafayette, Indiana, have said that the AI tool became so “incredibly popular” that any officer can now use it to draft reports for any case. The same goes for cops in Fort Collins, Colorado. And Frederick PD’s spokesperson told Ars that its officers are already using Draft One in more serious cases, too.</p>
<p>Draft One has not been tested at scale, so it’s currently unclear if it will decrease or increase the accuracy of police reports, Ferguson noted in his article analyzing Axon’s AI tool. Because of all the unknowns, Ferguson warned that one clear danger “for the criminal legal system is the digital poisoning of fact-based development in criminal trials by algorithmically altering the narrative” in ways that seem likely to bias police views.</p>
<p>“The technology is just being rolled out to police departments but will likely become the norm for police reports across the nation,” Ferguson predicted in his article. And “all of the concerns we might have about AI accuracy, human accuracy, and the translation between those two ways of communicating are heightened with AI-assisted police reports,” Ferguson told Ars.</p>
<p>Axon did not respond to Ars’ requests for comment.</p>
<h2>Playing “Mad Libs” with AI police reports</h2>
<p>A spokesperson for the Frederick police department told Ars exactly how the AI tech moves so quickly from the testing stage to everyday use in just about any case an officer takes on.</p>
<p>In Frederick, the first step was having agency leadership “thoroughly” evaluate Draft One “through case studies, multiple demos, and discussions with both Axon and test agencies,” the spokesperson said.</p>
<p>After that, the department discussed the tech with the county district attorney, presumably seeking to assess any legal concerns that may be raised in court.</p>
<p>Once everyone was on board, the spokesperson confirmed that officers initially “used Draft One’s AI capabilities for reporting minor incidents” as Axon recommended. But as AP News uncovered elsewhere, because “confidence in the tool has grown” in Frederick, “more officers are now utilizing it for a broader range of cases” today within a few months of purchasing the software, the spokesperson said.</p>
<p>The ease of adoption may have to do with how seamlessly Draft One works with body cameras police are already widely using. Axon designed Draft One to generate reports from its industry-leading body cameras, touting that police reports can be drafted “within five minutes of an incident ending.”</p>
<p>Ferguson analyzed the outputs and noted that the structure of AI-generated police reports is “somewhat standardized.” Each report starts by providing background information before explaining the cops’ actions, then the suspect’ reactions, and finally “the facts and details of the suspicion.”</p>
<p>Police officers are expected to review these outputs, then either reject the report or accept it as the first draft. Once their edits are done, the cops check a box confirming that parts of the report are AI-generated. And at the end, they sign off on the report, confirming that they “are willing to testify to its accuracy and completeness,” Ferguson noted. A supervisor then reviews the report, providing another check on the process.</p>
<p>But supervisor checks and other guardrails aren’t enough to safeguard the public from this tech, Ferguson suggested. What’s urgently needed is more transparency.</p>
<p>“At a minimum, information about how the models were trained, what information was provided, what information was excluded, and how the models were tested should accompany any use of the technology in court,” Ferguson recommended.</p>
<p>Additionally, Ferguson suggested that the public needs to better understand the way Draft One is coded to generate varied crime reports that read in a “certain pre-approved way.” The code could reveal which technical words or legal terms are favored for which crime reports and which are “forbidden,” Ferguson said, noting that “these choices are not illegitimate, just hidden in the code, and need to be surfaced.”</p>
<p>“Understanding what prompts and preferences were selected will allow advocates to see if any hidden errors, omissions, or distortions result from the request” to generate a specific report, Ferguson said.</p>
<p>Draft One’s code could even be designed to potentially insert probable cause into police reports, Ferguson warned.</p>
<p>“As it currently stands, Draft One makes no mention of recognizing or inserting prompts for probable cause,” Ferguson wrote. “However, the ease in which probable cause ‘inserts’ could be added is too obvious to ignore. All that would be required is that a checkbox for the particular crime charged” is ticked, and that “would trigger the insertion of the legal elements of the crime.”</p>
<p>And the problem only snowballs if these early AI-generated reports that “run the risk of creating scripts and boiler plate justifications for probable cause” could end up becoming the training data for future AI tech assisting cops writing police reports, Ferguson said.</p>
<p>We still don’t know if AI-generated police reports will be more or less detailed than human-written reports, Ferguson wrote. It’s even possible that the automated process will make reports more accurate. But until there’s more data, the only way courts can “have confidence that the resulting police reports can be trusted,” Ferguson said, will be by “surfacing and identifying the training models used, the queries, the parameters and choices, plus the testing results.”</p>
<p>“At almost every important point of AI-generated content creation—recording, transcription, editing, adoption—there is room for error,” Ferguson told Ars. “We simply do not know if the technology improves accuracy or impedes it. Any jurisdiction piloting the technology should be asking hard questions about how it works in practice.”</p>
<h2>Why cops love Draft One</h2>
<p>To ensure the quality of the draft reports, Axon conducted a double-blind study. According to the company’s press release, it consulted with “24 independent experts, including district attorneys, field operations command staff, and inclusion scholars” to compare average human-written police reports to Draft One outputs.</p>
<p>“Results showed that Draft One performed equal to or better than officer-only report narratives across five dimensions, including completeness, neutrality, objectivity, terminology and coherence,” Axon’s press release said. For any department implementing Draft One, Axon promised that these results would help “accelerate justice” by eliminating manual “data entry” that most cops find “burdensome.”</p>
<p>Immediately, cops who were early adopters in Colorado were struck by how much time Draft One saved them. “This technology has increased efficiency as well as quality and professionalism of our reports,” Frederick PD’s spokesperson told Ars. And a 27-year veteran Fort Collins sergeant quoted in Axon’s press release, Robert Younger, agreed, calling the AI tool “one of the most exciting innovations for law enforcement I have ever seen.”</p>
<p>Tests showed an “82 percent decrease in time spent writing reports,” Younger claimed.</p>
<p>Cops’ enthusiasm to use Draft One wherever possible was predictable. The EFF’s Guariglia told Ars that it was never a “realistic expectation” for Axon to think that cops would only choose to make “their lives easier under very specific circumstances” when reporting on minor incidents, when they could just as easily use Draft One under any circumstances.</p>
<p>“The technology is going to be used, and for Axon to just say, ‘we’re putting out this tech, but we don’t recommend police use it in this specific way, but we’re not creating any real substantial hurdles to prevent them from using it in this specific way,’ I think that sets an incredibly dangerous precedent,” Guariglia told Ars.</p>
<p>Axon claims that Draft One includes “a range of strict safeguards” that require that “humans make the decisions in key moments” so that no police report is ever fully AI-generated.</p>
<p>Among safeguards, Draft One requires officers to add key information—like names and addresses—and to edit out some information. Ferguson likened this to cops playing “Mad Libs” with AI-drafted reports instead of focusing on recording their own memory of the incident. Here’s an example from his article:</p>
<blockquote><p>“W-1 stated that S-1 approached her asked her: “What time is it?” As W-1 was looking at her watch, [<strong>using intimidation or threat</strong>] S-1 grabbed her purse [<strong>another’s property</strong>] and ran northbound on Main Street [<strong>taking the purse from her presence</strong>]. S-1 was observed by W-2 hiding in an alley [<strong>intending to deprive W-1 of the purse permanently</strong>].”</p></blockquote>
<p>Safeguards also include “controls to ensure proofreading,” like asking cops to catch and remove random nonsensical facts inserted into reports to ensure that cops are actually reviewing the AI-generated sections before signing off on the reports. In his law review article, Ferguson noted examples, such as “the international spy network was revealed to be a group of highly trained squirrels” or “it was unanimously decided that rock-paper-scissors would determine the suspect’s fate.”</p>
<p>If cops don’t remove these facts, it’s a sign they rubber-stamped the AI-generated report, Axon suggested, which would be unacceptable. The company’s CEO, Smith, told AP News that the last thing Axon wants is for cops to take the stand and testify, “Well, ‘the AI wrote that. I didn’t.’”</p>
<p>Civil rights activists’ chief concern is that Draft One will make police work easier while simultaneously making life harder for communities most often targeted by police, AP News reported. There may even be a spike in police reports as cops who may have dropped charges in minor incidents previously may suddenly be motivated to file charges if they don’t have to do all the paperwork themselves.</p>
<p>It’s currently unclear how many police departments are using Draft One, as Axon has not publicly disclosed that information. Axon already faces competition from other startups providing AI assistants to cops, including Policereports.ai and Truleo, AP News reported.</p>
<p>But because Axon is a trusted brand in police tech nationwide, “experts and police officials expect AI-generated reports to become more ubiquitous in the coming months and years,” AP News forecasted. And there’s no telling how Draft One may evolve over time.</p>
<p>Smith told AP News that eliminating biases in Draft One is one reason why the video from body cam footage doesn’t factor into the AI-generated reports—yet. But it seemingly could in the future.</p>
<p>“Given all the sensitivities around policing, around race and other identities of people involved, that’s an area where I think we’re going to have to do some real work before we would introduce it,” Smith told AP News. He further said that while “some of the tested responses” using video were not “overtly racist,” they were “insensitive in other ways.”</p>
<p>Axon did not respond to Ars’ request to comment on any updates planned for the AI tool.</p>
<h2>How chatbots could reshape the legal system</h2>
<p>Ferguson warned that Draft One and similar AI tools could change “the trajectory of individual cases” and reshape “the entire legal system,” all with the click of a button.</p>
<p>There are many things that can go wrong with AI-generated police reports, Guariglia and Ferguson agreed. AI could misinterpret a metaphor, gloss over or omit key facts, mix up the timeline of events, or show a bias toward police.</p>
<p>On top of those risks, cops are already speaking directly into the body camera to influence AI-generated reports, the AP reported, and it’s not clear how AI would interpret cops’ attempts to steer the narrative. Guariglia told Ars that no one is sure how the AI will interpret, for example, if a cop says, “drop the gun.” Draft One’s report might accurately note that the police officer said to drop the gun, or it might simply say the suspect was armed, Guariglia said. These details matter, especially if the video footage that the chatbot doesn’t summarize reveals that there was no gun.</p>
<p>“Police officers who deliberately speak with mistruths or exaggerations to shape the narrative available in body camera footage now have even more of a veneer of plausible deniability with AI-generated police reports,” Guariglia wrote in his blog. “If police were to be caught in a lie concerning what’s in the report, an officer might be able to say that they did not lie: the AI simply mis-transcribed what was happening in the chaotic video.”</p>
<p>Ferguson added that “perhaps more concerning, a sophisticated police officer will be able to narrate the facts to suit their desired outcome.</p>
<p>“Knowing that what the officer verbalizes will make it into the transcript could encourage officers to manipulate the facts,” Ferguson said.</p>
<p>Because AI could accidentally or intentionally be used to twist a narrative in the police’s favor, Guariglia fears that widespread adoption of the technology could rapidly “have catastrophic consequences for defendants in court.” Especially in cases where the police report is the sole evidence for sentencing or in complex cases where Guariglia said that “interpretation matters.”</p>
<p>Having access to chatbot logs could help courts discover inaccuracies in the AI reporting or make it obvious when cops lie on the stand, but just like getting body cam footage from police departments can be challenging, so could getting transcripts to verify details in AI-generated reports, Guariglia told Ars. And if the public—including journalists and public defenders—doesn’t have consistent access to check the chatbots’ logs, there’s a big concern that Draft One could give police “the ultimate out for having inconsistencies with their stories,” Guariglia said.</p>
<p>Ferguson noted that studies have shown that body camera footage—which captures scenes from the cops’ point of view—already biases police, and AI chatbots could compound that problem by algorithmically reinforcing that bias.</p>
<p>The impact these reports will have on the legal system is unclear, but Ferguson expects they will place an extra burden on courts. Any time a defendant contests details in the report, the court will have to figure out which parts are AI-generated and which parts the cop wrote, likely requiring chatbot logs and police testimony.</p>
<p>Any good defense lawyer will likely question the legitimacy of the AI-assisted report, Ferguson said. And “if a good percentage of the police report is AI-generated, this reality alone will call into question the legitimacy of the report in the eyes of the jury.”</p>
<p>For courts relying on AI-assisted police reports, key questions will be whether prosecutors “can still assert that the underlying facts are reliable and whether the judge can rely on the facts for questions of pretrial liberty,” Ferguson wrote.</p>
<p>“Neither question offers a simple answer,” Ferguson wrote.</p>
<p>Ferguson told AP News that there needs to be more public awareness about police use of chatbots so that benefits and potential harms can be debated. He recommends that “any lawyer with a case involving AI-generated police reports should be litigating about reliability, audit trails, and comparing the reports with the actual body-worn camera footage.” And “any judge relying on the system for probable cause or preventative detention decisions should be inquiring about what steps were taken to promote accuracy.”</p>
<p>Guariglia told Ars that the technology is so new that skeptics are not even at the stage of recommending improvements because they don’t know what unforeseeable problems may be coming around the bend. He has urged police departments to provide access to AI-assisted reports to external reviewers for further study.</p>
<p>“This is one of those technologies where it’s gonna hit the mainstream incredibly quickly,” Guariglia told Ars. “I don’t think we’re prepared for or aware of all the ways in which this is gonna cause problems.”</p>
<p>On the otherhand, Guariglia speculated in his blog that cops could end up abandoning the tech before we get a chance to discover just how useful it could be. Draft One could easily go the way of <a href="https://www.technologyreview.com/2024/04/16/1090846/ai-police-body-cams-cops-transparency/">discarded AI-enhanced body cameras</a> if the AI tool “consistently produces a narrative from audio that police do not like,” Guariglia said.</p>
<p>Listing image: Aurich Lawson | Getty Images</p>
