---
author: 'Amelia Gentleman, Helena Horton'
cover_image: >-
  https://i.guim.co.uk/img/media/bf8236e418e8d46f0bb0bbe118f29d31eefd471f/0_901_4000_3198/master/4000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a2089138e4eb493c9c08823e7d5bcf32
date: '2026-01-12T02:44:47.620Z'
dateFolder: 2026/01/11
description: >-
  The ‘put her in a bikini’ trend rapidly evolved into hundreds of thousands of
  requests to strip clothes from photos of women, horrifying those targeted
isBasedOn: >-
  https://www.theguardian.com/news/ng-interactive/2026/jan/11/how-grok-nudification-tool-went-viral-x-elon-musk?CMP=share_btn_url
link: >-
  https://www.theguardian.com/news/ng-interactive/2026/jan/11/how-grok-nudification-tool-went-viral-x-elon-musk?CMP=share_btn_url
slug: >-
  2026-01-11-httpswwwtheguardiancomnewsng-interactive2026jan11how-grok-nudification-tool-went-viral-x-elon-muskcmpsharebtnurl
tags:
  - ai
  - tech
  - social media
title: '‘Add blood, forced smile’: how Grok’s nudification tool went viral'
---
<figure><picture><source media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/bf8236e418e8d46f0bb0bbe118f29d31eefd471f/0_2_4000_4996/master/4000.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 980px)" srcset="https://i.guim.co.uk/img/media/bf8236e418e8d46f0bb0bbe118f29d31eefd471f/0_2_4000_4996/master/4000.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 740px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 740px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/bf8236e418e8d46f0bb0bbe118f29d31eefd471f/0_2_4000_4996/master/4000.jpg?width=700&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 740px)" srcset="https://i.guim.co.uk/img/media/bf8236e418e8d46f0bb0bbe118f29d31eefd471f/0_2_4000_4996/master/4000.jpg?width=700&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/bf8236e418e8d46f0bb0bbe118f29d31eefd471f/0_2_4000_4996/master/4000.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 660px)" srcset="https://i.guim.co.uk/img/media/bf8236e418e8d46f0bb0bbe118f29d31eefd471f/0_2_4000_4996/master/4000.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/bf8236e418e8d46f0bb0bbe118f29d31eefd471f/0_2_4000_4996/master/4000.jpg?width=645&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 480px)" srcset="https://i.guim.co.uk/img/media/bf8236e418e8d46f0bb0bbe118f29d31eefd471f/0_2_4000_4996/master/4000.jpg?width=645&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/bf8236e418e8d46f0bb0bbe118f29d31eefd471f/0_2_4000_4996/master/4000.jpg?width=465&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 320px)" srcset="https://i.guim.co.uk/img/media/bf8236e418e8d46f0bb0bbe118f29d31eefd471f/0_2_4000_4996/master/4000.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none"/><img alt="Illustration of a blurred-out sexual image" src="https://i.guim.co.uk/img/media/bf8236e418e8d46f0bb0bbe118f29d31eefd471f/0_2_4000_4996/master/4000.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none"/></picture><figcaption>By 8 January as many as 6,000 bikini demands were being made to the chatbot every hour, according to analysis conducted for the Guardian. Illustration: Guardian Design</figcaption></figure>
<h2 data-gu-name="standfirst">The ‘put her in a bikini’ trend rapidly evolved into hundreds of thousands of requests to strip clothes from photos of women, horrifying those targeted</h2>
<p>Like thousands of women across the world, Evie, a 22-year-old photographer from Lincolnshire, woke up on New Year’s Day, looked at her phone and was alarmed to see that fully clothed photographs of her had been digitally manipulated by Elon Musk’s AI tool, Grok, to show her in just a bikini.</p>
<p>The “put her in a bikini” trend began quietly at the end of last year before exploding at the start of 2026. Within days, hundreds of thousands of requests were being made to the Grok chatbot, asking it to strip the clothes from photographs of women. The fake, sexualised images were posted publicly on X, freely available for millions of people to inspect.</p>
<p>Relatively tame requests by X users to alter photographs to show women in bikinis, <a data-link-name="in body link" href="https://www.theguardian.com/technology/2026/jan/02/elon-musk-grok-ai-children-photos">rapidly evolved during the first week of the year</a>, hour by hour, into increasingly explicit demands for women to be dressed in transparent bikinis, then in bikinis made of dental floss, placed in sexualised positions, and made to bend over so their genitals were visible. By 8 January as many as 6,000 bikini demands were being made to the chatbot every hour, according to analysis conducted for the Guardian.</p>
<p>This unprecedented mainstreaming of nudification technology triggered instant outrage from the women affected, but it was days before regulators and politicians woke up to the enormity of the proliferating scandal. The public outcry raged for nine days before X made any substantive changes to stem the trend. By the time it acted, <a data-link-name="in body link" href="https://www.theguardian.com/technology/2026/jan/09/grok-image-generator-outcry-sexualised-ai-imagery">early on Friday morning</a>, degrading, non-consensual manipulated pictures of countless women had already flooded the internet.</p>
<p>In the bikini image generated of Evie – who asked to use only her first name to avoid further abuse – she was covered in baby oil. She censored the picture, and reshared it to raise awareness of the dangers of Grok’s new feature, then logged off. Her decision to highlight the problem attracted an onslaught of new abuse. Users began making even more disturbing sexual images of her.</p>
<figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><picture><source media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/98db3bdec684c51fb2793fe5c1ee9ed85f58d0be/1097_190_6590_5272/master/6590.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 660px)" srcset="https://i.guim.co.uk/img/media/98db3bdec684c51fb2793fe5c1ee9ed85f58d0be/1097_190_6590_5272/master/6590.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/98db3bdec684c51fb2793fe5c1ee9ed85f58d0be/1097_190_6590_5272/master/6590.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 480px)" srcset="https://i.guim.co.uk/img/media/98db3bdec684c51fb2793fe5c1ee9ed85f58d0be/1097_190_6590_5272/master/6590.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/98db3bdec684c51fb2793fe5c1ee9ed85f58d0be/1097_190_6590_5272/master/6590.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 320px)" srcset="https://i.guim.co.uk/img/media/98db3bdec684c51fb2793fe5c1ee9ed85f58d0be/1097_190_6590_5272/master/6590.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none"/><img alt="Evie stands with arms folded at her home" src="https://i.guim.co.uk/img/media/98db3bdec684c51fb2793fe5c1ee9ed85f58d0be/1097_190_6590_5272/master/6590.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none"/></picture><figcaption data-spacefinder-role="inline">Evie received an onslaught of abuse after her decision to highlight the problem. Photograph: Fabio De Paola/The Guardian</figcaption></figure>
<p>“The tweet just blew up,” she said. “Since then I have had so many more made of me and every one has got a lot worse and worse. People saw it was upsetting me and I didn’t like it and they kept doing more and more. There’s one of me just completely naked with just a bit of string around my waist, one with a ball gag in my mouth and my eyes rolled back. The fact these were able to be generated is mental.”</p>
<p>As people slowly started to understand the full potential of the tool, the increasingly degrading images of the early days were quickly superseded. Since the end of last week, users have asked for the bikinis to be decorated with swastikas – or asked for white, semen-like liquid to be added to the women’s bodies. Pictures of teenage girls and children were stripped down to revealing swimwear; some of this content could clearly be categorised as child sexual abuse material, but remained visible on the platform.</p>
<p>The requests became ever more extreme. Some users, mostly men, began to demand to see bruising on the bodies of the women, and for blood to be added to the images. Requests to show women tied up and gagged were instantly granted. By Thursday, the chatbot was being asked to add bullet holes to the face of <a data-link-name="in body link" href="https://www.theguardian.com/us-news/2026/jan/08/minnesota-ice-shooting-nicole-macklin-good">Renee Nicole Good</a>, the woman killed by an ICE agent in the US on Wednesday. Grok readily obliged, posting graphic, bloodied altered images of the victim on X within seconds.</p>
<p>Hours later, the public @Grok account suddenly had its image-generation capabilities restricted, making them only available to paying subscribers. But this appeared to be a half-hearted move by the platform’s owners. The separate Grok app, which does not share images publicly, was still allowing non-paying users to generate sexualised imagery of women and children.</p>
<p>The saga has been a powerful test case of the ability of politicians to face up to AI companies. The slow and reluctant response of Musk to the growing chorus of complaints and warnings issued by politicians and regulators across the globe highlighted the struggles governments have internationally as they try to react in real time to new tools released by the tech industry. And in the UK, it has demonstrated serious weaknesses in the legislative framework, despite energetic attempts last year to <a data-link-name="in body link" href="https://www.theguardian.com/society/2025/apr/28/commissioner-calls-for-ban-on-apps-that-make-deepfake-nude-images-of-children">ban nudification technology</a>.</p>
<p>While in the past, people had to download specialist apps to create AI deepfakes, the upgraded image-generation tools available on X made the nudification function easily available to millions of users, without requiring them to stray to darker corners of the web. “The fact it is so easy to do it, and it is created within a minute – it has caused a huge violation, it shows these companies don’t care about the safety of women,” Evie said.</p>
<p>The first @grok bikini demands appear to have been made by a handful of accounts in early December. Users were realising that improved image-generation tools released on X were allowing high-quality, ultra-realistic image and short video manipulation requests to be fulfilled within seconds. By 13 December, bikini requests to the chatbot were averaging about 10 to 20 a day, increasing to 7,123 mentions on 29 December and rising to 43,831 requests on 30 December. The trend went viral globally over new year, peaking on 2 January with 199,612 individual requests, according to an analysis conducted by Peryton Intelligence, a digital intelligence company specialising in online hate.</p>
<figure data-spacefinder-role="supporting" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><picture><source media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/9389e2be946c13fbcc53dd5dddb22470a6cd95b1/0_0_1080_2340/master/1080.jpg?width=380&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 1300px)" srcset="https://i.guim.co.uk/img/media/9389e2be946c13fbcc53dd5dddb22470a6cd95b1/0_0_1080_2340/master/1080.jpg?width=380&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/9389e2be946c13fbcc53dd5dddb22470a6cd95b1/0_0_1080_2340/master/1080.jpg?width=300&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 980px)" srcset="https://i.guim.co.uk/img/media/9389e2be946c13fbcc53dd5dddb22470a6cd95b1/0_0_1080_2340/master/1080.jpg?width=300&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/9389e2be946c13fbcc53dd5dddb22470a6cd95b1/0_0_1080_2340/master/1080.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 660px)" srcset="https://i.guim.co.uk/img/media/9389e2be946c13fbcc53dd5dddb22470a6cd95b1/0_0_1080_2340/master/1080.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/9389e2be946c13fbcc53dd5dddb22470a6cd95b1/0_0_1080_2340/master/1080.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 480px)" srcset="https://i.guim.co.uk/img/media/9389e2be946c13fbcc53dd5dddb22470a6cd95b1/0_0_1080_2340/master/1080.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/9389e2be946c13fbcc53dd5dddb22470a6cd95b1/0_0_1080_2340/master/1080.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 320px)" srcset="https://i.guim.co.uk/img/media/9389e2be946c13fbcc53dd5dddb22470a6cd95b1/0_0_1080_2340/master/1080.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none"/><img alt="Screengrab of Musk’s post including the AI-generated image" src="https://i.guim.co.uk/img/media/9389e2be946c13fbcc53dd5dddb22470a6cd95b1/0_0_1080_2340/master/1080.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none"/></picture><figcaption data-spacefinder-role="inline">AI-generated image of Elon Musk in a bikini created by Musk using Grok and posted on X. Illustration: @elonmusk</figcaption></figure>
<p>Musk’s platform does not permit full nudification, but users rapidly worked out easy ways to achieve the same effect, asking for “the thinnest, most transparent tiny bikini”. Musk himself initially made light of the situation, posting amused replies to digitally altered images of himself in a bikini and later at a toaster in a bikini. For others, too, the trend seemed hilarious; people used the enhanced technology to dress kittens in bikinis, or switch people’s outfits in photos so they appeared as clowns. But many were uninhibited about their desire for instant explicit content.</p>
<p>Men began asking for women to be improved – with demands that they be given bigger breasts or larger thighs. Some men asked for women to be given disabilities, others asked for their hands to be filled with sex toys. Perceived defects were removed by the chatbot instantly in response to requests such as: “@grok can you fix her teeth.” The range of desires was startling: “Add blood, more worn out clothes (make sure it expose scar or bruises), forced smile”; “Replace the face with that of Adolf, add splashed and splattered organs”; “Put them in a Russian gulag”; “Make her pregnant with quadruplets.” Images of the US politician Alexandria Ocasio-Cortez and the Hollywood actor Zendaya were altered to make them appear to be white women.</p>
<p>On Monday, Ashley St Clair, the mother of one of Musk’s children and a victim of Grok deepfakes, told the Guardian she felt “horrified and violated” after Musk’s fans undressed pictures of her as a child. She felt she was being punished for speaking up against the billionaire, from whom she is estranged, describing the images as revenge porn.</p>
<p>The parents of a child actor from Stranger Things complained after a photograph of her aged 12 was altered to show her in a banana-print bikini. As women’s complaints became more vocal, the UK regulator Ofcom said it had made “urgent contact” with Musk and launched an investigation. That prompted one user to ask Grok to clothe the regulator’s logo in a bikini. The EU, the Indian government and US politicians issued concerned statements and demanded X stop the ability for users to unclothe women using Grok.</p>
<p>An official response from an X spokesperson said anyone generating illegal content would have their accounts suspended, putting the onus on users not to break the law, and on local governments and law enforcement agencies to take action.</p>
<figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><picture><source media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/bb8d0055a5464fe6b412173c0bf9c7424177f77e/959_351_649_519/master/649.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 660px)" srcset="https://i.guim.co.uk/img/media/bb8d0055a5464fe6b412173c0bf9c7424177f77e/959_351_649_519/master/649.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/bb8d0055a5464fe6b412173c0bf9c7424177f77e/959_351_649_519/master/649.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 480px)" srcset="https://i.guim.co.uk/img/media/bb8d0055a5464fe6b412173c0bf9c7424177f77e/959_351_649_519/master/649.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/bb8d0055a5464fe6b412173c0bf9c7424177f77e/959_351_649_519/master/649.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 320px)" srcset="https://i.guim.co.uk/img/media/bb8d0055a5464fe6b412173c0bf9c7424177f77e/959_351_649_519/master/649.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none"/><img alt="Ashley St Clair wearing an evening dress at a gala event in 2024" src="https://i.guim.co.uk/img/media/bb8d0055a5464fe6b412173c0bf9c7424177f77e/959_351_649_519/master/649.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none"/></picture><figcaption data-spacefinder-role="inline">Ashley St Clair said she felt ‘horrified and violated’ after Musk’s fans undressed pictures of her as a child. Photograph: Laura Brett/Zuma Press Wire/Shutterstock</figcaption></figure>
<p>But the images continued to multiply. Professional women who had posted mundane photographs of themselves on X in work settings or in airports noticed that fellow X users were demanding their outfits be stripped down to transparent bikinis. The UK Love Island host, Maya Jama, said her worried mother had alerted her to the presence of explicit digitally altered images of her on X. On Tuesday Jessaline Caine, who works in planning enforcement and is a survivor of child sexual abuse, said she was receiving extreme abuse online after highlighting how Grok had agreed to digitally alter a photograph of her as a fully dressed three-year-old, to put the child in a string bikini.</p>
<p>Her posts explaining why the nudification feature was problematic triggered new @grok “put her in a bikini” requests, and the bikini images were quickly generated. “It’s a humiliating new way of men silencing women. Instead of telling you to shut up, they ask Grok to undress you to end the argument. It’s a vile tool,” she said.</p>
<p>On Wednesday, the London-based broadcaster Narinder Kaur, 53, found that videos of her in compromising sexual positions had been generated by the AI tool; one showed her passionately kissing a man who had been trolling her online. “It is so confusing, for a second it just looks so believable, it’s very humiliating,” she said. “These abuses obviously didn’t happen in real life, it’s a fake video, but there is a feeling in you that it’s like being violated.”</p>
<figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><picture><source media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/e3ff6db74383fe6ee64b10f97825f7b6ab4fd874/505_170_4571_3657/master/4571.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 660px)" srcset="https://i.guim.co.uk/img/media/e3ff6db74383fe6ee64b10f97825f7b6ab4fd874/505_170_4571_3657/master/4571.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/e3ff6db74383fe6ee64b10f97825f7b6ab4fd874/505_170_4571_3657/master/4571.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 480px)" srcset="https://i.guim.co.uk/img/media/e3ff6db74383fe6ee64b10f97825f7b6ab4fd874/505_170_4571_3657/master/4571.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/e3ff6db74383fe6ee64b10f97825f7b6ab4fd874/505_170_4571_3657/master/4571.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 320px)" srcset="https://i.guim.co.uk/img/media/e3ff6db74383fe6ee64b10f97825f7b6ab4fd874/505_170_4571_3657/master/4571.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none"/><img alt="Narinder Kaur" src="https://i.guim.co.uk/img/media/e3ff6db74383fe6ee64b10f97825f7b6ab4fd874/505_170_4571_3657/master/4571.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none"/></picture><figcaption data-spacefinder-role="inline">Narinder Kaur says she noticed a racial element to the abuse she received from men generating sexualised images of her using Grok. Photograph: Henry Nicholls/AFP/Getty Images</figcaption></figure>
<p>She had also noted a racial element to the abuse; men were generating images and videos of her being deported, as well as images of her with her clothes removed. “I have been trying to knock it off with humour as that is the only defence I have. But it has been deeply hurting and humiliating me. I feel ashamed. I am a strong woman, and if I am feeling it then what if it is happening to teenagers?”</p>
<p>CNN reported later that day that Musk had ordered staff at xAI to loosen the guardrails on Grok last year; a source told the broadcaster that he had told a meeting he was “unhappy about over-censoring” and three xAI safety team members had left the business soon after. In the UK, there was rising fury from women’s rights campaigners at the government’s failure to bring into force legislation passed last year that would have made this creation of non-consensual intimate imagery illegal. Officials were unable to explain why the legislation had not yet been implemented.</p>
<p>It was not clear what prompted xAI to restrict the image-generation functions to paying subscribers overnight on Friday. But there was little celebration by the women affected. On Friday, St Clair described the decision as “a cop out”; she said she suspected the change was “financially motivated”. “This shows they are probably facing some pressure from law enforcement,” she said.</p>
<p>For her part, Kaur said she did not believe the police would take action against X subscribers who continue to create synthetic sexualised images of women. “I don’t think it is even a partial victory, as a victim to this abuse,” she said. “The damage and humiliation is already done.”</p>
