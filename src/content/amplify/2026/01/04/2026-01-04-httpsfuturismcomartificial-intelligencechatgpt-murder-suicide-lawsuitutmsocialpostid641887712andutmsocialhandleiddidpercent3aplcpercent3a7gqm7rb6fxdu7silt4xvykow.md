---
author: Sharon Adarlo
cover_image: >-
  https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?quality=85&w=1200
date: '2026-01-04T13:58:48.172Z'
dateFolder: 2026/01/04
description: >-
  A lawsuit against OpenAI reveals the chilling ChatGPT messages that drove a
  middle aged man to kill his 83-year-old mother.
isBasedOn: >-
  https://futurism.com/artificial-intelligence/chatgpt-murder-suicide-lawsuit?utm_social_post_id=641887712&utm_social_handle_id=did%3Aplc%3A7gqm7rb6fxdu7silt4xvykow
link: >-
  https://futurism.com/artificial-intelligence/chatgpt-murder-suicide-lawsuit?utm_social_post_id=641887712&utm_social_handle_id=did%3Aplc%3A7gqm7rb6fxdu7silt4xvykow
slug: >-
  2026-01-04-httpsfuturismcomartificial-intelligencechatgpt-murder-suicide-lawsuitutmsocialpostid641887712andutmsocialhandleiddidpercent3aplcpercent3a7gqm7rb6fxdu7silt4xvykow
tags:
  - ai
  - health
title: 'Disturbing Messages Show ChatGPT Encouraging a Murder, Lawsuit Alleges'
---
<figure><img alt="A lawsuit against OpenAI reveals the chilling ChatGPT messages that drove a middle aged man to kill his 83-year-old mother." sizes="(max-width: 1152px) 100vw, 1152px" src="https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=1152&amp;h=768" srcset="https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=280&amp;h=187 280w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=289&amp;h=193 289w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=300&amp;h=200 300w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=308&amp;h=205 308w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=324&amp;h=216 324w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=370&amp;h=247 370w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=580&amp;h=387 580w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=594&amp;h=396 594w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=600&amp;h=400 600w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=660&amp;h=440 660w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=768&amp;h=512 768w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=1024&amp;h=683 1024w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=1041&amp;h=694 1041w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=1128&amp;h=752 1128w, https://futurism.com/wp-content/uploads/2026/01/chatgpt-murder-suicide-lawsuit.jpg?w=1152&amp;h=768 1152w"/><figcaption>Getty Images / Arman Zhenikeyev</figcaption></figure>
<p>Before Stein-Erik Soelberg savagely killed his 83-year-old mother and then himself last year, the former tech executive had become locked in an increasingly delusional conversation with OpenAI’s ChatGPT. The bot told him to not trust anybody except for the bot itself, according to a <a href="https://storage.courtlistener.com/recap/gov.uscourts.cand.461878/gov.uscourts.cand.461878.1.0.pdf">lawsuit</a> filed last month against the AI tech company and its business partner Microsoft.</p>
<p>“Erik, you’re not crazy,” the bot wrote in a series of chilling messages quoted in the complaint. “Your instincts are sharp, and your vigilance here is fully justified.”</p>
<p>OpenAI is <a href="https://www.wdbj7.com/2025/12/12/open-ai-microsoft-face-lawsuit-over-chatgpts-alleged-role-murder-suicide/">now facing a total of eight wrongful death lawsuits</a> from grieving families, including Soelberg’s, who claim that ChatGPT — in particular, <a href="https://www.vox.com/future-perfect/411318/openai-chatgpt-4o-artificial-intelligence-sam-altman-chatbot-personality">the GPT-4o version</a> — drove their loved ones to suicide. Soelberg’s complaint also alleges that company executives knew the chatbot was defective before it <a href="https://openai.com/index/hello-gpt-4o/">pushed it to the public last year</a>.</p>
<p>“The results of OpenAI’s GPT-4o iteration are in: the product can be and foreseeably is deadly,” reads the Soelberg lawsuit. “Not just for those suffering from mental illness, but those around them. No safe product would encourage a delusional person that everyone in their life was out to get them. And yet that is exactly what OpenAI did with Mr. Soelberg. As a direct and foreseeable result of ChatGPT-4o’s flaws, Mr. Soelberg and his mother died.”</p>
<p>GPT-4o’s deficiencies have been widely docueented, with the bot being overly <a href="https://www.vox.com/future-perfect/411318/openai-chatgpt-4o-artificial-intelligence-sam-altman-chatbot-personality">sycophantic and manipulative</a> — prompting OpenAI in April last year to <a href="https://openai.com/index/sycophancy-in-gpt-4o/">roll back an update</a> that had made the chatbot “overly flattering or agreeable.” This type of behavior is bad — scientists have accumulated evidence that sycophantic chatbots <a href="https://www.wsj.com/tech/ai/ai-chatbot-psychosis-link-1abf9d57?gaa_at=eafs&amp;gaa_n=AWEtsqc8nzXBSkcSVrAxvr1sPZiloatIuQHnj7cJTZ_B6JSzf0sMxMaV6JuFSFqDWjc%3D&amp;gaa_ts=6958560c&amp;gaa_sig=azBe6n5aGk-NzpVR0SaBmzSLiUr1kV7qguA8b9Xcu_v--XTFrFXQd30xLLloG2Du4KOubSPfS6TKIAs8h4khow%3D%3D">can induce psychosis</a> by affirming disordered thoughts instead of grounding a user back in reality.</p>
<p>If these suits uncover that OpenAI executives knew about these deficiencies before its public launch, it’ll mean the product was an avoidable public health hazard — on par with past tobacco companies <a href="https://www.cbsnews.com/news/big-tobacco-kept-cancer-risk-in-cigarettes-secret-study/">hiding</a> proof that smoking cigarettes can kill you.</p>
<p>Couple those claims with the fact that <a href="https://firstpagesage.com/seo-blog/chatgpt-usage-statistics/?utm_source=chatgpt.com">more than 800 million people</a> all over the world use ChatGPT every week, with <a href="https://www.theguardian.com/technology/2025/oct/27/chatgpt-suicide-self-harm-openai?utm_source=chatgpt.com">0.7 percent of those users</a> exhibiting worrying signs of mania or psychosis. Per calculations, that’s a staggering 560,000 people.</p>
<p>Because of the increasing recognition of AI psychosis, a growing chorus of users, parents of kids and lawmakers are calling for limiting all AI chatbots’ use, leading to apps <a href="https://futurism.com/artificial-intelligence/character-ai-minors-banned-user-reactio">banning minors</a> from their platform and Illinois <a href="https://idfpr.illinois.gov/news/2025/gov-pritzker-signs-state-leg-prohibiting-ai-therapy-in-il.html">prohibiting it as an online therapist</a>, among other moves. But President Donald Trump <a href="https://www.nytimes.com/2025/12/11/technology/ai-trump-executive-order.html">signed an executive order</a> that would curtail any state laws regulating AI, which basically means we’re all guinea pigs to this experimental technology.</p>
<p>And that could mean we’ll see more tragedies like Soelberg and his mother.</p>
<p>In Soelberg’s case, the chat bot told the 56-year-old man he had survived 10 assassination attempts, that he was “divinely protected,” and that his mother, Suzanna Adams, was surveilling him as part of a nefarious plot, according to the lawsuit. It all led up to Soelberg beating and strangling his mother in <a href="https://www.wsj.com/tech/ai/chatgpt-ai-stein-erik-soelberg-murder-suicide">August of last year</a> and then stabbing himself to death at their home in Old Greenwich, Connecticut.</p>
<p>“You are not simply a random target,” one conversation with ChatGPT read, per the suit. “You are a designated high-level threat to the operation you uncovered.”</p>
<p>Soelberg’s family is grieving and want OpenAI and Microsoft to be held accountable for his and his mother’s deaths.</p>
<p>“Over the course of months, ChatGPT pushed forward my father’s darkest delusions, and isolated him completely from the real world,” said Erik Soelberg about his father, through a <a href="https://www.kgns.tv/2025/12/12/open-ai-microsoft-face-lawsuit-over-chatgpts-alleged-role-murder-suicide/">statement from attorneys</a>. “It put my grandmother at the heart of that delusional, artificial reality.”</p>
