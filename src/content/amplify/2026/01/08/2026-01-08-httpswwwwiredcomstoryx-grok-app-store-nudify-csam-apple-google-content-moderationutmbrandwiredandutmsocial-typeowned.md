---
author: Caroline Haskins
cover_image: >-
  https://media.wired.com/photos/695e9565aa101b3c7113f21a/191:100/w_1280,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg
date: '2026-01-08T23:32:12.053Z'
dateFolder: 2026/01/08
description: >-
  Elon Musk’s chatbot has been used to generate thousands of sexualized images
  of adults and apparent minors. Apple and Google have removed other “nudify”
  apps—but continue to host X and Grok.
isBasedOn: >-
  https://www.wired.com/story/x-grok-app-store-nudify-csam-apple-google-content-moderation/?utm_brand=wired&utm_social-type=owned
link: >-
  https://www.wired.com/story/x-grok-app-store-nudify-csam-apple-google-content-moderation/?utm_brand=wired&utm_social-type=owned
slug: >-
  2026-01-08-httpswwwwiredcomstoryx-grok-app-store-nudify-csam-apple-google-content-moderationutmbrandwiredandutmsocial-typeowned
tags:
  - ai
  - tech
  - politics
title: Why Are Grok and X Still Available in App Stores?
---
<p>Elon Musk’s chatbot has been used to generate thousands of sexualized images of adults and apparent minors. Apple and Google have removed other “nudify” apps—but continue to host X and Grok.</p>
<figure><picture><source media="(max-width: 767px)" sizes="100vw" srcset="https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_120,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 120w, https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_240,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 240w, https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_320,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 320w, https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_640,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 640w, https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_960,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 960w"/><source media="(min-width: 768px)" sizes="100vw" srcset="https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_120,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 120w, https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_240,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 240w, https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_320,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 320w, https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_640,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 640w, https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_960,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 960w, https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_1280,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 1280w, https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_1600,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 1600w, https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_1920,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 1920w, https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_2240,c_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg 2240w"/><figure><img alt="BATH UNITED KINGDOM  JANUARY 07 In this photo illustration a iPhone screen displaying the Grok app and logo is seen on..." data-src="https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_2560%2Cc_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg" src="https://media.wired.com/photos/695e9565aa101b3c7113f21a/master/w_2560%2Cc_limit/How-Is-X-Still-in-App-Store-Business-2255064607.jpg"/></figure></picture></figure>
<p>Photograph: Anna Barclay/Getty Images</p>
<p>Elon Musk’s AI chatbot Grok is <a href="https://www.wired.com/story/grok-is-generating-sexual-content-far-more-graphic-than-whats-on-x/">being used</a> to flood X with <a href="https://www.wired.com/story/grok-is-pushing-ai-undressing-mainstream/">thousands</a> of sexualized images of adults and apparent minors wearing minimal clothing. Some of this content appears to not only violate X’s own <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://help.x.com/en/rules-and-policies/twitter-rules"}' data-offer-url="https://help.x.com/en/rules-and-policies/twitter-rules" href="https://help.x.com/en/rules-and-policies/twitter-rules">policies</a>, which prohibit sharing illegal content such as child sexual abuse material (CSAM), but may also violate the guidelines of Apple’s App Store and the Google Play store.</p>
<p>Apple and Google both explicitly ban apps containing CSAM, which is illegal to host and distribute in many countries. The tech giants also forbid apps that contain pornographic material or facilitate harassment. The Apple App Store <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://developer.apple.com/app-store/review/guidelines/"}' data-offer-url="https://developer.apple.com/app-store/review/guidelines/" href="https://developer.apple.com/app-store/review/guidelines/">says</a> it doesn’t allow “overtly sexual or pornographic material,” as well as “defamatory, discriminatory, or mean-spirited content,” especially if the app is “likely to humiliate, intimidate, or harm a targeted individual or group.” The Google Play store <a href="https://support.google.com/googleplay/android-developer/answer/9878810?hl=en&amp;ref_topic=9877466&amp;sjid=1253303111790657994-NC">bans</a> apps that “contain or promote content associated with sexually predatory behavior, or distribute non-consensual sexual content,” and well as programs that “contain or facilitate threats, harassment, or bullying.”</p>
<p>Over the past two years, Apple and Google removed a number of “nudify” and AI image-generation apps after <a href="https://www.bbc.com/news/videos/cx205lnplpwo">investigations</a> by the BBC and 404 Media found <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://www.404media.co/instagram-advertises-nonconsensual-ai-nude-apps/"}' data-offer-url="https://www.404media.co/instagram-advertises-nonconsensual-ai-nude-apps/" href="https://www.404media.co/instagram-advertises-nonconsensual-ai-nude-apps/">they were being advertised</a> or used to effectively turn ordinary photos into explicit images of women without their consent.</p>
<p>But at the time of publication, both the X app and the <a href="https://www.wired.com/story/grok-is-generating-sexual-content-far-more-graphic-than-whats-on-x/">standalone Grok app</a> remain available in both app stores. Apple, Google, and X did not respond to requests for comment. Grok is operated by Musk’s multibillion-dollar artificial intelligence startup xAI, which also did not respond to questions from WIRED. In a <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://x.com/Safety/status/2007648212421587223?s=20"}' data-offer-url="https://x.com/Safety/status/2007648212421587223?s=20" href="https://x.com/Safety/status/2007648212421587223?s=20">public statement</a> published on January 3, X said that it takes action against illegal content on its platform, including CSAM. “Anyone using or prompting Grok to make illegal content will suffer the same consequences as if they upload illegal content,” the company warned.</p>
<p>Sloan Thompson, the director of training and education at EndTAB, a group that teaches organizations how to prevent the spread of nonconsensual sexual content, says it is “absolutely appropriate” for companies like Apple and Google to take action against X and Grok.</p>
<p>The amount of nonconsensual explicit images on X generated by Grok has exploded over the past two weeks. One <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://www.bloomberg.com/news/articles/2026-01-07/musk-s-grok-ai-generated-thousands-of-undressed-images-per-hour-on-x?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTc2Nzc5MDk4NywiZXhwIjoxNzY4Mzk1Nzg3LCJhcnRpY2xlSWQiOiJUOEhRS0hLR0lGUE8wMCIsImJjb25uZWN0SWQiOiJGRUIzODlCNUI2ODI0RTY0QjY5MENEODE1RTBDREZGRCJ9.3B4JWnmqmXFC3DOqhs11h99g5gNzi4j_poKAHLuWdrY&amp;leadSource=uverify%20wall"}' data-offer-url="https://www.bloomberg.com/news/articles/2026-01-07/musk-s-grok-ai-generated-thousands-of-undressed-images-per-hour-on-x?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTc2Nzc5MDk4NywiZXhwIjoxNzY4Mzk1Nzg3LCJhcnRpY2xlSWQiOiJUOEhRS0hLR0lGUE8wMCIsImJjb25uZWN0SWQiOiJGRUIzODlCNUI2ODI0RTY0QjY5MENEODE1RTBDREZGRCJ9.3B4JWnmqmXFC3DOqhs11h99g5gNzi4j_poKAHLuWdrY&amp;leadSource=uverify%20wall" href="https://www.bloomberg.com/news/articles/2026-01-07/musk-s-grok-ai-generated-thousands-of-undressed-images-per-hour-on-x?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTc2Nzc5MDk4NywiZXhwIjoxNzY4Mzk1Nzg3LCJhcnRpY2xlSWQiOiJUOEhRS0hLR0lGUE8wMCIsImJjb25uZWN0SWQiOiJGRUIzODlCNUI2ODI0RTY0QjY5MENEODE1RTBDREZGRCJ9.3B4JWnmqmXFC3DOqhs11h99g5gNzi4j_poKAHLuWdrY&amp;leadSource=uverify%20wall">researcher</a> told Bloomberg that over a 24-hour period between January 5 and 6, Grok was producing roughly 6,700 images every hour they identified as “sexually suggestive or nudifying.” Another analyst collected more than 15,000 URLs of images that Grok created on X during a two-hour period on December 31. WIRED <a href="https://www.wired.com/story/grok-is-pushing-ai-undressing-mainstream/">reviewed</a> approximately one-third of the images, and found that many of them featured women dressed in revealing clothing. Over 2,500 were marked as no longer available within a week, while almost 500 were labeled as "age-restricted adult content."</p>
<p>Earlier this week, a spokesperson for the European Commission, the governing body of the European Union, <a href="https://www.reuters.com/business/media-telecom/britain-demands-elon-musks-grok-answers-concerns-about-sexualised-photos-2026-01-05/?">publicly condemned</a> the sexually explicit and non-consensual images being generated by Grok on X as “illegal” and “appalling,” telling Reuters that such content “has no place in Europe.”</p>
<p>On Thursday, the EU <a href="https://www.reuters.com/world/eu-commission-has-ordered-x-retain-all-grok-documents-until-end-2026-2026-01-08/">ordered X</a> to retain all internal documents and data relating to Grok until the end of 2026, extending a prior retention directive, to ensure authorities can access materials relevant to compliance with the EU’s Digital Services Act, though a new formal investigation has yet to be announced. Regulators in <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://www.cnbc.com/2026/01/05/india-eu-investigate-musks-x-after-grok-created-deepfake-child-porn.html"}' data-offer-url="https://www.cnbc.com/2026/01/05/india-eu-investigate-musks-x-after-grok-created-deepfake-child-porn.html" href="https://www.cnbc.com/2026/01/05/india-eu-investigate-musks-x-after-grok-created-deepfake-child-porn.html">other countries</a>, including the UK, India, and Malaysia have also said <a href="https://www.bbc.com/news/articles/c5y5w0k99r1o">they are</a> investigating the social media platform.</p>
<p>Grok and X are part of a <a href="https://www.wired.com/story/ai-nudify-websites-are-raking-in-millions-of-dollars/">multimillion dollar industry</a> peddling “nudify” services online. Over the past few years, dozens of standalone apps and websites have popped that promise to digitally strip women without their consent, often marketing themselves as harmless novelty tools while enabling image-based sexual abuse. Mainstream AI companies have also struggled to prevent their tools from being used to generate nonconsensual sexualized imagery. For example, WIRED <a href="https://www.wired.com/story/google-and-openais-chatbots-can-strip-women-in-photos-down-to-bikinis/">reported</a> last month that people were sharing tips online about how to get Google and OpenAI’s generative AI chatbots, Gemini and ChatGPT, to alter pictures of women to depict them wearing bikinis and other revealing clothing.</p>
<p>Lawmakers in the US and other countries have begun cracking down on nonconsensual AI deepfakes. Last year, President Donald Trump signed the TAKE IT DOWN Act, which makes it a federal crime to knowingly publish or host nonconsensual sexual images. But Thomspon says the law is limited by the fact that companies are only required to begin the removal process after a victim chooses to come forward.</p>
<p>“Private companies have a lot more agency in responding to things quickly,” Thompson says. “When we talk about other tools for addressing image based abuse—lawsuits take time, and it takes time for laws to be passed, and especially right now, when we have technologies that are hitting the market at a breakneck pace, and it's very, very difficult for laws to be passed at the same pace.”</p>
<p>David Greene, a civil liberties director at the <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://www.eff.org/"}' data-offer-url="https://www.eff.org/" href="https://www.eff.org/">Electronic Frontier Foundation</a>, says people should be cautious about the idea of removing entire platforms from app stores. He emphasizes that X and xAI both have the power to combat this problem themselves.</p>
<p>Greene argues that Musk’s companies could put in place better technical safeguards to deter users from creating deepfakes and other kinds of sexualized imagery. They “might not be a perfect fix, but might at least add some friction to the process,” he adds</p>
<p>Thompson agrees that companies like X and xAI should be subject to more public pressure to prevent these sorts of photos and videos from being created in the first place. “That's where I think we need intervention,” she says.</p>
