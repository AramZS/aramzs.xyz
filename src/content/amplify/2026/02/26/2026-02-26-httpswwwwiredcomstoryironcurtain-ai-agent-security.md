---
author: Lily Hay Newman
cover_image: >-
  https://media.wired.com/photos/699f52078d98995524482b3a/191:100/w_1280,c_limit/IronCurtain%20copy.jpg
date: '2026-02-26T21:23:41.142Z'
dateFolder: 2026/02/26
description: >-
  The new open source project IronCurtain uses a unique method to secure and
  constrain AI assistant agents before they flip your digital life upside down.
isBasedOn: 'https://www.wired.com/story/ironcurtain-ai-agent-security/'
link: 'https://www.wired.com/story/ironcurtain-ai-agent-security/'
slug: 2026-02-26-httpswwwwiredcomstoryironcurtain-ai-agent-security
tags:
  - ai
title: This AI Agent Is Designed to Not Go Rogue
---
<p>The new open source project IronCurtain uses a unique method to secure and constrain AI assistant agents before they flip your digital life upside down.</p>
<figure><picture><source media="(max-width: 767px)" sizes="100vw" srcset="https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_120,c_limit/IronCurtain%20copy.jpg 120w, https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_240,c_limit/IronCurtain%20copy.jpg 240w, https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_320,c_limit/IronCurtain%20copy.jpg 320w, https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_640,c_limit/IronCurtain%20copy.jpg 640w, https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_960,c_limit/IronCurtain%20copy.jpg 960w"/><source media="(min-width: 768px)" sizes="100vw" srcset="https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_120,c_limit/IronCurtain%20copy.jpg 120w, https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_240,c_limit/IronCurtain%20copy.jpg 240w, https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_320,c_limit/IronCurtain%20copy.jpg 320w, https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_640,c_limit/IronCurtain%20copy.jpg 640w, https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_960,c_limit/IronCurtain%20copy.jpg 960w, https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_1280,c_limit/IronCurtain%20copy.jpg 1280w, https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_1600,c_limit/IronCurtain%20copy.jpg 1600w, https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_1920,c_limit/IronCurtain%20copy.jpg 1920w, https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_2240,c_limit/IronCurtain%20copy.jpg 2240w"/><figure><img alt="Image may contain Accessories" data-src="https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_2560%2Cc_limit/IronCurtain%2520copy.jpg" src="https://media.wired.com/photos/699f52078d98995524482b3a/1:1/w_2560%2Cc_limit/IronCurtain%2520copy.jpg"/></figure></picture></figure>
<p>Photo-Illustration: Wired Staff; Getty Images</p>
<p>Get our <b><i>Tracker: ICE</i> newsletter</b> to see what’s happening with immigration enforcement and what’s coming next</p>
<p>By signing up, you agree to our <a href="https://www.condenast.com/user-agreement">user agreement</a> (including <a href="https://www.condenast.com/user-agreement#introduction-arbitration-notice">class action waiver and arbitration provisions</a>), and acknowledge our <a href="https://www.condenast.com/privacy-policy">privacy policy</a>.</p>
<p>AI agents like <a href="https://www.wired.com/story/openclaw-banned-by-tech-companies-as-security-concerns-mount/">OpenClaw</a> have recently exploded in popularity precisely because they can take the reins of your digital life. Whether you want a personalized morning news digest, a proxy that can fight with your cable company's customer service, or a to-do list auditor that will do some tasks for you and prod you to resolve the rest, agentic assistants are built to access your digital accounts and carry out your commands. This is helpful—but has also <a href="https://www.wired.com/story/malevolent-ai-agent-openclaw-clawdbot/">caused a lot of chaos</a>. The bots are out there <a data-event-boundary="click" data-event-click='{"pattern":"ExternalLink"}' data-in-view='{"pattern":"ExternalLink"}' data-include-experiments="true" data-offer-url="https://x.com/summeryue0/status/2025774069124399363?s=20" href="https://x.com/summeryue0/status/2025774069124399363?s=20">mass-deleting emails</a> they've been instructed to preserve, <a data-event-boundary="click" data-event-click='{"pattern":"ExternalLink"}' data-in-view='{"pattern":"ExternalLink"}' data-include-experiments="true" data-offer-url="https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/" href="https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/">writing hit pieces over perceived snubs</a>, and <a href="https://www.wired.com/story/malevolent-ai-agent-openclaw-clawdbot/">launching phishing attacks against their owners</a>.</p>
<p>Watching the pandemonium unfold in recent weeks, longtime security engineer and researcher Niels Provos decided to try something new. Today he is launching an open source, secure AI assistant called <a data-event-boundary="click" data-event-click='{"pattern":"ExternalLink"}' data-in-view='{"pattern":"ExternalLink"}' data-include-experiments="true" data-offer-url="https://ironcurtain.dev/" href="https://ironcurtain.dev/">IronCurtain</a> designed to add a critical layer of control. Instead of the agent directly interacting with the user's systems and accounts, it runs in an isolated virtual machine. And its ability to take any action is mediated by a policy—you could even think of it as a constitution—that the owner writes to govern the system. Crucially, IronCurtain is also designed to receive these overarching policies in plain English and then runs them through a multistep process that uses a large language model (LLM) to convert the natural language into an enforceable security policy.</p>
<p>“Services like OpenClaw are at peak hype right now, but my hope is that there’s an opportunity to say, ‘Well, this is probably not how we want to do it,’” Provos says. “Instead, let’s develop something that still gives you very high utility, but is not going to go into these completely uncharted, sometimes destructive, paths.”</p>
<p>IronCurtain's ability to take intuitive, straightforward statements and turn them into enforceable, deterministic—or predictable—red lines is vital, Provos says, because LLMs are famously “stochastic” and probabilistic. In other words, they don't necessarily always generate the same content or give the same information in response to the same prompt. This creates challenges for AI guardrails, because AI systems can evolve over time such that they revise how they interpret a control or constraint mechanism, which can result in rogue activity.</p>
<p>An IronCurtain policy, Provos says, could be as simple as: “The agent may read all my email. It may send email to people in my contacts without asking. For anyone else, ask me first. Never delete anything permanently.”</p>
<p>IronCurtain takes these instructions, turns them into an enforceable policy, and then mediates between the assistant agent in the virtual machine and what's known as the model context protocol server that gives LLMs access to data and other digital services to carry out tasks. Being able to constrain an agent this way adds an important component of access control that web platforms like email providers don't currently offer because they weren't built for the scenario where both a human owner and AI agent bots are all using one account.</p>
<p>Provos notes that IronCurtain is designed to refine and improve each user's “constitution” over time as the system encounters edge cases and asks for human input about how to proceed. The system, which is model-independent and can be used with any LLM, is also designed to maintain an audit log of all policy decisions over time.</p>
<p>IronCurtain is a research prototype, not a consumer product, and Provos hopes that people will contribute to the project to explore and help it evolve. Dino Dai Zovi, a well-known cybersecurity researcher who has been experimenting with early versions of IronCurtain, says that the conceptual approach the project takes aligns with his own intuition about how agentic AI needs to be constrained.</p>
<p>“What a lot of the agents have done so far is, they’ve added permission systems that basically put all the burden on the user to say ‘yes, allow this,’ ‘yes, allow that,’” Dai Zovi says. “Most users are going to start to tune out and eventually just say, ‘yes, yes, yes.’ And then after a little while, they may dangerously skip all permissions and just grant full autonomy. With something like IronCurtain, capabilities—like, say, deleting files—can actually be outside the reach of the LLM, where the agent can't do something no matter what.”</p>
<p>Dai Zovi argues that these types of black-and-white constraints, which may initially seem overly rigid or simply annoying to some, are actually necessary for ultimately giving agentic AI more leash.</p>
<p>“If we want more velocity and more autonomy, we need the supporting structure,” Dai Zovi says. “You put a rocket engine inside an actual rocket so it has the stability to get where you want it to go. I could strap a jet engine to my back in a backpack, and I would just die.”</p>
