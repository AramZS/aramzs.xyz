---
author: Disconnect
cover_image: 'https://disconnect.blog/content/images/size/w1200/2026/02/altman-india.png'
date: '2026-02-24T23:01:23.377Z'
dateFolder: 2026/02/24
description: OpenAI CEO downgrades humanity in pursuit of goal to merge with computers
isBasedOn: 'https://disconnect.blog/sam-altmans-anti-human-worldview/'
link: 'https://disconnect.blog/sam-altmans-anti-human-worldview/'
slug: 2026-02-24-httpsdisconnectblogsam-altmans-anti-human-worldview
tags:
  - ai
  - tech
title: Sam Altman’s anti-human worldview
---
<p>OpenAI CEO downgrades humanity in pursuit of goal to merge with computers</p>
<p><a href="https://disconnect.blog/author/parismarx/"> <figure><picture>  <figure><img alt="Paris Marx" sizes="300px" src="https://www.gravatar.com/avatar/cbf412e93682e4f72f6b73d8c058c9ee?s=250&amp;r=x&amp;d=mp" srcset="https://www.gravatar.com/avatar/cbf412e93682e4f72f6b73d8c058c9ee?s=250&amp;r=x&amp;d=mp 300w"/></figure> </picture></figure> </a></p>
<p>by <a href="https://disconnect.blog/author/parismarx/">Paris Marx</a></p>
<p>February 23, 2026 ∙ 9 min read</p>
<p><a href="https://x.com/intent/tweet?text=Sam%20Altman%E2%80%99s%20anti-human%20worldview&amp;url=https://disconnect.blog/sam-altmans-anti-human-worldview/"><figure></figure></a> <a href="https://www.facebook.com/sharer/sharer.php?u=https://disconnect.blog/sam-altmans-anti-human-worldview/"><figure></figure></a> <a href="https://www.linkedin.com/shareArticle?mini=true&amp;title=Sam%20Altman%E2%80%99s%20anti-human%20worldview&amp;url=https://disconnect.blog/sam-altmans-anti-human-worldview/"><figure></figure></a></p>
<figure><p> </p><picture>  <img alt="Sam Altman holding a microphone with ferns in the background" sizes="(max-width:480px) 300px, (max-width:768px) 600px, (max-width:1024px) 1200px, 2000px" src="https://disconnect.blog/content/images/size/w2000/2026/02/altman-india.png" srcset="https://disconnect.blog/content/images/size/w300/2026/02/altman-india.png 300w,"/> </picture><p> </p><figcaption>Sam Altman speaking to <i><em>The Indian Express</em></i>. Screenshot: YouTube/<a href="https://www.youtube.com/watch?v=qH7thwrCluM">The Indian Express</a></figcaption></figure>
<p>Written by <a href="https://disconnect.blog/author/parismarx/"> <figure><picture>  <figure><img alt="" sizes="300px" src="https://www.gravatar.com/avatar/cbf412e93682e4f72f6b73d8c058c9ee?s=250&amp;r=x&amp;d=mp" srcset="https://www.gravatar.com/avatar/cbf412e93682e4f72f6b73d8c058c9ee?s=250&amp;r=x&amp;d=mp 300w"/></figure> </picture></figure> <h3>Paris Marx</h3> <p>Paris Marx is a Canadian tech critic and host of the award-winning Tech Won’t Save Us podcast. He writes the Disconnect newsletter and is the author of Road to Nowhere: What Silicon Valley Gets Wrong about the Future of Transportation.</p> </a></p>
<p>Editor’s Choice <a href="https://disconnect.blog/getting-off-us-tech-a-guide/"> <figure><picture>  <figure><img alt="" sizes="300px" src="https://disconnect.blog/content/images/size/w300/2025/08/fc13303f-7ff5-4ba8-861b-4dbfc452ce29_2400x1350-2.png" srcset="https://disconnect.blog/content/images/size/w300/2025/08/fc13303f-7ff5-4ba8-861b-4dbfc452ce29_2400x1350-2.png 300w"/></figure> </picture></figure> <h3>Getting off US tech: a guide</h3> </a> <a href="https://disconnect.blog/social-media-must-be-reined-in/"> <figure><picture>  <figure><img alt="" sizes="300px" src="https://disconnect.blog/content/images/size/w300/2025/08/60542878-9ac8-45c3-9367-250e51f9d44f_2400x1350-2.png" srcset="https://disconnect.blog/content/images/size/w300/2025/08/60542878-9ac8-45c3-9367-250e51f9d44f_2400x1350-2.png 300w"/></figure> </picture></figure> <h3>Social media must be reined in</h3> </a> <a href="https://disconnect.blog/how-i-became-a-tech-critic/"> <figure><picture>  <figure><img alt="" sizes="300px" src="https://disconnect.blog/content/images/size/w300/2025/08/b3be3c63-9d03-453f-aac6-b9742f3ad127_1200x675-jpeg.jpg" srcset="https://disconnect.blog/content/images/size/w300/2025/08/b3be3c63-9d03-453f-aac6-b9742f3ad127_1200x675-jpeg.jpg 300w"/></figure> </picture></figure> <h3>How I became a tech critic</h3> </a></p>
<p>Newsletter</p>
<h3>Get all the latest posts delivered straight to your inbox.</h3>
<p>  Subscribe </p>
<p>Processing your application Please check your inbox and click the link to confirm your subscription. There was an error sending the email</p>
<p>The list of reasons to want OpenAI banished from the face of this planet and to see Sam Altman behind bars for the rest of his life is longer than I could possibly list in a single article. The generative AI hype wave he kicked off in late 2022 has not delivered on the promises he made, but has delivered a slew of social harms he hadn’t anticipated.</p>
<p>Over the past few years, we’ve seen it become far easier for misogynists and pedophiles to churn out sexually explicit images of <a href="https://www.nytimes.com/2026/01/22/technology/grok-x-ai-elon-musk-deepfakes.html?ref=disconnect.blog">women</a> and <a href="https://www.techpolicy.press/minors-are-on-the-frontlines-of-the-sexual-deepfake-epidemic-heres-why-thats-a-problem/?ref=disconnect.blog">children</a>. We’ve seen teenagers and adults alike get hooked on chatbots, leading them to have <a href="https://www.ctvnews.ca/canada/article/ontario-man-alleges-chatgpt-caused-delusions-sues-parent-company-openai/?ref=disconnect.blog">mental breakdowns</a>, be <a href="https://futurism.com/commitment-jail-chatgpt-psychosis?ref=disconnect.blog">institutionalized</a>, and even <a href="https://www.npr.org/sections/shots-health-news/2025/09/19/nx-s1-5545749/ai-chatbots-safety-openai-meta-characterai-teens-suicide?ref=disconnect.blog">commit suicide</a>. We’ve seen those who want to want the public question reality and not know what’s real or fake — whether simply for profit-seeking engagement or more nefarious reasons — use chatbots and image generators to push things into overdrive.</p>
<p>In short, it’s been a social disaster. But even with all that said, I was hardly prepared for the contrast between two stories that emerged in recent days; stories that show how deeply irresponsible and anti-human of a world Altman is trying to create, all while his company ignores its social responsibly in cases that could have ultimately saved people’s lives.</p>
<p><a href="https://disconnect.blog/sam-altmans-anti-human-worldview/#/portal/signup"> Become a subscriber </a></p>
<h2>Downgrading humanity</h2>
<p>Altman is used to being challenged on the resource demands of his AI ambitions, and occasionally he lets slip some pretty revealing responses. In early 2024, he declared we would <a href="https://www.bloomberg.com/news/videos/2024-01-16/openai-s-atlman-and-makanju-on-global-implications-of-ai?ref=disconnect.blog">need to geoengineer the planet</a> to mitigate the climate impacts of all the energy needed to allow him and the tech industry to realize their ultimate plans for the widespread adoption of generative AI — and to pursue the holy grail of artificial general intelligence, or AGI. Yet, on stage at an event hosted by <em>The Indian Express</em> on February 20, he gave a much more worrying answer.</p>
<figure><a href="https://disconnect.blog/sam-altmans-self-serving-vision-of-the-future/"><p>Sam Altman’s self-serving vision of the future</p><p>The OpenAI CEO expects the most marginalized to pay the price of his ambition</p><img alt="" src="https://disconnect.blog/content/images/icon/disconnect-logo-80.png"/>DisconnectParis Marx<img alt="" src="https://disconnect.blog/content/images/thumbnail/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2f23d80c2b-61e3-49be-be6c-7d33c59f5bd3_2400x1350-png-1.jpg"/></a></figure>
<p>The OpenAI CEO slammed claims that AI presented a threat to access to fresh water, jumping on a bandwagon that industry boosters <a href="https://undark.org/2025/12/16/ai-data-centers-water/?ref=disconnect.blog">have been riding</a> for some time now. Their argument seeks to obscure the local impacts of data center water use by focusing on figures for the regional and national levels or making comparisons to other water-intensive industries. They certainly don’t want you to recognize that data centers were <a href="https://www.asce.org/publications-and-news/civil-engineering-source/civil-engineering-magazine/issues/magazine-issue/article/2024/03/engineers-often-need-a-lot-of-water-to-keep-data-centers-cool?ref=disconnect.blog">already among the top 10</a> water-consuming industries in the United States well before the AI boom put things into overdrive.</p>
<p>But the real problem with Altman’s response was how he <a href="https://www.youtube.com/watch?v=qH7thwrCluM&amp;ref=disconnect.blog">reframed the question</a>: it wasn’t about how much energy AI used, but how much it used in comparison to humans. Altman does not have these comparative figures at the ready. He admitted as much in his answer. He was constructing a theoretical argument that justified his desire to ignore the impacts of his company and the wider industry. In truth, the figures don’t even matter because he’s engaged in something much more pernicious as he seeks to distract from the impacts of his corporate efforts.</p>
<p>“It takes like 20 years of life and all of the food you eat during that time before you get smart,” Altman asserted, talking about a typical human. “And not only that, it took the very widespread evolution of the 100 billion people that have ever lived and learned not to get eaten by predators and learned how to figure out science and whatever, to produce you.” In short, he’s saying that creating humanity and humans as they now exist required a lot of energy through human history and for each person living today — which means we cannot blame companies like OpenAI for the impacts associated with generative AI and the data centers it requires.</p>
<p>Let’s be clear: this is an absurd line of argument. Altman is seeking to equate AI with humans once again. He’s already tried to sell the public on seeing his chatbots as companions, therapists, and assistants rapidly on their way to human-equivalent levels of cognition, if not there already — assertions that are pure fantasy — and after making those claims, he now wants the resources needed to create AGI to be judged on a human scale too.</p>
<p>There is an undercurrent to the argument that effectively suggests humanity itself needs to be managed if there’s a resource crunch. Human life is downgraded to be equivalent to a machine, and thus has none of the inherent value we tend to associate with it or the qualities that make us uniquely human. There is ample reason to justify the energy use needed to ensure humans live and even thrive — beginning with the fact that we’re actually alive but going as far as to recognize the inherent value of human life that should be preserved and be allowed to flourish. Those qualities do not apply to Altman’s slop-generating machines.</p>
<figure><a href="https://disconnect.blog/why-silicon-valley-is-bringing-eugenics/"><p>Why Silicon Valley is bringing eugenics back</p><p>Elon Musk is the most prominent face of the effort to protect tech’s privilege</p><img alt="" src="https://disconnect.blog/content/images/icon/disconnect-logo-81.png"/>DisconnectParis Marx<img alt="" src="https://disconnect.blog/content/images/thumbnail/https-3a-2f-2fsubstack-post-media-s3-amazonaws-com-2fpublic-2fimages-2f7181b3d1-df2f-414f-8111-548bcf23edf3_896x500-webp.jpg"/></a></figure>
<p>He does not seem to share that same reverence for humanity; his reverence is reserved for the fantastical AGI gods he seems determined to bring into being. This shouldn’t be a surprise. Many of the billionaires at the height of Silicon Valley adhere to <a href="https://aeon.co/essays/why-longtermism-is-the-worlds-most-dangerous-secular-credo?ref=disconnect.blog">an anti-human worldview</a> that not only sees humans merging with machines, but being consumed by them. Altman has <a href="https://www.technologyreview.com/2018/03/13/144721/a-startup-is-pitching-a-mind-uploading-service-that-is-100-percent-fatal/?ref=disconnect.blog">paid to have his brain frozen</a> when he dies, in the hope that it can be uploaded to a computer sometime in the future, and has argued that “<a href="https://blog.samaltman.com/the-merge?ref=disconnect.blog">the merge</a>” — where humans and machines become one — is essential for the future of humanity.</p>
<p>This is all in line with the longtermist worldview, which argues the value of people alive today and people who might live a million years from now are equivalent. If an action today might help ensure billions of people will live in the far future, even if it means harming millions in the present, that is justified under their anti-human calculus. It’s a philosophy that seems to exist purely to justify the science fictional pursuits of tech billionaires while their actions magnify the suffering of billions of actual people. In fact, those future people they envision are not people at all, but “post-humans” who live in vast computer simulations, not as flesh and blood.</p>
<h2>Neglecting responsibility</h2>
<p>Altman’s statements on stage in India would have been bad enough, but they appeared even more heartless and anti-human after a report from the <em>Wall Street Journal</em> the following day. Mass shootings are sadly far too common in the United States these days, but they’re still quite rare in many other countries.</p>
<p>On February 10, Canada suffered one of the worst mass shootings in its history when eight people were killed in Tumbler Ridge, British Columbia, including <a href="https://www.cbc.ca/news/tumbler-ridge-mass-shooting-victims-9.7086903?ref=disconnect.blog">five students and a teacher</a> at a secondary school. After the shooting, OpenAI <a href="https://www.cbc.ca/news/canada/british-columbia/openai-tumbler-ridge-shooter-ban-9.7100497?ref=disconnect.blog">reached out to authorities</a> to provide information about the shooter’s use of ChatGPT and announced it had banned the shooter’s account months earlier.</p>
<p>However, what OpenAI didn’t say, but the <em>Wall Street Journal</em> discovered, was that employees <a href="https://www.wsj.com/us-news/law/openai-employees-raised-alarms-about-canada-shooting-suspect-months-ago-b585df62?ref=disconnect.blog">pushed for the company to reach out</a> to Canadian authorities to alert them to what the person who would later take eight people’s lives was inputing to ChatGPT. The user was flagged through an automated system for suggesting scenarios to the chatbot involving gun violence. “Internally, about a dozen staffers debated whether to take action on [the user’s] posts,” wrote the <em>Journal</em>. “Some employees interpreted [the user’s] writings as an indication of potential real-world violence.”</p>
<p>I’ve seen suggestions online that this presents serious privacy concerns, but I think those people need to check <a href="https://disconnect.blog/reclaiming-sovereignty-in-the-digital-age/">their cyberlibertarian leanings</a>. The companies have been quite open about the fact that chatbot conversations are not fully private, just as people’s search history isn’t. These companies have a duty to the public to identify users trying to use their tools to do harm, just as would be the case in other industries. Simply because something happens online does not mean it exists beyond accountability, and if people don’t want their chatbot conversations flagged, they can simply not use chatbots — or avoid talking to them about committing gun violence or harming people.</p>
<figure><a href="https://disconnect.blog/generative-ai-is-a-societal-disaster/"><p>Generative AI is a societal disaster</p><p>Governments are deluding themselves into believing investment justifies allowing AI to upend society</p><img alt="" src="https://disconnect.blog/content/images/icon/disconnect-logo-82.png"/>DisconnectParis Marx<img alt="" src="https://disconnect.blog/content/images/thumbnail/4832622_5_articlelarge_IMG_2232.jpg"/></a></figure>
<p>There’s no question this was negligence on the part of OpenAI. For a company that has talked so much about AI safety, their leaders are clearly not taking their responsibilities for the present-day impacts to their users and the wider society seriously — in part because safety to them is again associated with fantasy rather than reality. AI safety means to align AI with humanity so a future AGI doesn’t seek to annihilate us (or some sci-fi foolishness like that). It doesn’t mean to stop real harm, as OpenAI could have helped to do in Tumbler Ridge had its leadership listened to employees pushing them to inform police.</p>
<p>We have already seen all the reports about the <a href="https://www.theguardian.com/society/2025/aug/30/therapists-warn-ai-chatbots-mental-health-support?ref=disconnect.blog">negative mental health impacts</a> of chatbot dependence, and ChatGPT even <a href="https://www.nytimes.com/2025/08/26/technology/chatgpt-openai-suicide.html?ref=disconnect.blog">coaching teenagers</a> on how to commit suicide. OpenAI only <a href="https://www.cnbc.com/2025/08/26/openai-plans-chatgpt-changes-after-suicides-lawsuit.html?ref=disconnect.blog">announced changes</a> to ChatGPT on that front after it was sued over a teenager’s death. But the story about the company’s decision not to report a potential shooter to Canadian law enforcement, coming right on the heels of Altman denigrating humanity to the level of machine, was a bit too much for me to handle.</p>
<h2>Believing hype over reality</h2>
<p>As far as I’m concerned, there are two big takeaways here. The first is that OpenAI, Altman, and the generative AI industry more widely needs to start feeling the pressure. They’ve had a pretty easy ride these past three years, as they made big promises, caused hundreds of billions of dollars to flow in their direction, and generated a slew of social harms they haven’t had to properly account for. This technology is being pushed by people who not only disregard human life, but seek to subsume it to computers, and it’s time they’re not only reined in but seriously questioned and held to account for what they’re doing.</p>
<p>But beyond that is to question what our governments are doing by not just welcoming the industry, but often actively pushing generative AI throughout the public sector and into the private sector too. In response to the <em>Journal</em>’s revelations, Canada’s AI minister said he was “deeply disturbed” and <a href="https://www.cbc.ca/news/canada/british-columbia/federal-ai-minister-raises-concerns-over-openai-tumbler-ridge-shooting-9.7101279?ref=disconnect.blog">reached out</a> to OpenAI for answers. But he’s more of an AI evangelist than someone seeking to really understand the impacts of the technologies and take action to rein them in. His response to <a href="https://disconnect.blog/x-shows-why-stricter-tech-regulation-is-necessary/">the recent Grok deepfake scandal</a> was little more than a secular version of “thoughts and prayers.”</p>
<figure><a href="https://disconnect.blog/x-shows-why-stricter-tech-regulation-is-necessary/"><p>X shows why stricter tech regulation is necessary</p><p>We need comprehensive rules on social media far more than age limits</p><img alt="" src="https://disconnect.blog/content/images/icon/disconnect-logo-83.png"/>DisconnectParis Marx<img alt="" src="https://disconnect.blog/content/images/thumbnail/photo-1694878981733-f6637408d729"/></a></figure>
<p>Our governments are actively selling us out to companies that do not have our best interests in mind, based on promises of increased productivity and a flood of investment that are based far more on hype than reality. There are already signals that companies in other parts of the economy are <a href="https://www.apolloacademy.com/ai-adoption-rate-trending-down-for-large-companies/?ref=disconnect.blog">pulling back</a> from AI investment after <a href="https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/?ref=disconnect.blog">not seeing</a> <a href="https://www.theglobeandmail.com/business/article-return-on-generative-ai-investments-survey-2-canadian-businesses/?ref=disconnect.blog">the returns</a>, and that even workers in tech who think they’re becoming more productive thanks to these tools are <a href="https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/?ref=disconnect.blog">deluding themselves</a>.</p>
<p>While chasing the hype, governments are leaving their citizens open to abuse and harms that few other industries would so easily get away with. As Altman and his colleagues make it clearer than ever that they care very little for most of the humans on our planet and in our societies, their word should stop being taken as gospel and the impacts of their companies should be assessed on what they’re doing in the here and now, not what they might do sometime in the far future.</p>
<p><a href="https://disconnect.blog/sam-altmans-anti-human-worldview/#/portal/signup"> Become a subscriber </a></p>
<p><em>Note: I chose not to use the shooter’s name in this piece, hence the references to the person as the shooter or a ChatGPT user.</em></p>
<p><a href="https://x.com/intent/tweet?text=Sam%20Altman%E2%80%99s%20anti-human%20worldview&amp;url=https://disconnect.blog/sam-altmans-anti-human-worldview/"><figure></figure></a> <a href="https://www.facebook.com/sharer/sharer.php?u=https://disconnect.blog/sam-altmans-anti-human-worldview/"><figure></figure></a> <a href="https://www.linkedin.com/shareArticle?mini=true&amp;title=Sam%20Altman%E2%80%99s%20anti-human%20worldview&amp;url=https://disconnect.blog/sam-altmans-anti-human-worldview/"><figure></figure></a> <a data-clipboard-target="#copy-link" href="javascript:"><figure></figure></a> The link has been copied!</p>
