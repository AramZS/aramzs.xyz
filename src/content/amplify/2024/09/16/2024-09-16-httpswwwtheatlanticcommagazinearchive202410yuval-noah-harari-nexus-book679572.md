---
author: Daniel Immerwahr
cover_image: >-
  https://cdn.theatlantic.com/thumbor/HgReYjBMTVGEmMk4SwrkEbe3i80=/288x0:1710x1778/648x810/media/img/2024/09/05/1024_CC_Immerwahr_Harari/original.png
date: '2024-09-17T00:43:41.000Z'
dateFolder: 2024/09/16
description: >-
  Yuval Noah Harari is a famous Israeli historian known for his bestselling book
  "Sapiens," which has sold over 25 million copies. He lives a minimalist
  lifestyle, avoiding smartphones and spending significant time in meditation
  and retreats. Harari is especially admired in Silicon Valley, where
  influential figures like Bill Gates and Mark Zuckerberg promote his ideas.
isBasedOn: >-
  https://www.theatlantic.com/magazine/archive/2024/10/yuval-noah-harari-nexus-book/679572/
link: >-
  https://www.theatlantic.com/magazine/archive/2024/10/yuval-noah-harari-nexus-book/679572/
slug: >-
  2024-09-16-httpswwwtheatlanticcommagazinearchive202410yuval-noah-harari-nexus-book679572
tags:
  - ai
  - tech
title: Yuval Noah Harari’s Apocalyptic Vision
---
<html><body><div>His warning of AI’s dangers is alarming, but does it help us avoid them?</div><figure><img alt="Bald man with glasses near orange horizon line with a series of circled images spiraling out of his head including early man, stone tool, wheat, coins, book, computer chip, and yellow warning triangle with exclamation point" src="https://cdn.theatlantic.com/thumbor/HgReYjBMTVGEmMk4SwrkEbe3i80=/288x0:1710x1778/648x810/media/img/2024/09/05/1024_CC_Immerwahr_Harari/original.png"/><figcaption> (Illustration by Petra Péterffy. Source: Nicolas Maeterlinck / Belga Photo / Alamy.)</figcaption></figure><div><p data-flatplan-paragraph="true"><small><i data-stringify-type="italic">This article was featured in the One Story to Read Today newsletter. </i><i data-stringify-type="italic"><a data-event-element="inline link" data-gtm-vis-first-on-screen31117857_899="217114" data-gtm-vis-has-fired31117857_899="1" data-gtm-vis-recent-on-screen31117857_899="217114" data-gtm-vis-total-visible-time31117857_899="100" data-sk="tooltip_parent" data-stringify-link="https://www.theatlantic.com/newsletters/sign-up/one-story-to-read-today/" delay="150" href="https://www.theatlantic.com/newsletters/sign-up/one-story-to-read-today/" rel="noopener noreferrer" target="_blank">Sign up for it here</a></i><i data-stringify-type="italic">.</i></small></p></div><p>“A<span class="smallcaps">bout 14 billion years ago</span>, matter, energy, time and space came into being.” So begins <i><a data-event-element="inline link" href="https://bookshop.org/a/12476/9780062316110">Sapiens: A Brief History of Humankind</a> </i>(2011), by the Israeli historian Yuval Noah Harari, and so began one of the 21st century’s most astonishing academic careers. <i>Sapiens</i> has sold more than 25<i> </i>million copies in various languages. Since then, Harari has published several other books, which have also sold millions. He now employs some 15 people to organize his affairs and promote his ideas.</p><p>He needs them. Harari might be, after the Dalai Lama, the figure of global renown who is least online. He doesn’t use a smartphone (“I’m <a data-event-element="inline link" href="https://archive.jamesaltucher.com/podcast/yuval-noah-harari/">trying to conserve my time and attention</a>”). He <a data-event-element="inline link" href="https://tim.blog/2020/10/30/yuval-noah-harari-transcript/">meditates for two hours daily</a>. And he spends a month or more each year on retreat, forgoing what one can only presume are staggering speaking fees to sit in silence. Completing the picture, Harari is bald, bespectacled, and largely vegan. The <a data-event-element="inline link" href="https://www.theguardian.com/books/2018/aug/15/21-lessons-for-the-21st-century-by-yuval-noah-harari-review">word <i>guru</i> is sometimes heard</a>.</p><p>Harari’s monastic aura gives him a powerful allure in Silicon Valley, where he is revered. Bill Gates blurbed <i>Sapiens</i>. Mark Zuckerberg promoted it. In 2020, Jeff Bezos testified remotely to Congress in front of a nearly bare set of bookshelves—a disquieting look for the founder of Amazon, the planet’s largest bookseller. Sharp-eyed viewers made out, among the six lonely titles huddling for warmth on the lower-left shelf, <a data-event-element="inline link" href="https://www.nytimes.com/2020/12/11/books/celebrity-bookshelves-anthony-fauci-chris-rock.html">two of Harari’s books</a>. Harari is to the tech CEO what David Foster Wallace once was to the Williamsburg hipster.</p><p><a href="https://www.theatlantic.com/magazine/archive/2024/03/facebook-meta-silicon-valley-politics/677168/">From the March 2024 issue: The rise of techno-authoritarianism</a></p><p>This is a surprising role for someone who started as almost a parody of professorial obscurity. Harari’s first monograph, based on his Oxford doctoral thesis, analyzed the genre characteristics of early modern soldiers’ memoirs. His second considered small-force military operations in medieval Europe—but only the nonaquatic ones. Academia, he felt, was pushing him toward “narrower and narrower questions.”</p><p>What changed Harari’s trajectory was taking up Vipassana meditation and agreeing to teach an introductory world-history course, a hot-potato assignment usually given to junior professors. (I was handed the same task when I joined my department.) The epic scale suited him. His lectures at the Hebrew University of Jerusalem, which formed the basis for <i>Sapiens</i>, told the fascinating tale of how <i>Homo sapiens</i> bested their rivals and swarmed the planet.</p><p>Harari is a deft synthesizer with broad curiosity. Does physical prowess correspond to social status? Why do we find lawns so pleasing? Most scholars are too specialized to even pose such questions. Harari dives right in. He shares with Jared Diamond, Steven Pinker, and Slavoj Žižek a zeal for theorizing widely, though he surpasses them in his taste for provocative simplifications. In medieval Europe, he explains, “Knowledge = Scriptures x Logic,” whereas after the scientific revolution, “Knowledge = Empirical Data x Mathematics.”</p><blockquote>Harari is to the tech CEO what David Foster Wallace once was to the Williamsburg hipster.</blockquote><p>Heady stuff. Of course, there is nothing inherently more edifying about zooming out than zooming in. We learn from brief histories of time and five-volume biographies of Lyndon B. Johnson alike. But Silicon Valley’s recent inventions invite galaxy-brain cogitation of the sort Harari is known for. The larger you feel the disruptions around you to be, the further back you reach for fitting analogies. Stanley Kubrick’s <i>2001: A Space Odyssey</i> famously compared space exploration to apes’ discovery of tools.</p><p><a href="https://www.theatlantic.com/magazine/archive/2018/10/yuval-noah-harari-technology-tyranny/568330/">From the October 2018 issue: Yuval Noah Harari on why technology favors tyranny</a></p><p>Have such technological leaps been good? Harari has doubts. Humans have “produced little that we can be proud of,” he complained in <i>Sapiens</i>. His next books, <a data-event-element="inline link" href="https://bookshop.org/a/12476/9780062464347"><i>Homo Deus: A Brief History of Tomorrow</i></a> (2015) and <a data-event-element="inline link" href="https://bookshop.org/a/12476/9780525512196"><i>21 Lessons for the 21st Century</i></a> (2018), gazed into the future with apprehension. Now Harari has written another since-the-dawn-of-time overview, <a data-event-element="inline link" href="https://bookshop.org/a/12476/9780593734223"><i>Nexus: A Brief History of Information Networks From the Stone Age to AI</i></a>. It’s his grimmest work yet. In it, Harari rejects the notion that more information leads automatically to truth or wisdom. But it has led to artificial intelligence, whose advent Harari describes apocalyptically. “If we mishandle it,” he warns, “AI might <a data-event-element="inline link" href="https://www.theatlantic.com/magazine/archive/2018/06/henry-kissinger-ai-could-mean-the-end-of-human-history/559124/">extinguish not only the human dominion on Earth</a> but the light of consciousness itself, turning the universe into a realm of utter darkness.”</p><p class="rw-outer-content"><span>Some content could not be imported from the original document.</span> <a href="https://www.theatlantic.com/magazine/archive/2024/10/yuval-noah-harari-nexus-book/679572/">View content ↗ </a></p><p><span class="smallcaps">Those seeking </span>a precedent for AI often bring up the movable-type printing press, which inundated Europe with books and led, they say, to the scientific revolution. Harari rolls his eyes at this story. Nothing guaranteed that printing would be used for science, he notes. Copernicus’s <i>On the Revolutions of the Heavenly Spheres</i> failed to sell its puny initial print run of about 500 copies in 1543. It was, the writer Arthur Koestler joked, an “all-time worst seller.”</p><p>The book that did sell was Heinrich Kramer’s <i>The Hammer of the Witches</i> (1486), which ranted about a supposed satanic conspiracy of sexually voracious women who copulated with demons and cursed men’s penises. The historian Tamar Herzig describes Kramer’s treatise as “arguably the most misogynistic text to appear in print in premodern times.” Yet it was “a bestseller by early modern standards,” she writes. With a grip on its readers that Harari likens to QAnon’s, Kramer’s book encouraged the witch hunts that killed tens of thousands. These murderous sprees, Harari observes, were “made worse” by the printing press.</p><p>Ampler information flows <a data-event-element="inline link" href="https://www.theatlantic.com/magazine/archive/2018/10/yuval-noah-harari-technology-tyranny/568330/">made surveillance and tyranny worse</a> too, Harari argues. The Soviet Union was, among other things, “one of the most formidable information networks in history,” he writes. When Aleksandr Solzhenitsyn griped about its leader, Joseph Stalin, in letters, he took the precaution of referring to him euphemistically as “the man with the mustache.” Even so, his letters were intercepted and understood, and Solzhenitsyn was <a data-event-element="inline link" href="https://www.newyorker.com/magazine/1994/02/14/aleksandr-solzhenitsyn-the-exile-returns">sentenced to eight years in the Gulag</a>. Much of the material that Moscow gathered about conditions in the country was either unreliable or poorly understood, Harari notes. But that stream of paper fed fantasies of total control, which killed millions of Soviet citizens.</p><p>Information has always carried this destructive potential, Harari believes. Yet up until now, he argues, even such hellish episodes have been only that: episodes. Demagogic manias like the ones Kramer fueled tend to burn bright and flame out. It’s hard to keep people in a perpetually frenzied state. Their emotional triggers change, and a treatise that once would have induced them to attack their neighbors will, a month or a year later, seem laughable.</p><p>States ruled by top-down terror have a durability problem too, Harari explains. Even if they could somehow intercept every letter and plant informants in every household, they’d still need to intelligently analyze all of the incoming reports. No regime has come close to managing this, and for the 20th-century states that got nearest to total control, persistent problems managing information made basic governance difficult.</p><p><a href="https://www.theatlantic.com/magazine/archive/2020/09/china-ai-surveillance/614197/">From the September 2020 issue: China’s artificial-intelligence surveillance state goes global</a></p><p>So it was, at any rate, in the age of paper. <a data-event-element="inline link" href="https://www.theatlantic.com/magazine/archive/2020/09/china-ai-surveillance/614197/">Collecting data is now much, much easier</a>. A future Solzhenitsyn won’t need to send an impolitic letter in clumsy code through governmental mail to have his thoughts revealed. A digital dictatorship could just check his search history. Some people worry that the government will implant a chip in their brain, but they should “instead worry about the smartphones on which they read these conspiracy theories,” Harari writes. Phones can already track our eye movements, record our speech, and deliver our private communications to nameless strangers. They are listening devices that, astonishingly, people are willing to leave by the bedside while having sex.</p><p>Harari’s biggest worry is what happens when AI enters the chat. Currently, massive data collection is offset, as it has always been, by the difficulties of data analysis. We’re used to reports of, say, police arresting innocent Black people on the advice of facial-recognition software (algorithms trained on databases full of pictures of white people, as many are, struggle to distinguish among nonwhite individuals). Such stories illustrate the risks of relying on algorithms, but they can offer false comfort by suggesting that AI is too glitchy to work. That won’t be true for long.</p><p>What defense could there be against an entity that recognized every face, knew every mood, and weaponized that information? In early modern Europe, readers had to find, buy, and potentially translate Kramer’s deranged treatise (it was written in Latin) to fall under its spell. Today’s political deliriums are stoked by click-maximizing algorithms that steer people toward “engaging” content, which is often whatever feeds their righteous rage. Imagine what will happen, Harari writes, when bots generate that content themselves, personalizing and continually adjusting it to flood the dopamine receptors of each user. Kramer’s <i>Hammer of the Witches</i> will seem like a mild sugar high compared with the heroin rush of content the algorithms will concoct. If AI seizes command, it could make serfs or psychopaths of us all.</p><p><a href="https://www.theatlantic.com/magazine/archive/2023/07/generative-ai-human-culture-philosophy/674165/">From the July/August 2023 issue: Adrienne LaFrance on defending humanity in the age of AI</a></p><p>This might happen. Will it, though? Harari regards AI as ultimately unfathomable—and that is his concern. When <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2016/03/the-invisible-opponent/475611/">a computer defeated the South Korean Go champion in 2016</a>, one move it made was so bizarre that it looked like a mistake. The move worked, but the algorithm’s programmers couldn’t explain its reasoning. Although we know how to make AI models, we don’t understand them. We’ve blithely summoned an “alien intelligence,” Harari writes, with no idea what it will do.</p><p>Last year, Harari signed <a data-event-element="inline link" href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">an open letter</a> warning of the “profound risks to society and humanity” posed by unleashing “powerful digital minds that no one—not even their creators—can understand, predict, or reliably control.” It called for a pause of at least six months on training advanced AI systems, backed by law if needed. Remarkably, some of the researchers who’d developed those systems signed the letter, as did Elon Musk. The implication was that AI is so powerful, even its inventors fear it.</p><p>Perhaps, but cynics saw the letter as self-serving. It fed the hype by insisting that artificial intelligence, rather than being a buggy product with limited use, was an epochal development. It showcased tech leaders’ Oppenheimer-style moral seriousness. Yet it cost them nothing, as there was no chance their research would actually stop. Four months after signing, Musk <a data-event-element="inline link" href="https://www.reuters.com/technology/elon-musks-ai-firm-xai-launches-website-2023-07-12/">publicly launched an AI company</a>.</p><p><span class="smallcaps">Harari sits </span>above the fray of Silicon Valley politicking. The hope is that his elevated vantage will allow him to see farther. But just as it’s possible to be too narrowly focused and miss the forest for the trees, it’s also possible to be too zoomed-out and miss the forest for the solar system. Although Harari is a good guide to how future technologies might destroy democracy (<a data-event-element="inline link" href="https://www.theatlantic.com/business/archive/2017/02/the-post-human-world/517206/">or humanity</a>), he’s less helpful on the present-day economics bringing those technologies forth.</p><p><a href="https://www.theatlantic.com/business/archive/2017/02/the-post-human-world/517206/">Read: Derek Thompson’s 2017 interview with Yuval Noah Harari on the post-human world</a></p><p>The economics of the Information Age have been treacherous. They’ve made content cheaper to consume but less profitable to produce. Consider the effect of the free-content and targeted-advertising models on journalism: Since 2005, the United States <a data-event-element="inline link" href="https://localnewsinitiative.northwestern.edu/projects/state-of-local-news/2023/report/">has lost nearly a third of its newspapers</a> and more than two-thirds of its newspaper jobs, to the point where <a data-event-element="inline link" href="https://www.threads.net/@benedictevans/post/C3u8bZQI0Ox?hl=en">nearly 7 percent of newspaper employees</a> now work for a single organization, <i>The New York Times</i>. In the 21st-century United States—at the height and center of the information revolution—we speak of “news deserts,” places where reporting has essentially vanished.</p><p>AI threatens to exacerbate this. With better chatbots, platforms won’t need to link to external content, because they’ll reproduce it synthetically. Instead of a Google search that sends users to outside sites, a chatbot query will summarize those sites, keeping users within Google’s walled garden. The prospect isn’t a network with a million links but a <i>Truman Show</i>–style bubble: personally generated content, read by voices that sound real but aren’t, plus product placement. Among other problems, this would cut off writers and publishers—the ones actually generating ideas—from readers. Our <a data-event-element="inline link" href="https://www.theatlantic.com/magazine/archive/2023/07/generative-ai-human-culture-philosophy/674165/">intellectual institutions would wither</a>, and the internet <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2024/02/artificial-intelligence-self-learning/677484/">would devolve into a closed loop</a> of “five giant websites, each filled with screenshots of the other four,” as the software engineer Tom Eastman puts it.</p><blockquote>Hand-wringing about the possibility that AI developers will lose control of their creation distracts from the more plausible scenario that they’ll use it as planned.</blockquote><p>Harari has little to say about <a data-event-element="inline link" href="https://www.theatlantic.com/magazine/archive/2018/06/henry-kissinger-ai-could-mean-the-end-of-human-history/559124/">the erosion of our intellectual institutions</a>. In a way, he is symptomatic of the trend. Although flesh and blood, Harari is Silicon Valley’s ideal of what a chatbot should be. He raids libraries, detects the patterns, and boils all of history down to bullet points. (Modernity, he writes, “can be summarised in a single phrase: humans agree to give up meaning in exchange for power.”) He’s written an entire book, <i>21 Lessons for the 21st Century</i>, in the form of a list. For readers whose attention flags, he delivers amusing factoids at a rapid clip.</p><p><a href="https://www.theatlantic.com/technology/archive/2024/02/artificial-intelligence-self-learning/677484/">Read: Things get strange when AI starts training itself</a></p><p>All of this derives from Harari’s broad reading. Yet, like a chatbot, he has a quasi-antagonistic relationship with his sources, an <i>I’ll read them so you don’t have to</i> attitude. He mines other writers for material—a neat quip, a telling anecdote—but rarely seems taken with anyone else’s views. Nearly all scholars, in their acknowledgments, identify the interlocutors who inspired or challenged them. In <i>Nexus</i>, Harari doesn’t acknowledge any intellectual influences beyond his business relationships: Thanks go to his publishers, his editors, and the “in-house research team at Sapienship”—that is, his employees.</p><p>His asceticism is relevant here, too. Harari meditates, he says, to prevent himself from getting “entangled in” or “blinded by” human “fictions.” The implication is that everything out there is, in some sense, a trap. Intellectually, Harari is more of a teetotaler than a connoisseur; somehow it’s easier to picture him deep in his own thoughts than absorbed in a serious book.</p><p>Harari’s distance from the here and now shapes how he sees AI. He discusses it as something that simply happened. Its arrival is nobody’s fault in particular. At the start of <i>Nexus</i>, Harari brings up, as a parable, Johann Wolfgang von Goethe’s story of the sorcerer’s apprentice, about a well-meaning but hubristic novice who conjures with <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2022/09/artificial-intelligence-machine-learing-natural-language-processing/661401/">a magic beyond his ken</a>. People tend to “create powerful things with unintended consequences,” Harari agrees, though he faults Goethe for pinning the blame on an individual. In Harari’s view, “power always stems from cooperation between large numbers of humans”; it is the product of society.</p><p>Surely true, but why are we talking about the sorcerer’s apprentice at all? Artificial intelligence isn’t a “whoopsie.” It’s something scientists have been working on purposefully for decades. (The AI project at MIT, still operating, <a data-event-element="inline link" href="https://www.csail.mit.edu/about/mission-history">was founded in 1959</a>.) Nor have these efforts been driven by idle curiosity. Individual AI models <a data-event-element="inline link" href="https://www.nytimes.com/2024/04/29/technology/ai-startups-financial-reality.html">cost billions of dollars</a>. In 2023, <a data-event-element="inline link" href="https://www.axios.com/2024/07/08/ai-stock-market">about a fifth of venture capital</a> in North America and Europe went to AI. Such sums make sense only if tech firms can earn enormous revenues off their product, by monopolizing it or marketing it. And at that scale, the most obvious buyers are other large companies or governments. How confident are we that giving more power to corporations and states will turn out well?</p><p><a href="https://www.theatlantic.com/ideas/archive/2022/12/putin-russian-ukraine-war-global-peace/672385/">Yuval Noah Harari: The end of the new peace</a></p><p>AI might not become an alien intelligence with its own aims. But, presuming it works, it will be a formidable weapon for whoever is rich enough to wield it. Hand-wringing about the possibility that AI developers will lose control of their creation, like the sorcerer’s apprentice, distracts from the more plausible scenario that they won’t lose control, and that they’ll use or sell it as planned. A better German fable might be Richard Wagner’s <i>The Ring of the Nibelung </i>: A power-hungry incel forges a ring that will let its owner rule the world—and the gods wage war over it.</p><p>Harari’s eyes are more on the horizon than on Silicon Valley’s economics or politics. This may make for deep insights, but it also makes for unsatisfying recommendations. In <i>Nexus</i>, he proposes four principles. The first is “benevolence,” explained thus: “When a computer network collects information on me, that information should be used to help me rather than manipulate me.” Don’t be evil—check. Who would disagree? Harari’s other three values are decentralization of informational channels, accountability from those who collect our data, and some respite from algorithmic surveillance. Again, these are fine, but they are quick, unsurprising, and—especially when expressed in the abstract, as things that “we” should all strive for—not very helpful.</p><p>Harari ends <i>Nexus</i> with a pronouncement: “The decisions we all make in the coming years” will determine whether AI turns out to be “a hopeful new chapter” or a “terminal error.” Yes, yes, though his persistent first-person pluralizing (“decisions <i>we </i>all make”) softly suggests that AI is humanity’s collective creation rather than the product of certain corporations and the individuals who run them. This obscures the most important actors in the drama—ironically, just as those actors are sapping our intellectual life, hampering the robust, informed debates we’d need in order to make the decisions Harari envisions.</p><p>Taking AI seriously might mean directly confronting the companies developing it. Activists worried about the concentration of economic power speak—with specifics—about antitrust legislation, tighter regulation, transparency, data autonomy, and alternative platforms. Perhaps large corporations should be broken up, as AT&amp;T was.</p><p>Harari isn’t obviously opposed. His values would in fact seem to justify such measures, especially because some of the nightmarish what-if scenarios he sketches involve out-of-control corporations (and states). Yet Harari slots easily into the dominant worldview of Silicon Valley. Despite his oft-noted digital abstemiousness, he exemplifies its style of gathering and presenting information. And, like many in that world, he combines technological dystopianism with political passivity. Although he thinks tech giants, in further developing AI, might end humankind, he does not treat thwarting them as an urgent priority. His epic narratives, told as stories of humanity as a whole, do not make much room for such us-versus-them clashes.</p><p>Harari writes well at the scale of the species. As a book, <i>Nexus</i> doesn’t reach the high-water mark of <i>Sapiens</i>, but it offers an arresting vision of how AI could turn catastrophic. The question is whether Harari’s wide-angle lens helps us see how to avoid that. Sometimes, for the best view, you need to come down from the mountaintop.</p><hr/><div><p data-flatplan-paragraph="true"><small><em>This article appears in the <a data-event-element="inline link" data-gtm-vis-first-on-screen31117857_899="4058" data-gtm-vis-has-fired31117857_899="1" data-gtm-vis-recent-on-screen31117857_899="4058" data-gtm-vis-total-visible-time31117857_899="100" href="https://www.theatlantic.com/magazine/toc/2024/10/">October 2024</a> print edition with the headline “A Brief History of Yuval Noah Harari.”</em></small></p></div></body></html>
