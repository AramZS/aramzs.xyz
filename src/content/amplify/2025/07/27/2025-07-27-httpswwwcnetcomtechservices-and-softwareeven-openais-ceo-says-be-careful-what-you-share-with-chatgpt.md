---
author: >-
  See Full Bio & Jon Reed & Jon Covers Artificial Intelligence. He Previously
  Led Cnet'S Home Energy & Utilities Category & With A Focus On Energy-Saving
  Advice & Thermostats & Heating & Cooling. Jon Has More Than A Decade Of
  Experience Writing & Re...
cover_image: >-
  https://www.cnet.com/a/img/resize/6f5237e55eba272ae00f0348c51b7b7286c840d4/hub/2025/07/25/d61443ea-77fc-4b49-abde-beafe10319e7/gettyimages-2218523666.jpg?auto=webp&fit=crop&height=675&width=1200
date: '2025-07-27T18:03:57.510Z'
dateFolder: 2025/07/27
description: >-
  The AI model is not your therapist and the company behind it can't necessarily
  keep it secret. Sam Altman thinks that's 'very screwed up.'
isBasedOn: >-
  https://www.cnet.com/tech/services-and-software/even-openais-ceo-says-be-careful-what-you-share-with-chatgpt/
link: >-
  https://www.cnet.com/tech/services-and-software/even-openais-ceo-says-be-careful-what-you-share-with-chatgpt/
slug: >-
  2025-07-27-httpswwwcnetcomtechservices-and-softwareeven-openais-ceo-says-be-careful-what-you-share-with-chatgpt
tags:
  - ai
title: Even OpenAI's CEO Says Be Careful What You Share With ChatGPT
---
<div><article><p>Maybe don't spill your deepest, darkest secrets with an <a href="https://www.cnet.com/tech/services-and-software/best-ai-chatbots/" target="_self">AI chatbot</a>. You don't have to take my word for it. Take it from the guy behind the most popular generative AI model on the market.</p><p>Sam Altman, the CEO of <a href="https://www.cnet.com/tech/services-and-software/chatgpt-plus-review/" target="_self">ChatGPT</a> maker OpenAI, raised the issue this week in an <a href="https://www.youtube.com/watch?v=aYn8VKW6vXA" target="_self">interview</a> with host Theo Von on the This Past Weekend podcast. He suggested that your conversations with AI should have similar protections as those you have with your doctor or lawyer. At one point, Von said one reason he was hesitant to use some AI tools is because he "didn't know who's going to have" his personal information.</p><p data-ad-callout="Advertisement"></p><figure><a href="https://www.cnet.com/ai-atlas/" rel="" target="_blank"> </a> </figure><p>"I think that makes sense," Altman said, "to really want the privacy clarity before you use it a lot, the legal clarity."</p><p data-ad-callout="Advertisement"></p><p>More and more AI users are <a href="https://www.cnet.com/tech/services-and-software/can-ai-be-your-therapist-3-things-that-worry-professionals-and-3-tips-for-staying-safe/" target="_self">treating chatbots like their therapists</a>, doctors or lawyers, and that's created a serious privacy problem for them. There are no confidentiality rules and the actual mechanics of what happens to those conversations are startlingly unclear. Of course, there are other problems with using AI as a therapist or confidant, like how bots can give terrible advice or how they can <a href="https://www.massgeneralbrigham.org/en/about/newsroom/press-releases/llms-stigmatizing-language-alcohol-substance-use-disorder" target="_self">reinforce stereotypes or stigma</a>. (My colleague Nelson Aguilar has compiled a list of the <a href="https://www.cnet.com/tech/services-and-software/11-things-you-shouldnt-be-using-chatgpt-for/" target="_self">11 things you should never do with ChatGPT</a> and why.)</p><p data-ad-callout="Advertisement"></p><p data-ad-callout="Advertisement"></p><p>Altman's clearly aware of the issues here, and seems at least a bit troubled by it. "People use it, young people especially, use it as a therapist, a life coach, I'm having these relationship problems, what should I do?" he said. "Right now, if you talk to a therapist or a lawyer or a doctor about those problems, there's legal privilege for it."</p><p data-ad-callout="Advertisement"></p><p>The question came up during a part of the conversation about whether there should be <a href="https://www.cnet.com/tech/services-and-software/congress-isnt-stepping-up-to-regulate-ai-where-does-that-leave-us-now/" target="_self">more rules or regulations around AI</a>. Rules that stifle AI companies and the tech's development are unlikely to gain favor in Washington these days, as President Donald Trump's <a href="https://www.cnet.com/tech/services-and-software/trumps-ai-action-plan-is-here-5-key-takeaways/" target="_self">AI Action Plan</a> released this week expressed a desire to regulate this technology less, not more. But rules to protect them might find favor. </p><p data-ad-callout="Advertisement"></p><p data-ad-callout="Advertisement"></p><p><strong>Read more:</strong> <a href="https://www.cnet.com/tech/services-and-software/features/ai-essentials-29-ways-to-make-gen-ai-work-for-you-according-to-our-experts/" target="_self">AI Essentials: 29 Ways You Can Make Gen AI Work for You, According to Our Experts</a></p><p>Altman seemed most worried about a lack of legal protections for companies like his to keep them from being forced to turn over private conversations in lawsuits. OpenAI has <a href="https://openai.com/index/response-to-nyt-data-demands/" target="_self">objected</a> to requests to retain user conversations during a lawsuit with the New York Times over <a href="https://www.cnet.com/tech/services-and-software/were-all-copyright-owners-why-you-need-to-care-about-ai-and-copyright/" target="_self">copyright infringement and intellectual property</a> issues. (Disclosure: Ziff Davis, CNET's parent company, in April filed a lawsuit against OpenAI, alleging it infringed Ziff Davis copyrights in training and operating its AI systems.)</p><p data-ad-callout="Advertisement"></p><p data-ad-callout="Advertisement"></p><p>"If you go talk to ChatGPT about the most sensitive stuff and then there's a lawsuit or whatever, we could be required to produce that," Altman said. "I think that's very screwed up. I think we should have the same concept of privacy for your conversations with AI that you do with your therapist or whatever."</p><h2>Be careful what you tell AI about yourself</h2><p>For you, the issue isn't so much that OpenAI might have to turn your conversations over in a lawsuit. It's a question of whom you trust with your secrets.</p><p data-ad-callout="Advertisement"></p><p data-ad-callout="Advertisement"></p><p>William Agnew, a researcher at Carnegie Mellon University who was part of a team that <a href="https://cse.umn.edu/college/news/new-research-shows-ai-chatbots-should-not-replace-your-therapist" target="_self">evaluated chatbots</a> on their performance dealing with therapy-like questions, told me recently that privacy is a paramount issue when confiding in AI tools. The uncertainty around how models work -- and how your conversations are kept from appearing in other people's chats -- is reason enough to be hesitant.</p><p data-ad-callout="Advertisement"></p><p>"Even if these companies are trying to be careful with your data, these models are well known to regurgitate information," Agnew said.</p><p>If ChatGPT or another tool regurgitates information from your therapy session or from medical questions you asked, that could appear if your insurance company or someone else with an interest in your personal life asks the same tool about you. </p><p>"People should really think about privacy more and just know that almost everything they tell these chatbots is not private," Agnew said. "It will be used in all sorts of ways."</p></article></div>
