---
author: Limites numériques
cover_image: ''
date: '2025-07-24T16:50:06.774Z'
dateFolder: 2025/07/24
description: AI significantly increases environmental impacts of digital technologies.
isBasedOn: 'https://limitesnumeriques.fr/travaux-productions/ai-forcing/en'
link: 'https://limitesnumeriques.fr/travaux-productions/ai-forcing/en'
slug: 2025-07-24-httpslimitesnumeriquesfrtravaux-productionsai-forcingen
tags:
  - ai
  - design
  - culture
title: How tech companies are pushing us to use AI
---
<h2>Introduction</h2>
<p>The forced deployment of generative AI services causes serious social and environnemental issues. We mentionned it in <a href="https://limitesnumeriques.substack.com/p/limites-numeriques-12">one of our newsletters</a> and press alerts are becoming more and more frequent.</p>
<p>AI <a href="https://www.iea.org/reports/electricity-2024/executive-summary">significantly increases environmental impacts of digital technologies</a>. To mention just a few digits, <a href="https://www.latribune.fr/technos-medias/informatique/les-data-centers-menaces-d-obsolescence-a-cause-de-l-essor-de-l-ia-1007271.html">80% of data centers could now be obsolete</a> and during the first half of 2023 <a href="https://www.businessinsider.com/ai-data-centers-land-grab-google-meta-openai-amazon-2023-12?r=US&amp;IR=T">North America reached a new record with a +25% rise in the construction of new data centers</a>.</p>
<p>Driven by massive investments that need to be profitable, by promises of new profit sources or by fear to be overwhelmed, many tech companies started to implement features feeded by AI.</p>
<p>The addition of new functionalities in apps or softwares is of course not new in itself, but what strikes with AI is the way companies push to adopt these features, especially through design. It seems to us that this phenomenon is unprecedented in the history of interfaces. <strong>Our goal with this study is to analyse multiple strategies settled by companies to encourage us to adopt AI, whether we want it or not</strong>.</p>
<h2>Analysis</h2>
<p>Early 2024, we noticed that a lot of AI icons appeared in several softwares, websites and apps we were using.<br/>
So we've started to collect systematically screenshots of each interface change linked to AI. Thanks to word of mouth and a call on <a href="https://mastodon.design/@limitesnumeriques/113431042717320191">Mastodon</a>, we collected hundreds of screenshots, as much in professionnal productivity softwares than in other type of use (hobbies, communication, creativity, etc.).</p>
<p>By analysing this corpus, we observed that features based on AI are proposed to users aggressively, through different recurring strategies. When we compare the way functions feeded by AI are integrated to interfaces with changes not linked to AI, the contrast is often striking and shows how much AI features take a special place.</p>
<p><strong>Here is how companies push us to use artificial intelligence</strong>.</p>
<h4>AI on center stage</h4>
<p>First of all, AI functions tend to take a lot of space and get usually the most valued place in interfaces, toolbars and menus.</p>
<p><strong><em>Snapchat</em></strong> for example added a feature based on AI in the form of a conversation named MyAI that, unlike other conversations, always stands above the rest, even if users never interact with it. We noted <strong><em>Google</em></strong> employs quite the same system by disguising AI as an incoming message. In the <strong><em>LinkedIn</em></strong> pop-over messaging service, a banner announcing an AI-based feature takes more than half of the space.</p>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/d77f1cd69c-1743082711/snapchat-google.jpg"/><figcaption> Snaptchat and Google Messages </figcaption></figure>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/en/4881d783a3-1745594953/googlekeep-linkedin.jpg"/><figcaption> Google Keep and Linkedin </figcaption></figure>
<p>In <strong><em>Notion</em></strong> and <strong><em>DeepL</em></strong>, when people select words, a toolbar appears in which first buttons on the left (located as close as possible to the cursor) are functionalities feeded by AI. On <em><strong>Notion</strong></em>, we can notice that these features take about a third of the toolbar space.</p>
<figure data-v-3ad7e601=""><figcaption><p>DeepL</p></figcaption></figure>
<figure data-v-3ad7e601=""><figcaption><p>Notion</p> </figcaption></figure>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/bb7b53d697-1745844067/whatapp.jpg"/><figcaption> Meta AI in Whatsapp </figcaption></figure>
<p>In <strong>Whatsapp</strong>, Meta AI is both present as a simple conversation, but can also be launched by clicking just above the message button. Moreover, the search bar button now launches a prompt instead. Many people have told us that they launched the AI inadvertently.</p>
<p>AI features are not only valued in the space, they are also highlighted visually. For example, in many cases like <em><strong>Buffer, Miro</strong></em> or <em><strong>Acrobat Reader</strong></em>, AI functions are emphasized by a specific color, such as a colored gradient or even an animated icon (<em><strong>Notion</strong></em>), contrary to all other functions that are generally displayed thanks to static grayscale icons.</p>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/e41dfd700c-1743082712/mashup-icones.jpg"/></figure>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/13ca474030-1743082709/ai-animation.gif"/><figcaption> In Notion </figcaption></figure>
<p>We also observed that AI features are provided with numerous ways of access and that they're constantly reminded to people. In <strong><em>Acrobat Reader</em></strong> for example, AI functions are presented and suggested to users several times. The same “AI Assistant” function is introduced at least six times in the interface: in left and right toolbars, as a button in the menu bar, as a tooltip in the interface, as an invitation in the graphical interface and when people select text.</p>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/3688e9d009-1743082708/adobe-interface.jpg"/></figure>
<p>We can see in some pages a complete graphical rework of the interface at the colors and symbols of AI.</p>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/fa09b11f8c-1743082710/qwant-avant-apres.jpg"/><figcaption>The home page of the Qwant search engine [fr] in april, 2014 (on the left) and in november, 2024 (on the right). The new page wears all the graphical codes of AI (colors, spark symbol) and values AI functionalities.</figcaption></figure>
<p>As they open <strong><em>Adobe Photoshop</em></strong>, users are first received in a contextual window encouraging them to “explore the power of generative AI”. After closing this first pop-up, a tooltip opens in the interface to suggest the same functionality. Likewise, when people open <strong><em>Microsoft Skype</em></strong> they're often welcomed by an AI chatbot called Copilot which invites them to use it as soon as the interface opens. Many tools like <em><strong>Slack</strong></em> and <strong><em>Google Doc</em></strong> also promote their AI functions with the help of banners in the interface.<br/>
Accordingly, the way AI features are introduced to people leads to a split of their usual work habits stream. A bunch of tooltips and banners promoting AI in interfaces generally need at least one clic from users to be deleted.</p>
<figure data-v-3ad7e601=""><figcaption><p>Adobe Acrobat: at the document opening</p> </figcaption></figure>
<h4>You're only one clic left to use it</h4>
<p>The preeminence given to AI functions in interfaces brings inescapably people to trigger them, even by mistake. For example, in <strong><em>Notion</em></strong>, it's very easy to trigger the AI assistant accidentally by pressing the space bar, which is a very frequently used key. In comparison, the keyboard shortcut for any other command requires from people to press “/”, which is less subject to this kind of error.</p>
<p><strong>It is possible that this overexposure is a first time in the history of interfaces. Never a feature would have been more pushed in such a short time, spatially, graphically and interactively all at once, and in such a persistent way</strong>.</p>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/4421d66dc6-1743082713/notion-espace-ai-light.gif"/><figcaption>On Notion, an invitation to AI on simple clic and the prompt launch through the space bar</figcaption></figure>
<h4>Always enabled…</h4>
<p>If AI functions are extremely easy to trigger or enabled by default, yet it is way harder for people to disable or refuse them. Usually, it's even impossible.</p>
<p>For example, people discovered that the sport monitoring app <em><strong>Strava</strong></em> started to use AI to comment their activities and, even if they didn't want to use it, they would not have any way to turn it off.<br/>
In <em><strong>Snapchat</strong></em> again, the <em>MyAI</em> conversation not only stays on the top, it is also currently impossible for users to delete it.</p>
<p>Even if apps offer ways to disable AI-based functions, it's not harmless. By the words we choose, first of all, because the refusal of AI-based function use can rarely be non categorical/is often categorical. Instead, apps propose usually a temporary way to remove the function by using words like “ignore for know” or “maybe later”. That means to users that they'll definitely end up using it in the long term.</p>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/en/95ae5aa418-1745846579/not-now-gemini.jpg"/></figure>
<h4>…but very hard to disable</h4>
<p>To understand how much AI is imposed to us, it's interesting to see, by contrast, how many applications hide that they started to enable AI learning on our datas by default. If the disable option exists, its existence isn't mentionned to users and the dedicated parameter is hidden among others. There is a notable gap between, in one hand, the way AI-based functions abilities are highlighted and introduced and, on the other hand, the informations provided to users to let them prevent AI training on/over their datas.</p>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/91b642613b-1743082711/optout-x.jpg"/></figure>
<h4>The symbol of magic and innovation</h4>
<p>The most common graphic symbol used to represent AI features is the spark icon ✨. Usually combined to something “special”, thrilling, new, but also to innovation and amazement, <a href="https://sociodesign.hypotheses.org/942">the icon contributes to an inherently “good” depiction of a functionality</a>. Unlike other icons that literally or figuratively illustrate what they do (⚙️🖋️🗑️📅📎 etc.), the ✨ icon used for AI actually stands out from other functionalities in interfaces.</p>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/6bb15c02f2-1743082708/sparkles-icones.jpg"/></figure>
<p>This graphical treatment is by the way often completed with superlatives, and the lexical field of power and magic (“Powerful assistant” for Grok, “Explore the power” for Photoshop, “Join us to dive into performance” for Apple).</p>
<p>Note also the <a href="https://simplyputpsych.co.uk/monday-musings-1/the-rise-of-purple-in-ai-branding-a-trend-rooted-in-symbolism-psychology-and-strategy#section-0">ubiquity of the mauve color</a> commonly associated to magic and impalpable. Moreover, we observed the use of pretty much identical blue-mauve gradients.</p>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/68b006f5e1-1743082712/sorciere.jpg"/><figcaption> Witches in Merlin the Wizard or in Snow White </figcaption></figure>
<figure data-v-3ad7e601=""><figcaption><p>Commercial page on Notion's website (2022)</p> </figcaption></figure>
<p>During a meeting with <a href="https://www.linkedin.com/in/marionlamarque/">Marion Lamarque</a>, a color specialist, she draws our attention to this: “In visual arts, purple stands for magic, but is also connects with innovation. The mauve, a faded version of purple, adds a sensation of softness and gives to the magic of AI a comforting face, especially when combined to a sky blue gradient, calming and consensual.”</p>
<h4>The all-in-one or the non definition of the feature</h4>
<p>By summoning visual semantics of magic, companies place AI as a multipurpose tool, without ever saying what it can't do. This graphical undefinition favors the AI highlight in all our interfaces, without distinguishing their major use differencies. Actually the same icon is used by companies for AI-based features that have nothing in common. The AI button from <em><strong>Zoom</strong></em>, for example, is a complete different use of <em><strong>Google</strong></em>'s, however they're visually close. The graphical standardisation of deeply different functionalities <a href="https://www.nngroup.com/articles/ai-sparkles-icon-problem/">produces a grey area</a> beneficial for/serving AI. If we don't know precisely what we are talking about, we are not really in a position to expect something from it. We are invited to be caught by surprise and may encounter difficulties to crititicise its effects.</p>
<figure data-v-3ad7e601=""><figcaption><p>Notion (on the left) explains that their AI tool “does it all”, Adobe (in the middle) proposes different functions and uses “etc” to suggest that AI can do a lot of other things. Google did likewise with “and more”.</p> </figcaption></figure>
<p>This “magification” affects not only new functionalities but also sometimes those yet settled/fixed in our uses and well understood. On <em><strong>Cairn</strong></em> for example, the algorithmic recommandation of similar publications is now related to the AI symbol.</p>
<h4>Make the machine and its materiality invisible</h4>
<p>The versatility promised by AI tools, embodied by magical invocations, results also to an invisibilisation of many AI operations materiality, imposing the idea that AI makes necessarily things easier, better and faster.<br/>
Those metaphors are convenient because they help to avoid questions about efficiency and environmental or political effects, leading to an opaque data generation process during a magical event.</p>
<figure data-v-3ad7e601=""><figcaption><p>Qwant proposes an “instantaneous” answer to searches thanks to AI. Even though it appears a long time after results. Words and metaphors hide the calculation of the machine and the impacts much more significant than a basic search.</p> </figcaption></figure>
<p>We don't know how should behave something magic : is it normal that it takes time ? Did I do something wrong ? Is its resources consumption justified ? Making the machine invisible through the metaphor of magic changes the relation people have to tools. It is not possible anymore to pay attention to the machine.</p>
<h4>The human metaphor</h4>
<p>A common shape that generative AI take in our interfaces is the assistant's. Intelligent assistants - or AI assistants - are personified through metaphors reminding human characteristics, for example by having a name like “Aria” (<em><strong>Opera</strong></em>) or “Leo” (_<strong>Brave_</strong>). Their humanity is also suggested by the way they are showed in the interface. For example, the <em><strong>Snapchat</strong></em> assistant is introduced as a contact. The AI assistants personnification is pushed until the textual interaction mode and the invitations to ask to or to discuss with the AI.</p>
<p>Assistants propose help to people for “learning in new ways, planning events, writting thank-you notes, and more” (<em><strong>Gemini</strong></em> on <em><strong>Google</strong></em>), “discuss, create and find anything” (<em><strong>Notion</strong></em>), or “suggest unique ideas” (<em><strong>Skype</strong></em>). These activities bring to mind tasks we usually associate to humans more than to IT/computing process. Presenting AI with human characteristics or skills contributes to speeches praising its attractivity and high-performance. This human skills versatility also justifies the AI functions colonisation in our digital services.</p>
<figure data-v-3ad7e601=""><figcaption><p>Notion IA button</p> </figcaption></figure>
<p>Generative AI tools often mention professionnal roles (ex: “Copilot” (<em><strong>Microsoft</strong></em>), “Agentforce” (<em><strong>Slack</strong></em>), “Cocreator” (<em><strong>Paint</strong></em>), “Companion” (<em><strong>Microsoft</strong></em>, <em><strong>Zoom</strong></em>), “Analyst” (<em><strong>Google Chat</strong></em>), or literally “Assistant” (<em><strong>Proton</strong></em>, <em><strong>Brave</strong></em>, <em><strong>Webex</strong></em>)). It feeds the idea that AI is like a peer, or a partner. It also echoes to the <a href="https://archive.org/details/Apple-Computer-Educom-1987-John-Sculley-Keynote-Address-On-The-Knowledge-Navigator">fantasy of reducing challenging tasks thanks to technology</a>: the AI assistant allows to delegate uninteresting or difficult actions, raising users to more important tasks.</p>
<p>In those personnified examples, we (users) do not use AI as we would do with a tool, we are asking for devoted assistants (ex: “Whenever you need me”(<em><strong>Notion</strong></em>), “Need help?” (<em><strong>Brave</strong></em>)) to do things in our place. AI assistants are presented as skillfull subordinates, waiting for instructions to guide them. This positioning from AI as hierarchically inferior to us, and controllable (waiting for our orders) could be an answer to the fear of <a href="https://danslesalgorithmes.net/2024/12/10/lia-generative-nouvelle-couche-dexploitation-du-travail/">work damaging for qualified workers</a>. It conveys the seducing figure of an agent merging the properties of a tool and a teammate, except that this colleague won't ask for help.</p>
<blockquote> <p><strong><em>“We want tireless agents that treat us as co-workers, even if we do not treat them like that”</em></strong></p> </blockquote>
<p>Newendorp and his colleagues, in an <a href="https://https//dl.acm.org/doi/full/10.1145/3613904.3642739">2024 article</a> talking about the metaphor of social relation induced by conversationnal agents.</p>
<h4>AI mastering, a skill like an other ?</h4>
<p>Another strategy to reinforce the AI adoption involves presenting functionalities that seek generative AI as an extension of productivity, creativity or intelligence of people, which give them new skills (ex: generate code) or more time (ex: generate meeting notes). Features do not introduce AI as a customised assistant who will do things for us, they rather display a sample group of tools that extend users skills (here professionnal ones): possible actions achievable by AI are depicted as traditionnal software tools icons, rather than a free text field.</p>
<p>This tool evocation takes part in the presentation of AI use as a factor of professionnal competivity, where the execution speed of tasks and the spectum of know-hows are valued. It is a more indirect and pernicious way to impose AI, by playing on the competition between workers.</p>
<h4>An unseen <em>forced use</em> to offset huge investments</h4>
<p>This analyse shows that something special happens with AI: a form of forced use, probably unseen in the history of interfaces. Because massive investments of hundreds of billions dollars, made by companies affraid of being outdistanced in what can be perceived as a gold rush, have to be profitable. In a saturated market, where perspectives of growth are know quite weak, new AI features become very often an <a href="https://www.wheresyoured.at/saaspocalypse-now/">opportunity</a> to increase <a href="https://www.theverge.com/2024/9/3/24234698/canva-price-increase-300-percent-ai-features">here</a> and <a href="https://www.lemondeinformatique.fr/actualites/lire-en-integrant-copilot-microsoft365-voit-ses-tarifs-augmenter-pour-les-particuliers-95817.html">there</a> the subscriptions prices of several digital services. We, users, have then to pay the price of the financial risk taken by companies in this AI race. And then more or less visible changes that overwhelmed our interfaces are the direct consequence.</p>
<p>Unlike previous technological evolutions, companies can now, through updates and softwares hosted in the cloud, transform interfaces overnight, affecting all users in an instant. What could progressively happen before is now almost instantly spread to billions of people in the world, except that there is no escape.</p>
<p>The collective hype effect pushes then companies that don't want to “miss” the change of paradigm in a race. To such an extent that some functionalities seem to exist only to say “we too”, and other features employing algorithms for ages get dressed in the colors of AI.</p>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/2b781a66ef-1743082712/ai-plan.jpg"/></figure>
<h4>AI, an answer seeking for a need to satisfy</h4>
<p>Tech companies grope around to try to find features which will be adopted. We saw it, the eruption of new AI functionalities is served with a massive amount of informations, pop-ups, communications, tutorials and use case examples (TV spots, tooltips, etc.). This forced use strategy, accompanied by a massive profusion of explanations, seem to be the sign of a technology where uses are at best unclear, at worst unable to answer to any request or need.</p>
<p>This race to new AI features, symbol of innovation, happens at the cost of real needs and can, in many cases, participate to <a href="https://networkcultures.org/longform/2024/09/05/algorithms-vs-interactions-the-revenge-of-artificial-intelligence-over-design/">hide deeper issues in our softwares</a>.</p>
<figure data-v-3ad7e601=""><img alt="" src="https://limitesnumeriques.fr/media/pages/travaux-productions/ai-forcing/d616194b77-1743082713/mastodon-ia.jpg"/></figure>
