---
author: Matthew Guariglia
cover_image: 'https://www.eff.org/files/banner_library/robot-robot-2a.png'
date: '2025-07-15T23:31:02.286Z'
dateFolder: 2025/07/15
description: >-
  Axon Enterprise’s Draft One — a generative artificial intelligence product
  that writes police reports based on audio from officers’ body-worn cameras —
  seems deliberately designed to avoid audits that could provide any
  accountability to the public, an EFF investigation has found.Our review of...
isBasedOn: >-
  https://www.eff.org/deeplinks/2025/07/axons-draft-one-designed-defy-transparency
link: >-
  https://www.eff.org/deeplinks/2025/07/axons-draft-one-designed-defy-transparency
slug: >-
  2025-07-15-httpswwwefforgdeeplinks202507axons-draft-one-designed-defy-transparency
tags:
  - privacy
  - law and order
title: Axon’s Draft One is Designed to Defy Transparency
---
<figure><img alt="a sinister police robot types a report" src="https://www.eff.org/files/banner_library/robot-robot-2a.png"/><figcaption>a sinister police robot types a report</figcaption></figure>
<p>Axon Enterprise’s Draft One — a generative artificial intelligence product that writes police reports based on audio from officers’ body-worn cameras — seems deliberately designed to avoid audits that could provide any accountability to the public, an EFF investigation has found.</p>
<p>Our review of public records from police agencies already using the technology — including police reports, emails, procurement documents, department policies, software settings, and more — as well as Axon’s own user manuals and marketing materials revealed that it’s often impossible to tell which parts of a police report were generated by AI and which parts were written by an officer.</p>
<p>You can read our full report, which details what we found in those documents, how we filed those public records requests, and how you can file your own, <a href="https://eff.org/deeplinks/2025/07/effs-guide-getting-records-about-axons-ai-generated-police-reports">here</a>.</p>
<p>Everyone should have access to answers, evidence, and data regarding the effectiveness and dangers of this technology. Axon and its customers claim this technology will revolutionize policing, but it remains to be seen how it will change the criminal justice system, and who this technology benefits most.</p>
<p>For months, <a href="https://www.eff.org/deeplinks/2024/05/what-can-go-wrong-when-police-use-ai-write-reports">EFF</a> and other <a href="https://www.aclu.org/documents/aclu-on-police-departments-use-of-ai-to-draft-police-reports">organizations</a> have warned about the threats this technology poses to accountability and transparency in an already flawed criminal justice system. Now we've concluded the situation is even worse than we thought: <b>There is no meaningful way to audit Draft One usage, whether you're a police chief or an independent researcher, because Axon designed it that way. </b></p>
<p>Draft One uses a ChatGPT variant to process body-worn camera audio of public encounters and create police reports based only on the captured verbal dialogue; it does not process the video. The Draft One-generated text is sprinkled with bracketed placeholders that officers are encouraged to add additional observations or information—or can be quickly deleted. Officers are supposed to edit Draft One's report and correct anything the Gen AI misunderstood due to a lack of context, troubled translations, or just plain-old mistakes. When they're done, the officer is prompted to sign an acknowledgement that <a href="https://vimeo.com/936340459">the report was generated using Draft One and that they have reviewed the report and made necessary edits to ensure it is consistent with the officer’s recollection</a>. Then they can copy and paste the text into their report. When they close the window, the draft disappears.</p>
<p>Any new, untested, and problematic technology needs a robust process to evaluate its use by officers. In this case, one would expect police agencies to retain data that ensures officers are actually editing the AI-generated reports as required, or that officers can accurately answer if a judge demands to know whether, or which part of, reports used by the prosecution were written by AI.</p>
<p>One would expect audit systems to be readily available to police supervisors, researchers, and the public, so that anyone can make their own independent conclusions. And one would expect that Draft One would make it easy to discern its AI product from human product – after all, even your basic, free word processing software can track changes and save a document history.</p>
<p>But Draft One defies all these expectations, offering meager oversight features that deliberately conceal how it is used.</p>
<p>So when a police report includes biased language, inaccuracies, misinterpretations, or even outright lies, the record won't indicate whether the officer or the AI is to blame. That makes it extremely difficult, if not impossible, to assess how the system affects justice outcomes, because there is little non-anecdotal data from which to determine whether the technology is junk.</p>
<p>The disregard for transparency is perhaps best encapsulated by a short email that an administrator in the Frederick Police Department in Colorado, one of Axon's first Draft One customers, sent to a company representative after receiving a public records request related to AI-generated reports.</p>
<p>"We love having new toys until the public gets wind of them," the administrator <a href="https://www.documentcloud.org/documents/25979149-frederick-police-department-re-tss-5058-reports-utilizing-draft-one/">wrote</a>.</p>
<h2><strong>No Record of Who Wrote What</strong></h2>
<p>The first question anyone should have about a police report written using Draft One is which parts were written by AI and which were added by the officer. Once you know this, you can start to answer more questions, like:</p>
<ul> <li>Are officers meaningfully editing and adding to the AI draft? Or are they reflexively rubber-stamping the drafts to move on as quickly as possible? </li> <li>How often are officers finding and correcting errors made by the AI, and are there patterns to these errors? </li> <li>If there is inappropriate language or a fabrication in the final report, was it introduced by the AI or the officer? </li> <li>Is the AI overstepping in its interpretation of the audio? If a report says, "the subject made a threatening gesture," was that added by the officer, or did the AI make a factual assumption based on the audio? If a suspect uses metaphorical slang, does the AI document literally? If a subject says "yeah" through a conversation as a verbal acknowledgement that they're listening to what the officer says, is that interpreted as an agreement or a confession?</li> </ul>
<p>Ironically, Draft One does not save the first draft it generates. Nor does the system store any subsequent versions. Instead, the officer copies and pastes the text into the police report, and the previous draft, originally created by Draft One, disappears as soon as the window closes. There is no log or record indicating which portions of a report were written by the computer and which portions were written by the officer, except for the officer's own recollection. If an officer generates a Draft One report multiple, there's no way to tell whether the AI interprets the audio differently each time.</p>
<p>Axon is open about not maintaining these records, at least when it markets directly to law enforcement.</p>
<p>In this video of a <a href="https://vimeo.com/941650612">roundtable discussion about the Draft One product</a>, Axon’s senior principal product manager for generative AI is asked (at the 49:47 mark) whether or not it’s possible to see after-the-fact which parts of the report were suggested by the AI and which were edited by the officer. His response (bold and definition of RMS added):</p>
<p>“<b>So we don’t store the original draft and that’s by design and that’s really because the last thing we want to do is create more disclosure headaches for our customers and our attorney’s offices</b>—so basically the officer generates that draft, they make their edits, if they submit it into our Axon records system then that’s the only place we store it, if they copy and paste it into their third-party RMS [records management system] system as soon as they’re done with that and close their browser tab, it’s gone. It’s actually never stored in the cloud at all so you don’t have to worry about extra copies floating around.”</p>
<p>To reiterate: Axon deliberately does not store the original draft written by the Gen AI, because "the last thing" they want is for cops to have to provide that data to anyone (say, a judge, defense attorney or civil liberties non-profit).</p>
<p>Following up on the same question, Axon's Director of Strategic Relationships at Axon Justice suggests this is fine, since a police officer using a word processor wouldn't be required to save every draft of a police report as they're re-writing it. This is, of course, misdirection and not remotely comparable. An officer with a word processor is one thought process and a record created by one party; Draft One is two processes from two parties–Axon and the officer. Ultimately, it could and should be considered two records: the version sent to the officer from Axon and the version edited by the officer.</p>
<p>The days of there being unexpected consequences of police departments writing reports in word processors may be over, but Draft One is still unproven. After all, every AI-evangelist, including Axon, claims this technology is a game-changer. So, why wouldn't an agency want to maintain a record that can establish the technology’s accuracy?</p>
<p>It also appears that Draft One isn't simply hewing to <a href="https://post.ca.gov/portals/0/post_docs/basic_course_resources/workbooks/LD_18_V-3.5.pdf">long</a>-<a href="https://www.lewisu.edu/writingcenter/pdf/police-report-resource-revised.pdf">established</a> <a href="https://www.csus.edu/campus-safety/police-department/_internal/_documents/rwm.pdf">norms</a> of police report-writing; it may fundamentally change them. In <a href="https://www.documentcloud.org/documents/25977598-campbell-pd-please-read-axon-draft-one-ai-generated-r/">one email</a>, the Campbell Police Department's Police Records Supervisor tells staff, “You may notice a significant difference with the narrative format…if the DA’s office has comments regarding our report narratives, please let me know.” It's more than a little shocking that a police department would implement such a change without fully soliciting and addressing the input of prosecutors. In this case, the Santa Clara County District Attorney had already suggested police include a disclosure when Axon Draft One is used in each report, but Axon's engineers had yet to finalize the feature at the time it was rolled out.</p>
<p>One of the main concerns, of course, is that this system effectively creates a smokescreen over truth-telling in police reports. If an officer lies or uses inappropriate language in a police report, who is to say that the officer wrote it or the AI? An officer can be punished severely for official dishonesty, but the consequences may be more lenient for a cop who blames it on the AI. There has already been an occasion when engineers discovered a bug that allowed officers on at least three occasions to circumvent the "guardrails" that supposedly deter officers from submitting AI-generated reports without reading them first, as Axon <a href="https://www.documentcloud.org/documents/25979172-frederick-police-department-re-draft-one-guardrails-issue/?mode=document#document/p2">disclosed</a> to the Frederick Police Department.</p>
<p>To serve and protect the public interest, the AI output must be continually and aggressively evaluated whenever and wherever it's used. But Axon has intentionally made this difficult.</p>
<h2><strong>What the Audit Trail Actually Looks Like </strong></h2>
<p>You may have seen <a href="https://my.axon.com/s/article/View-the-audit-trail-in-Axon-Evidence-Draft-One?language=en_US">news stories or other public statements </a>asserting that Draft One does, indeed, have auditing features. So, we dug through the user manuals to figure out what that exactly means.</p>
<p>The first thing to note is that, based on our review of the documentation, there appears to be no feature in Axon software that allows departments to export a list of all police officers who have used Draft One. Nor is it possible to export a list of all reports created by Draft One, unless the department has customized its process (we'll get to that in a minute).</p>
<p>This is disappointing because, without this information, it's near impossible to do even the most basic statistical analysis: how many officers are using the technology and how often.</p>
<p>Based on the documentation, you can only export two types of very basic logs, with the process differing depending on whether an agency uses <a href="https://my.axon.com/s/article/View-the-audit-trail-in-Axon-Evidence-Draft-One?language=en_US">Evidence</a> or Records/Standards products. These are:</p>
<ol> <li><b>A log of basic actions taken on a particular report.</b> If the officer requested a Draft One report or signed the Draft One liability disclosure related to the police report, it will show here. But nothing more than that.</li> <li><b>A log of an individual officer/user's basic activity in the Axon Evidence/Records system</b>. This audit log shows things such as when an officer logs into the system, uploads videos, or accesses a piece of evidence. The only Draft One-related activities this tracks are whether the officer ran a Draft One request, signed the Draft One liability disclosure, or changed the Draft One settings. </li> </ol>
<p>This means that, to do a comprehensive review, an evaluator may need to go through the record management system and look up each officer individually to identify whether that officer used Draft One and when. That could mean combing through dozens, hundreds, or in some cases, thousands of individual user logs.</p>
<figure><img alt="An audit log on Axon's Draft one which shows only when an officer as generated a report and when they have signed the liability disclosure." src="https://www.eff.org/files/2025/07/08/screenshot_2025-07-08_at_8.35.40_am.png"/><figcaption>An example of Draft One usage in an audit log.</figcaption></figure>
<p>An auditor could also go report-by-report as well to see which ones involved Draft One, but the sheer number of reports generated by an agency means this method would require a massive amount of time.</p>
<p>But can agencies even create a list of police reports that were co-written with AI? It depends on whether the agency has included a disclosure in the body of the text, such as "I acknowledge this report was generated from a digital recording using Draft One by Axon." If so, then an administrator can use "Draft One" as a keyword search to find relevant reports.</p>
<p>Agencies that do not require that language told us they could not identify which reports were written with Draft One. For example, one of those agencies and one of Axon's most promoted clients, the Lafayette Police Department in Indiana, told us:</p>
<p>"Regarding the attached request, we do not have the ability to create a list of reports created through Draft One. They are not searchable. This request is now closed."</p>
<p>Meanwhile, in response to a similar public records request, the Palm Beach County Sheriff's Office, which does require a disclosure at the bottom of each report that it had been written by AI, was able to isolate more than 3,000 Draft One reports generated between December 2024 and March 2025.</p>
<p>They told us: "We are able to do a keyword and a timeframe search. I used the words draft one and the system generated all the draft one reports for that timeframe."</p>
<p>We have requested further clarification from Axon, but they have yet to respond.</p>
<p>However, as we learned from email exchanges between the Frederick Police Department in Colorado and Axon, Axon is tracking police use of the technology at a level that isn't available to the police department itself.</p>
<p>In response to a request from Politico's Alfred Ng in August 2024 for Draft One-generated police reports, the police department was struggling to isolate those reports.</p>
<p>An Axon representative <a href="https://www.documentcloud.org/documents/25979141-frederick-police-deparmtent-email-re-media-request/?mode=document#document/p4">responded</a>: "Unfortunately, there’s no filter for DraftOne reports so you’d have to pull a User’s audit trail and look for Draft One entries. To set expectations, it’s not going to be graceful, but this wasn’t a scenario we anticipated needing to make easy."</p>
<p>But then, Axon followed up: "We track which reports use Draft One internally so I exported the data." Then, a few days later, Axon provided Frederick with some custom JSON code to extract the data in the future.</p>
<h2><br/>What is Being Done About Draft One</h2>
<p>The California Assembly is currently considering <a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202520260SB524">SB 524</a>, a bill that addresses transparency measures for AI-written police reports. The legislation would require disclosure whenever police use artificial intelligence to partially or fully write official reports, as well as “require the first draft created to be retained for as long as the final report is retained.” Because Draft One is designed not to retain the first or any previous drafts of a report, it cannot comply with this common-sense and first-step bill, and any law enforcement usage would be unlawful.</p>
<p>Axon markets Draft One as a solution to a problem police have been complaining about for at least a century: that they do too much paperwork. Or, at least, they spend too much time doing paperwork. The current research on whether Draft One remedies this issue shows mixed <a href="https://www.crimrxiv.com/pub/nxbmzp2j">results</a>, from some agencies claiming it has <a href="https://www.eff.org/deeplinks/2025/03/anchorage-police-department-ai-generated-police-reports-dont-save-time">no real-time savings</a>, with others agencies extolling its virtues (although their data also shows that <a href="https://www.documentcloud.org/documents/25973591-lake-havasu-police-department-draft-one-report-redacted-2/?mode=document#document/p17">results</a> vary even within the department).</p>
<p>In the justice system, police must prioritize accuracy over speed. Public safety and a trustworthy legal system demand quality over corner-cutting. Time saved should not be the only metric, or even the most important one. It's like evaluating a drive-through restaurant based only on how fast the food comes out, while deliberately concealing the ingredients and nutritional information and failing to inspect whether the kitchen is up to health and safety standards.</p>
<p>Given how untested this technology is and how much the company is in a <a href="https://www.investors.com/news/axon-stock-earnings-q2-draft-one-ai/">hurry to sell</a> Draft One, many local lawmakers and prosecutors have taken it upon themselves to try to regulate the product’s use. Utah is currently considering <a href="https://www.eff.org/deeplinks/2025/02/utah-bill-aims-make-officers-disclose-ai-written-police-reports">a bill that would mandate disclosure </a>for any police reports generated by AI, thus sidestepping one of the current major transparency issues: it’s nearly impossible to tell which finished reports started as an AI draft.</p>
<p>In King County, Washington, which includes Seattle, the district attorney’s office has been clear in their instructions: <a href="https://www.eff.org/deeplinks/2024/10/prosecutors-washington-state-warn-police-dont-use-gen-ai-write-reports">police should not use AI to write police reports</a>. Their<a href="https://komonews.com/amp/news/local/king-county-prosecutor-tells-police-not-to-use-ai-artificial-intelligence-for-official-reports-for-now-errors-concerns-law-enforcement-perjury-criminal-justice"> memo says</a></p>
<blockquote><p>We do not fear advances in technology – but we do have legitimate concerns about some of the products on the market now... AI continues to develop and we are hopeful that we will reach a point in the near future where these reports can be relied on. For now, our office has made the decision not to accept any police narratives that were produced with the assistance of AI.</p> </blockquote>
<p>We urge other prosecutors to follow suit and demand that police in their jurisdiction not unleash this new, unaccountable, and intentionally opaque AI product.</p>
<h2><strong>Conclusion</strong></h2>
<p>Police should not be using AI to write police reports. There are just too many unanswered questions about how AI would translate the audio of situations and whether police will actually edit those drafts, while simultaneously, there is no way for the public to reliably discern what was written by a person and what was written by a computer. This is before we even get to the question of how these reports might compound and exacerbate existing problems or create new ones in an already unfair and untransparent criminal justice system.</p>
<p>EFF will continue to research and advocate against the use of this technology but for now, the lesson is clear: Anyone with control or influence over police departments, be they lawmakers or people in the criminal justice system, has a duty to be informed about the potential harms and challenges posed by AI-written police reports.</p>
