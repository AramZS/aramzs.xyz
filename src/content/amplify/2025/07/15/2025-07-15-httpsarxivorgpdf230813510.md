---
author: ''
cover_image: ''
date: '2025-07-15T23:18:00.169Z'
dateFolder: 2025/07/15
description: null
isBasedOn: 'https://arxiv.org/pdf/2308.13510'
link: 'https://arxiv.org/pdf/2308.13510'
slug: 2025-07-15-httpsarxivorgpdf230813510
tags:
  - ad tech
  - privacy
title: Optimizing Hierarchical Queries for the \\ Attribution Reporting API
---
<div class="rw-pdf-text-view">
<h1>
<b>
    Optimizing Hierarchical Queries for the Attribution Reporting API
   </b>
</h1>
<p block-type="Text">
   Matthew Dawson
   <i>
<sup>
     1
    </sup>
</i>
   , Badih Ghazi
   <i>
<sup>
     1
    </sup>
</i>
   ,* , Pritish Kamath
   <i>
<sup>
     1
    </sup>
</i>
   , Kapil Kumar
   <i>
<sup>
     1
    </sup>
</i>
   , Ravi Kumar
   <i>
<sup>
     1
    </sup>
</i>
   , Bo Luan
   <i>
<sup>
     1
    </sup>
</i>
   , Pasin Manurangsi
   <i>
<sup>
     1
    </sup>
</i>
   , Nishanth Mundru
   <i>
<sup>
     1
    </sup>
</i>
   , Harikesh Nair
   <i>
<sup>
     1
    </sup>
</i>
   , Adam Sealfon
   <i>
<sup>
     1
    </sup>
</i>
   and Shengyu Zhu
   <i>
<sup>
     1
    </sup>
</i>
</p>
<p block-type="Text">
<i>
<sup>
     1
    </sup>
    Google
   </i>
</p>
<h4>
<b>
    Abstract
   </b>
</h4>
<p block-type="Text">
   We study the task of performing hierarchical queries based on summary reports from the
   <i>
    Attribution Reporting API
   </i>
   for ad conversion measurement. We demonstrate that methods from optimization and differential privacy can help cope with the noise introduced by privacy guardrails in the API. In particular, we present algorithms for (i) denoising the API outputs and ensuring consistency across different levels of the tree, and (ii) optimizing the privacy budget across different levels of the tree. We provide an experimental evaluation of the proposed algorithms on public datasets.
  </p>
<h4>
<b>
    Keywords
   </b>
</h4>
<p block-type="Text">
   ad conversion measurement, hierarchical aggregation, differential privacy, attribution reporting API
  </p>
<h2>
<b>
    1. Introduction
   </b>
</h2>
<p block-type="TextInlineMath">
   Over the last two decades, third-party cookies
   <a href="#page-8-0">
    [1]
   </a>
   have been essential to online advertising, and particularly to ad conversion measurement, whereby an ad impression (e.g., a click or a view) on a publisher site or app could be joined to a conversion on the advertiser, in order to compute aggregate conversion reports (e.g., the number of conversions attributed to a subset of impressions) or to train ad bidding models (e.g.,
   <a href="#page-8-1">
    [2,
   </a>
<a href="#page-8-2">
    3,
   </a>
<a href="#page-8-3">
    4,
   </a>
<a href="#page-8-4">
    5]
   </a>
   ). However, in recent years, privacy concerns have led several browsers to decide to deprecate third-party cookies, e.g.,
   <a href="#page-8-5">
    [6,
   </a>
<a href="#page-8-6">
    7,
   </a>
<a href="#page-8-7">
    8]
   </a>
   . The
   <i>
    Attribution Reporting API
   </i>
<a href="#page-8-8">
    [9,
   </a>
<a href="#page-8-9">
    10]
   </a>
   seeks to provide privacy-preserving ways for measuring ad conversions on the Chrome browser and the Android mobile operating system. This API relies on a variety of mechanisms for limiting the privacy leakage, including bounding the contributions to the output reports of the conversions attributed to each impression, as well as noise injection to satisfy differential privacy (for more details, see
   <a href="#page-1-0">
    Sec
   </a>
<a href="#page-1-0">
    tion 2)
   </a>
   .
  </p>
<p block-type="Text">
   We study the
   <i>
    conversion reporting
   </i>
   task, where a query consists of counting the number of conversions attributed to impressions such that some features of the conversion and the impression are restricted to certain given values. In particular, we focus on the
   <i>
    hierarchical queries
   </i>
   setting where the goal is to estimate the number of con-
  </p>
<p block-type="Text">
<a href="https://ceur-ws.org">
    Proceedings
   </a>
</p>
<p block-type="Text">
   ISSN 1613-0073
  </p>
<p>
<img src="https://readwise-assets.s3.amazonaws.com/media/reader/parsed_document_assets/338242122/PgnhjWXq36OnKuIvsKyA98uXde1J9-1wp34Gx8BW4FU-_pa_e1IQjjC.jpeg"/>
</p>
<p>
<span id="page-0-0">
</span>
<b>
    Figure 1:
   </b>
   Example of Hierarchical Queries.
  </p>
<p block-type="Text">
   versions attributed to impressions where the features are restricted according to certain nested conditions. Consider the example in
   <a href="#page-0-0">
    Figure 1,
   </a>
   where we wish to estimate the number of conversions:
  </p>
<p block-type="ListGroup">
</p><ul>
<li block-type="ListItem">
     attributed to impressions from campaign 123.
    </li>
<li block-type="ListItem">
     that are also restricted to take place in New York.
    </li>
<li block-type="ListItem">
     that are further restricted to occur on a Friday.
    </li>
</ul>
<p block-type="Text">
   In general, the goal is to estimate the conversion count for each node in a given tree, similar to the one in
   <a href="#page-0-0">
    Figure 1.
   </a>
</p>
<p block-type="Text">
   Such estimates can be obtained using summary reports from the Attribution Reporting API, as discussed in
   <a href="#page-1-1">
    Section 2.2.
   </a>
   In this work, we present a linear-time post-processing algorithm that denoises the estimates for different nodes that are returned by the API and ensures that the estimates are consistent with respect to the tree structure. We also show that our algorithm is optimal among all linear unbiased estimators for arbitrary trees, extending results for regular trees
   <a href="#page-8-10">
    [11,
   </a>
<a href="#page-8-11">
    12]
   </a>
<a href="#page-3-0">
    (Section 4)
   </a>
   . Since the API allows the ad-tech to allocate a privacy budget across different measurements containing contributions from the same impression, we provide an algorithm for optimizing the allocation of the privacy
  </p>
<p>
<i>
    AdKDD'23
   </i>
</p>
<p>
<sup>
    $
   </sup>
<a href="mailto:mwdawson@google.com">
    mwdawson@google.com
   </a>
   (M. Dawson);
   <a href="mailto:badihghazi@gmail.com">
    badihghazi@gmail.com
   </a>
   (B. Ghazi);
   <a href="mailto:pritishk@google.com">
    pritishk@google.com
   </a>
   (P. Kamath);
   <a href="mailto:kkapil@google.com">
    kkapil@google.com
   </a>
   (K. Kumar);
   <a href="mailto:ravi.k53@gmail.com">
    ravi.k53@gmail.com
   </a>
   (R. Kumar);
   <a href="mailto:luanbo@google.com">
    luanbo@google.com
   </a>
   (B. Luan);
   <a href="mailto:pasin@google.com">
    pasin@google.com
   </a>
   (P. Manurangsi);
  </p>
<p>
<a href="mailto:nmundru@google.com">
    nmundru@google.com
   </a>
   (N. Mundru);
   <a href="mailto:hsnair@google.com">
    hsnair@google.com
   </a>
   (H. Nair);
   <a href="mailto:adamsealfon@google.com">
    adamsealfon@google.com
   </a>
   (A. Sealfon);
   <a href="mailto:shengyuzhu@google.com">
    shengyuzhu@google.com
   </a>
   (S. Zhu)
  </p>
<p>
<sup>
    ©
   </sup>
   2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
   <a href="https://creativecommons.org/licenses/by/4.0">
    CEUR
   </a>
   Workshop http://ceur-ws.org CEUR Workshop Proceedings
   <a href="https://ceur-ws.org">
    (CEUR-WS.org)
   </a>
</p>
<p block-type="Text">
   budget across the different levels of the tree
   <a href="#page-5-0">
    (Section 5)
   </a>
   .
  </p>
<p block-type="Text">
   We start by recalling in
   <a href="#page-1-0">
    Section 2
   </a>
   the basics of differential privacy and summarizing the query model for summary reports in the Attribution Reporting API. In
   <a href="#page-2-0">
    Section 3,
   </a>
   we formally define the optimization problem that we seek to solve. In
   <a href="#page-5-1">
    Section 6,
   </a>
   we provide an experimental evaluation of our algorithms on two public datasets. We conclude with some future directions in
   <a href="#page-6-0">
    Section 7.
   </a>
</p>
<h2>
<span id="page-1-0">
</span>
<b>
    2. Preliminaries
   </b>
</h2>
<h4>
<b>
    2.1. Differential Privacy (DP)
   </b>
</h4>
<p block-type="Text">
   Let  be the number of rows in the dataset and let  be the (arbitrary) set representing the domain of values for each row. We distinguish two types of columns (a.k.a. attributes):
   <i>
    known
   </i>
   and
   <i>
    unknown
   </i>
   . We also assume knowledge of the set of possible values that each unknown attribute can take.
  </p>
<p block-type="TextInlineMath">
<span id="page-1-5">
</span>
<b>
    Definition 1
   </b>
   (DP
   <a href="#page-8-12">
    [13]
   </a>
   )
   <b>
    .
   </b>
<i>
    For
   </i>
   ≥ 0
   <i>
    , an algorithm is
   </i>
   -DP
   <i>
    if for every pair
   </i>
   , ′
   <i>
    of datasets that differ on the unknown attributes of one row
    <a href="#page-1-2">
     1
    </a>
    , and for every possible output , it holds that
   </i>
   Pr[() = ] ≤   ·Pr[( ′ ) = ]
   <i>
    .
   </i>
</p>
<p block-type="TextInlineMath">
<span id="page-1-7">
</span>
<b>
    Lemma 2
   </b>
   (Basic Composition)
   <b>
    .
   </b>
<i>
    Let be an algorithm that runs algorithms
   </i>
   1, . . . ,
   <i>
    on the same dataset such that is -DP with
   </i>
   ≥ 0
   <i>
    for each
   </i>
   ∈ []
   <i>
    . Then, is
   </i>
   ( ∑︀ =1 )
   <i>
    -DP.
   </i>
</p>
<p block-type="TextInlineMath">
<span id="page-1-6">
</span>
<b>
    Lemma 3
   </b>
   (Post-processing)
   <b>
    .
   </b>
<i>
    Let
   </i>
   &gt; 0
   <i>
    , and and
   </i>
   ′
   <i>
    be any two sets. If
   </i>
   :   →
   <i>
    is an -DP algorithm, and
   </i>
   :  →  ′
   <i>
    is any randomized mapping, then
   </i>
   ( ∘ ) :   →  ′
   <i>
    is -DP.
   </i>
</p>
<p block-type="Text">
   For an extensive overview of DP, we refer the reader to the monograph
   <a href="#page-8-13">
    [18]
   </a>
   . A commonly used method in DP is the discrete Laplace mechanism. To define it, we recall the notion of ℓ1-sensitivity.
  </p>
<p block-type="TextInlineMath">
<b>
    Definition 4
   </b>
   (ℓ1-sensitivity)
   <b>
    .
   </b>
<i>
    Let be any set, and
   </i>
   :   → R
   <i>
    be a -dimensional function. Its
   </i>
   ℓ1-sensitivity
   <i>
    is defined as
   </i>
   ∆1 := max,′ ‖()−( ′ )‖1
   <i>
    , where and
   </i>
   ′
   <i>
    are two datasets that differ on the unknown attributes of a single row.
   </i>
</p>
<p block-type="Text">
<span id="page-1-4">
</span>
<b>
    Definition 5
   </b>
   (Discrete Laplace Mechanism)
   <b>
    .
   </b>
<i>
    The
   </i>
   discrete Laplace distribution
   <i>
    centered at
   </i>
   0
   <i>
    and with parameter
   </i>
   &gt; 0
   <i>
    , denoted by
   </i>
   DLap()
   <i>
    , is the distribution whose
   </i>
</p>
<p block-type="TextInlineMath">
<i>
    probability mass function at integer is
   </i>
   −1 +1 ·  −||
   <i>
    . The
   </i>
   -dimensional discrete Laplace mechanism
   <i>
    with parameter applied to a function
   </i>
   :   → Z
   <i>
    , on input a dataset
   </i>
   ∈
   <i>
    , returns
   </i>
   () +
   <i>
    where is a  dimensional noise random variable whose coordinates are sampled i.i.d. from
   </i>
   DLap()
   <i>
    .
   </i>
</p>
<p block-type="TextInlineMath">
<b>
    Lemma 6.
   </b>
<i>
    For every
   </i>
   &gt; 0
   <i>
    , the -dimensional discrete Laplace mechanism with parameter
   </i>
   ≤ /∆1
   <i>
    is -DP.
   </i>
</p>
<h4>
<span id="page-1-1">
</span>
<b>
    2.2. Attribution Reporting API
   </b>
</h4>
<p block-type="Text">
   The
   <i>
    aggregatable reports
   </i>
<a href="#page-8-9">
    [10]
   </a>
   are constructed as follows:
  </p>
<p block-type="ListGroup">
</p><ul>
<li block-type="ListItem">
<b>
      Impression (a.k.a. source) registration:
     </b>
     The API provides a mechanism for the ad-tech to register an impression (e.g., a click or view) on the publisher site or app. During registration, the ad-tech can specify impression-side aggregation keys (e.g., one corresponding to the campaign or geo location).
    </li>
<li block-type="ListItem">
<b>
      Conversion (a.k.a. trigger) registration:
     </b>
     The API also provides a mechanism for the ad-tech to register a conversion on the advertiser site or app. As it does so, the ad-tech can specify conversion-side key pieces along with aggregatable values corresponding to each setting of the impression-side aggregation keys. E.g., a conversion-side key piece could capture the conversion type or (a discretization of) the conversion timestamp. The combined aggregation key (which can be thought of as the concatenation of the impression-side aggregation key and the conversion-side key piece) is restricted to be at most 128 bits. The aggregatable value is required to be an integer between 1 and the
     <sup>
      1
     </sup>
<i>
      parameter
     </i>
     of the API, which is set to 2
     <sup>
      16
     </sup>
     = 65,536.
    </li>
<li block-type="ListItem">
<b>
      Attribution:
     </b>
     The API supports last-touch attribution where the conversion is attributed to the last (unexpired) impression registered by the same ad-tech. (The API supports a broader family of single-touch attribution schemes allowing more flexible prioritization over impressions and conversions; we do not discuss this aspect any further as it is orthogonal to our algorithms.
     <a href="#page-1-3">
      2
     </a>
     )
    </li>
<li block-type="ListItem">
<b>
      Histogram contributions generation:
     </b>
     The API enforces that the sum of contributions across all aggregatable reports generated by different conversions attributed to the same impression is capped to at most the
     <sup>
      1
     </sup>
     = 2
     <sup>
      16
     </sup>
     parameter. An example construction of histogram contributions is in
     <a href="#page-2-1">
      Figure 2.
     </a>
     While in this example the conversion key piece depends only on conversion information (the conversion day), it can be
    </li>
</ul>
<p>
<span id="page-1-2">
</span>
<sup>
    1
   </sup>
   We note that this instantiation of the DP definition is related to the label DP setting in machine learning
   <a href="#page-8-14">
    [14,
   </a>
<a href="#page-8-15">
    15,
   </a>
<a href="#page-8-16">
    16,
   </a>
<a href="#page-8-17">
    17]
   </a>
   , where the features of an example are considered known and only its label is deemed unknown and sensitive. In our use case, there might be multiple unknown attributes, whose concatenation is treated in a conceptually similar way to the
   <i>
    label
   </i>
   in the label DP setting.
  </p>
<p>
<span id="page-1-3">
</span>
<sup>
    2
   </sup>
   The API moreover enforces a set of rate limits on registered impressions, and attributed conversions; we omit discussing these since they are not essential to the focus of this paper. We refer the interested reader to the documentation
   <a href="#page-8-18">
    [19]
   </a>
   .
  </p>
<p>
<img src="https://readwise-assets.s3.amazonaws.com/media/reader/parsed_document_assets/338242122/JqjEEbzjaCnF_GPbEWsckvaHSXsW-zITSC9DTfIzkyU-_pa_SF6ViRH.jpeg"/>
</p>
<p>
<b>
    Figure 2:
   </b>
   Histogram Contributions Generation.
  </p>
<p>
<span id="page-2-2">
</span>
<b>
    Table 1
   </b>
   Dataset Post-Attribution and Pre-Aggregation.
  </p>
<table>
<tbody>
<tr>
<th>
      Click
     </th>
<th>
      campaign
     </th>
<th>
      location
     </th>
<th>
      day
     </th>
</tr>
<tr>
<th>
      1
     </th>
<td>
      123
     </td>
<td>
      Paris
     </td>
<td>
      Monday
     </td>
</tr>
<tr>
<th>
      2
     </th>
<td>
      456
     </td>
<td>
      Chicago
     </td>
<td>
      Friday
     </td>
</tr>
<tr>
<th>
      3
     </th>
<td>
      789
     </td>
<td>
      London
     </td>
<td>
      *
     </td>
</tr>
<tr>
<th>
      4
     </th>
<td>
      123
     </td>
<td>
      New York
     </td>
<td>
      Friday
     </td>
</tr>
<tr>
<th>
      · · ·
     </th>
<td>
      · · ·
     </td>
<td>
      · · ·
     </td>
<td>
      · · ·
     </td>
</tr>
</tbody>
</table>
<p block-type="Text">
   replaced by an attribute that depends on both impression and conversion information (e.g., a discretization of the difference between impression time and conversion time); this can be done using filters
   <a href="#page-8-19">
    [20]
   </a>
   .
  </p>
<p block-type="Text">
   At query time, a set of histogram keys is requested by the ad-tech
   <a href="#page-8-20">
    [21]
   </a>
   . (The set of keys that are queried could be set to the Cartesian product of all
   <i>
    known
   </i>
   values of the impression-side features with the set of all
   <i>
    possible
   </i>
   values of the conversion-side features.) The aggregatable reports are combined in the aggregation service to produce a
   <i>
    summary report
   </i>
   by applying the discrete Laplace mechanism
   <a href="#page-1-4">
    (Definition 5)
   </a>
   with parameter /
   <sup>
    1
   </sup>
   to the requested aggregation keys. This report satisfies -DP where each row of the dataset corresponds to an impression and its attributed conversions if any (see
   <a href="#page-2-2">
    Table 1
   </a>
   for an example
   <a href="#page-2-3">
    3
   </a>
   ), and where the known columns in
   <a href="#page-1-5">
    Defini
   </a>
<a href="#page-1-5">
    tion 1
   </a>
   are the attributes that only depend on impression information (campaign and location in
   <a href="#page-2-2">
    Table 1)
   </a>
   .
  </p>
<p block-type="Text" class="has-continuation">
   In the hierarchical aggregation setting, each node of the tree corresponds to an aggregation key, and the level
  </p>
<p block-type="Text">
<span id="page-2-1">
</span>
   of the node is (implicitly) specified in the impression-side aggregation key and/or in the conversion-side key piece (as shown in
   <a href="#page-2-1">
    Figure 2)
   </a>
   .
  </p>
<p block-type="Text">
   For the use case of estimating conversion counts, the aggregatable value could be set so as to increment the count by +1. Since the scale of the noise injected in summary reports is 1/, the ad-tech can improve accuracy by setting the contribution of an increment to +
   <sup>
    1
   </sup>
   instead of +1 (and then scaling down the value it receives from the aggregation service by 1). If the
   <sup>
    1
   </sup>
   contribution has to be divided across multiple keys, the contribution of each increment needs to be scaled down accordingly. E.g., in
   <a href="#page-2-1">
    Figure 2,
   </a>
   since each impression affects 3 keys, the contribution is set to ⌊1/3⌋ = 21, 845.
  </p>
<h2>
<span id="page-2-0">
</span>
<b>
    3. Optimization Problem
   </b>
</h2>
<h3>
<b>
    3.1. Hierarchical Query Estimation
   </b>
</h3>
<p block-type="Text">
   We formally define the
   <i>
    hierarchical query estimation
   </i>
   problem. Given a dataset , consider a tree where each node corresponds to the subset of the rows of , conditioned on the values of some of the attributes. We consider the setting where each level of the tree introduces a conditioning on the value of a new attribute. For
   <i>
    known
   </i>
   attributes, the child nodes of a node correspond to the different values taken by that attribute in  within the rows. For
   <i>
    unknown
   </i>
   attributes, the child nodes correspond to
   <i>
    all
   </i>
   possible values for that attribute, whether or not they actually occur in the dataset. Given this tree, the problem is to privately release the approximate number of data rows corresponding to each node that have an attributed conversion.
  </p>
<p>
<span id="page-2-3">
</span>
<sup>
    3
   </sup>
   The * in the conversion-related field in
   <a href="#page-2-2">
    Table 1
   </a>
   indicates that the click corresponding to that row did not get an attributed conversion.
  </p>
<h4>
<b>
    3.2. Error Measure and Consistency
   </b>
</h4>
<p block-type="Text">
   We consider the following error measure, which is defined in
   <a href="#page-8-21">
    [22]
   </a>
   .
  </p>
<p block-type="TextInlineMath">
<b>
    Definition 7
   </b>
   (RMS Relative Error at Threshold)
   <b>
    .
   </b>
<i>
    For a count
   </i>
   ≥ 0
   <i>
    , and its randomized estimate
   </i>
   ˆ ∈ R
   <i>
    , the
   </i>
   Root Mean Squared Relative Error at Threshold
   <i>
    when estimating
   </i>
   √︃
   <i>
    by
   </i>
<sup>
    ˆ
   </sup>
<i>
    is defined as
   </i>
   RMSRE (, ˆ) :=
  </p>
<p block-type="TextInlineMath">
   E [︂(︁ |^−| max(,) )︁2 ]︂ ,
   <i>
    where the expectation is over the randomness of
   </i>
   ˆ
   <i>
    .
   </i>
</p>
<p block-type="Text">
   Suppose we have the count estimates (e.g., the number of conversions as in
   <a href="#page-0-0">
    Figure 1)
   </a>
   at every node in a tree. Each conversion contributes to the count for multiple nodes. For example, a conversion for ad campaign 123 that occurs on a Friday in New York contributes to the 6th leaf from the left, but also to each of its ancestor nodes. This imposes relationships among the counts at various nodes. If the only geo locations with conversions attributed to ad campaign 123 on Friday are New York and Chicago, then the total number of such conversions must equal the sum of the number of such conversions in each of the two locations. More generally, the count for any node must equal the sum of the counts for its children. An estimator with this property is called
   <i>
    consistent
   </i>
   .
  </p>
<p block-type="TextInlineMath">
   For a tree  with levels 0, . . ., , with  being the set of nodes at level , and estimators ˆ of the counts  at each node , define the tree error RMSRE () to be
  </p>
<p block-type="Equation">
<math display="block">
    \sqrt{\frac{1}{d+1}\sum_{i=0}^d \left(\frac{1}{|L_i|}\sum_{v\in L_i}\text{RMSRE}_{\tau}(c_v,\hat{c}_v)^2\right)}.
   </math>
</p>
<p block-type="Text">
   The goal of the hierarchical query estimation problem is to privately estimate the counts of every node with minimum possible tree error, where the estimates should be consistent. To achieve this, we will employ post-processing and privacy budgeting strategies.
  </p>
<h2>
<span id="page-3-0">
</span>
<b>
    4. Post-processing Algorithms
   </b>
</h2>
<p block-type="Text">
   Directly applying the discrete Laplace mechanism to add independent noise to each node does not result in a consistent estimate. Consistency can be achieved by estimating only the counts of leaves and inferring the count of each nonleaf node by adding the counts of its leaf descendants, but this can lead to large error for nodes higher up in the tree. Alternatively, one can achieve consistency by post-processing independent per-node estimates. Since DP is preserved under post-processing
   <a href="#page-1-6">
    (Lemma 3)
   </a>
   , this comes at no cost to the privacy guarantee, and it can substantially improve accuracy.
  </p>
<p block-type="TextInlineMath">
<span id="page-3-1">
</span>
<b>
    Input:
   </b>
   (; var), (; var) : ,  are samples from random variables ,  resp. such that E  = E  and variances Var() = var and Var( ) = var.
   <b>
    Output:
   </b>
   (; var) : combined estimate and variance.
  </p>
<p block-type="Equation">
<math display="block">
    \begin{array}{l} \mathsf{var}_z \leftarrow \frac{\mathsf{var}_x \cdot \mathsf{var}_y}{\mathsf{var}_x + \mathsf{var}_y} \\ z \leftarrow \mathsf{var}_z \cdot \left( \frac{x}{\mathsf{var}_x} + \frac{y}{\mathsf{var}_y} \right) \\ \mathsf{return} \ (z; \mathsf{var}_z) \end{array}
   </math>
</p>
<p block-type="Text">
   Since the count of any node must equal the sum of the counts of its children, we can obtain a second independent estimate of the count of any nonleaf node by summing the estimates of its children. We can combine these two estimates to obtain a single estimate of lower variance. Extending this observation, Hay et al.
   <a href="#page-8-10">
    [11]
   </a>
   and Cormode et al.
   <a href="#page-8-11">
    [12]
   </a>
   give efficient post-processing algorithms for regular (every non-leaf has the same number of children) and balanced (every leaf is at the same depth) trees, achieving consistency and also a substantial improvement in accuracy. In particular, estimating the counts of each node can be expressed as a linear regression problem, and these algorithms compute the least-squares solution, which is known to achieve optimal error variance among all unbiased linear estimators. Moreover, this special case of least-squares regression can be solved in linear time.
  </p>
<p block-type="TextInlineMath">
   We generalize this algorithm to arbitrary trees in
   <a href="#page-4-0">
    Al
   </a>
<a href="#page-4-0">
    gorithm 2.
   </a>
   This allows us to handle trees with different fanouts and noise at different levels or even at different nodes in the same level, which is the case for the conversion reporting trees we study. The input to the algorithm are independent noisy counts  for all nodes  in , with E  =  and variance Var() = var.
  </p>
<p block-type="TextInlineMath">
   The key idea is a simple method
   <a href="#page-3-1">
    (Algorithm 1)
   </a>
   to combine two
   <i>
    independent
   </i>
   and
   <i>
    unbiased
   </i>
   estimates of the same quantity to get an estimate with reduced variance as follows: Suppose  and  are two
   <i>
    independent
   </i>
   random variables with E  = E  = , with variances var and var respectively, then the optimal convex combination of  and  that minimizes the variance in the estimate of  is inversely proportional to the variances, namely  = (var · +var ·)/(var +var ), which has variance Var() = (var · var )/(var + var ).
  </p>
<p block-type="TextInlineMath">
<a href="#page-4-0">
    Algorithm 2
   </a>
   comprises of two linear-time passes. The first pass proceeds bottom-up from the leaves to the root. For each non-leaf node  it recursively computes  ↑  , which is an optimal linear unbiased estimate of , using only the noisy counts  for all  that are in the subtree rooted at ,
   <i>
    excluding
   </i>
   . This is combined with the noisy count  to compute  ⇑  , which is an optimal linear unbiased estimate of , using only the noisy counts  for all  that are in the sub-tree rooted at ,
   <i>
    including
   </i>
   .
  </p>
<p block-type="TextInlineMath">
<span id="page-4-0">
</span>
<b>
    Params:
   </b>
   Tree  with root .
   <b>
    Input:
   </b>
   (; var)∈ : noisy counts and variances for all  ∈ .
   <b>
    Output:
   </b>
   (̂︀; var ̂︁)∈ : post-processed estimates and variance for all .
   <i>
    # Bottom-up pass
   </i>
<b>
    for
   </b>
   leaf  ∈
   <b>
    do
   </b>
   ◁ ( ⇑  ; var⇑  ) ← (; var)
   <b>
    for
   </b>
   each internal node  from largest to smallest depth
   <b>
    do
   </b>
   ◁ ( ↑  ; var
   <sup>
    ↑
   </sup>
   ) ← (︁∑︀ ∈child()  ⇑  ; ∑︀ ∈child() var⇑  )︁ ◁ ( ⇑  ; var⇑  ) ← CombineEstimates((; var),( ↑  ; var
   <sup>
    ↑
   </sup>
   ))
   <i>
    # Top-down pass
   </i>
   For root :
   <sup>
    ◁
   </sup>
   (̂︀; var ̂︁)
   <sup>
    ←
   </sup>
   ( ⇑  ; var⇑  ) ◁ ( ⇓  ; var⇓  ) ← (; var)
   <b>
    for
   </b>
   each non-root node  from smallest to largest depth
   <b>
    do
   </b>
   ◁  ← parent() ◁ ( ↓  ; var
   <sup>
    ↓
   </sup>
   ) ← (︃  ⇓  − ∑︀ ∈child()∖{}  ⇑  ; var⇓  + ∑︀ ∈child()∖{} var⇑  )︃
   <i>
    # equals
   </i>
   ( ⇓  −  ↑  +  ⇑  ; var⇓  + var
   <sup>
    ↑
   </sup>
   − var⇑  )
   <sup>
    ◁
   </sup>
   (̂︀; var ̂︁)
   <sup>
    ←
   </sup>
   CombineEstimates(( ⇑  ; var⇑  ),( ↓  ; var
   <sup>
    ↓
   </sup>
   )) ◁ ( ⇓  ; var⇓  ) ← CombineEstimates((; var),( ↓  ; var
   <sup>
    ↓
   </sup>
   ))
   <b>
    return
   </b>
   (̂︀; var ̂︁)∈
  </p>
<p>
<img src="https://readwise-assets.s3.amazonaws.com/media/reader/parsed_document_assets/338242122/W7Y0VX51NZmXnk6oIG2W4bNq7sqCxRq9l4ro3cm2Qgg-_pa_WEDajAC.jpeg"/>
</p>
<p>
<b>
    Figure 3:
   </b>
   Intermediate variables in
   <a href="#page-4-0">
    Algorithm 2.
   </a>
</p>
<p block-type="TextInlineMath">
   The second pass proceeds top-down and computes for each non-root node , a estimate  ↓  , which is an optimal linear unbiased estimate of  using only the noisy counts  for all  that are
   <i>
    not
   </i>
   in the sub-tree rooted at . The estimates  ⇑  and  ↓  are then combined to obtain ̂︀, which is the optimal linear unbiased estimate of  using all the estimates  for all  in . To assist with the recursive procedure, it also computes an estimate  ⇓  , which is the optimal linear unbiased estimate of  using only the noisy counts  for all  that are not strictly in the sub-tree under  (i.e., includes ). See
   <a href="#page-4-1">
    Figure 3.
   </a>
</p>
<p block-type="Text">
<span id="page-4-3">
</span>
<a href="#page-4-0">
    Algorithm 2
   </a>
   not only reduces the variance of each estimate but also achieves the smallest possible variance among all unbiased linear estimators, simultaneously for all nodes.
  </p>
<p block-type="TextInlineMath">
<b>
    Theorem 8
   </b>
   (Optimality of Post-Processing)
   <b>
    .
   </b>
<i>
    For every
   </i>
<sup>
    ∈
   </sup>
<i>
    ,
   </i>
   ̂︀
   <i>
    is the best linear unbiased estimator (BLUE) of the count and has variance
   </i>
   var ̂︁
   <i>
    . In particular,
   </i>
   (̂︀)∈
   <i>
    minimizes
   </i>
   RMSRE (, ̂︀)
   <i>
    among all linear unbiased estimators, for all
   </i>
   ∈
   <i>
    .
   </i>
</p>
<p block-type="TextInlineMath">
<span id="page-4-1">
</span>
   This extends the results from
   <a href="#page-8-10">
    [11,
   </a>
<a href="#page-8-11">
    12]
   </a>
   , which work only for regular trees, to arbitrary trees. Similar to their proofs, the theorem above follows once we show that the (appropriately scaled) estimates (̂︀)∈ are an ordinary least squares estimator (OLS) of the counts ()∈ . Proving the latter boils down to showing that the estimates satisfy the two conditions in the following lemma:
  </p>
<p block-type="TextInlineMath">
<span id="page-4-2">
</span>
<b>
    Lemma 9.
   </b>
<i>
    For any and
   </i>
   (; var)∈
   <i>
    , let
   </i>
   (̂︀; var ̂︁)∈
   <i>
    be the output of
    <a href="#page-4-0">
     Algorithm 2.
    </a>
    Then, the following hold:
   </i>
</p>
<p block-type="ListGroup">
</p><ul>
<li block-type="ListItem">
<i>
      (Consistency) For all internal :
     </i>
     ̂︀
     <sup>
      =
     </sup>
     ∑︀ ∈child() ̂︀
     <i>
      .
     </i>
</li>
<li block-type="ListItem">
<i>
      (Weighted Root-to-Leaf Sum Preservation) For each leaf ,
     </i>
     ∑︀ ∈anc()  var = ∑︀ ∈anc() ̂︀ var
     <i>
      , where
     </i>
     anc()
     <i>
      denotes the nodes on the path from to (inclusive).
     </i>
</li>
</ul>
<p block-type="Text">
   The proof of
   <a href="#page-4-2">
    Lemma 9
   </a>
   is by induction on the number of nodes in the tree. The inductive step is done by selecting a node whose children are all leaves and "coalescing" all of the node's children. We provide the full proofs in
   <a href="#page-9-0">
    Appendix A.
   </a>
</p>
<h2>
<span id="page-5-0">
</span>
<b>
    5. Privacy Budgeting Over Tree Levels
   </b>
</h2>
<p block-type="Text">
   To allocate the privacy budget across the levels of the tree, the simplest approach is to divide it equally among the levels, or to put all of the budget on the lowest level. However, basic composition
   <a href="#page-1-7">
    (Lemma 2)
   </a>
   allows us to allocate the privacy budget arbitrarily among the nodes of the tree, and we can apply post-processing
   <a href="#page-4-0">
    (Algorithm 2)
   </a>
   to noisy initial estimates with unequal variances as well. This motivates the question of whether we can improve accuracy with an unequal privacy budget allocation, and if so, how.
  </p>
<p block-type="TextInlineMath">
   Given the true counts , we use a greedy iterative approach for optimizing the privacy budget allocation. Let  be the number of phases (e.g.,  = 20) corresponding to the granularity of the allocation. Initially allocate zero (or infinitesimal) privacy budget to each level, and divide the (remaining) privacy budget into  units of size /. In each of  phases, select the level that would result in the lowest RMSRE () when using / additional privacy budget, and increase the privacy budget of that level by /. The error RMSRE () can be computed directly using the variance var ̂︁ of each post-processed estimate ̂︀ as returned by
   <a href="#page-4-0">
    Algorithm 2.
   </a>
   We present the details of this greedy iterative approach in
   <a href="#page-11-0">
    Appendix B.
   </a>
</p>
<p block-type="Text">
   Using the true counts to optimize the privacy budget allocation can leak sensitive information and violate the privacy guarantee, and is infeasible in the API. Instead of using the true counts to allocate the privacy budget, one can use alternatives such as simulated data, or historical data that is not subject to the privacy constraints (e.g., before third-party cookie deprecation), or noisy historical data that has already been protected with DP (e.g., the output of the API over data from a previous time period). We refer to this family of privacy budget optimization methods as
   <i>
    prior-based
   </i>
   . When no such alternatives are available, one could start out with a suboptimal privacy budgeting strategy (e.g., uniform privacy budgeting across levels) and improve the allocation over time.
  </p>
<h2>
<span id="page-5-1">
</span>
<b>
    6. Experimental Evaluation
   </b>
</h2>
<p block-type="Text">
   We evaluate the algorithms on two public ad conversion datasets.
  </p>
<p block-type="Text" class="has-continuation">
<b>
    Criteo Sponsored Search Conversion Log (CSSCL) Dataset
    <a href="#page-8-22">
     [23]
    </a>
</b>
   This dataset contains 15,995,634 clicks obtained from a sample of 90-day logs of live traffic from Criteo Predictive Search. Each point contains information on a user action (e.g., time of click on an ad) and a potential subsequent conversion (purchase of the corresponding product) within a 30-day attribution window. We consider the attributes: partner_id, prod-
  </p>
<p block-type="Text">
   uct_country, device_type, product_age_group &amp; time_delay_for_conversion. The last attribute is discretized into 2-day (or 6-day) buckets so that there are at most 15 (5 respectively) possible values of the rounded time delay. The first 4 attributes are considered
   <i>
    known
   </i>
   (they only relate to the impression), whereas the last is considered
   <i>
    unknown
   </i>
   . For the discretization into 6-day buckets, we retain the unknown attribute and 3 known attributes instead of 4 (omitting product_age_group), resulting in a depth 4 tree (instead of depth 5).
  </p>
<p block-type="Text">
   In
   <a href="#page-6-1">
    Figure 4,
   </a>
   we plot RMSRE versus  for various different methods evaluated on the later 45 days of data, namely,
  </p>
<p block-type="ListGroup">
</p><ul>
<li block-type="ListItem">
     Equal privacy budget split across levels without any post-processing.
    </li>
<li block-type="ListItem">
     Equal privacy budget split across levels with postprocessing
     <a href="#page-4-0">
      (Algorithm 2)
     </a>
     .
    </li>
<li block-type="ListItem">
     All privacy budget on leaves with post-processing.
    </li>
<li block-type="ListItem">
     Prior-based optimized privacy budget split across levels optimized for each partner_id without any postprocessing.
    </li>
<li block-type="ListItem">
     Prior-based optimized privacy budget split across levels optimized for each partner_id with post-processing
     <a href="#page-4-0">
      (Algorithm 2)
     </a>
     .
    </li>
</ul>
<p block-type="TextInlineMath">
   For the prior-based privacy budget split optimization, the privacy budgeting was performed using a noisy prior computed on the first 45 days (privately estimated with  = 1 and an equal privacy budget split over levels). For partner_id's that appear only in the later 45 days, the prior is computed on all the partner_id's that appear in the first 45 days of data. E.g., for  = 4 and the depth 5 tree, RMSRE
   <sup>
    10
   </sup>
   ≈ 0.1, and for the depth 4 tree, RMSRE
   <sup>
    5
   </sup>
   ≈ 0.17.
  </p>
<p block-type="TextInlineMath">
<b>
    Criteo Attribution Modeling for Bidding (CAMB) Dataset
    <a href="#page-8-23">
     [24]
    </a>
</b>
   It consists of ∼16M impressions from 30 days of Criteo live traffic. We consider last-touch attribution with impression attributes: campaign, categorical features cat1, cat8, and a discretization of conversion delay, i.e., the gap between conversion_timestamp and (impression) timestamp. As for CSSCL, we consider two discretizations for the difference, with two tree depths.
   <a href="#page-7-0">
    Figure 5
   </a>
   shows the plots for CAMB. The privacy budgeting was performed similarly to CSSCL but with the noisy prior computed on the first 15 days. For  = 4 and the depth 4 tree, RMSRE
   <sup>
    10
   </sup>
   ≈ 0.19, and for the depth 3 tree (omitting attribute cat8), RMSRE
   <sup>
    5
   </sup>
   ≈ 0.20 and RMSRE
   <sup>
    10
   </sup>
   ≈ 0.12.
  </p>
<p block-type="Text">
   Our prior-based budgeting with post-processing method equals or outperforms all other approaches in each setting
   <a href="#page-6-1">
    (Figures 4
   </a>
   and
   <a href="#page-7-0">
    5)
   </a>
   .
  </p>
<p>
<img src="https://readwise-assets.s3.amazonaws.com/media/reader/parsed_document_assets/338242122/HmZp-s5EIPRzDHZtl0xSy_YGFujl4PWR92d4AwtsyKI-_pa_x4e9NEX.jpeg"/>
</p>
<p>
<span id="page-6-1">
</span>
<b>
    Figure 4:
   </b>
   RMSRE () vs  for  ∈ {5, 10} on CSSCL dataset, with noisy prior obtained via equal budget split and  = 1.
  </p>
<h2>
<span id="page-6-0">
</span>
<b>
    7. Conclusion and Future Directions
   </b>
</h2>
<p block-type="Text" class="has-continuation">
   In this work, we studied hierarchical querying of the Attribution Reporting API, and presented algorithms for consistency enforcement and privacy budgeting, demonstrating their performance on two public ad datasets. We next discuss some interesting future directions. We focused on the so-called OPC ("one per click") setting where each impression gets at most a single attributed conversion. An important direction is to consider the extension to the more general MPC ("many per click") setting where an impression can get multiple attributed conversions. It would also be interesting to extend our treatment of conversion counts to the task of estimating conversion values. While the error is small for values of  around 16 in our evaluation, we note that this is specific to the datasets and the (restricted) functionality that we study (i.e., conversion counts with OPC). Achieving small errors on additional functionalities (e.g., MPC or conversion values) will likely require larger values of .
  </p>
<p block-type="Text">
   Another natural direction is to extend the consistency enforcement algorithm to ensure monotonicity (i.e., that the output estimate for a node of the tree is at least the output estimate for any of its children), and non-negativity. Our privacy budgeting method optimizes for one privacy parameter
   <i>
    per-level
   </i>
   of the tree; it would be good to explore the extent to which
   <i>
    per-node
   </i>
   privacy budgeting can yield higher accuracy. While we considered
   <i>
    data-independent
   </i>
   weights when defining the tree error in terms of the node errors, there could be situations where
   <i>
    data-dependent
   </i>
   weights are preferable, e.g., to avoid the tree error being dominated by the error in many nodes with no conversions, while being insensitive to the error of few nodes where most of the conversions occur. Another interesting direction to study privacy budgeting under approximate DP
   <a href="#page-8-24">
    [25]
   </a>
   . Our work considered the hierarchical query model; a natural direction is to optimize the
   <i>
    direct query model
   </i>
<a href="#page-8-25">
    [26]
   </a>
   . Finally, the Attribution Reporting API also offers
   <i>
    event-level reports
   </i>
<a href="#page-8-26">
    [27]
   </a>
   . It would be interesting to see if these could be also used to further improve the accuracy for hierarchical queries.
  </p>
<p>
<img src="https://readwise-assets.s3.amazonaws.com/media/reader/parsed_document_assets/338242122/4wE4pSEFXqw3CPM2HJ8q9BE0eVKPZ66pl6uCq8D4JA0-_pa_JL3xq3q.jpeg"/>
</p>
<p>
<span id="page-7-0">
</span>
<b>
    Figure 5:
   </b>
   RMSRE () vs  for  ∈ {5, 10} on CAMB dataset with noisy prior obtained via equal budget split and  = 1.
  </p>
<h2>
<b>
    References
   </b>
</h2>
<p block-type="ListGroup" class="has-continuation">
</p><ul>
<li block-type="ListItem">
<span id="page-8-0">
</span>
     [1] Wikipedia, HTTP cookie: third-party cookie,
     <a href="https://en.wikipedia.org/wiki/HTTP_cookie#Third-party_cookie">
      https:
     </a>
<a href="https://en.wikipedia.org/wiki/HTTP_cookie#Third-party_cookie">
      //en.wikipedia.org/wiki/HTTP_cookie#Third-par
     </a>
<a href="https://en.wikipedia.org/wiki/HTTP_cookie#Third-party_cookie">
      ty_cookie,
     </a>
     2023.
    </li>
<li block-type="ListItem">
<span id="page-8-1">
</span>
     [2] Q. Lu, S. Pan, L. Wang, J. Pan, F. Wan, H. Yang, A practical framework of conversion rate prediction for online display advertising, in: AdKDD, 2017.
    </li>
<li block-type="ListItem">
<span id="page-8-2">
</span>
     [3] Y. Choi, M. Kwon, Y. Park, J. Oh, S. Kim, Delayed feedback model with negative binomial regression for multiple conversions, in: AdKDD, 2020.
    </li>
<li block-type="ListItem">
<span id="page-8-3">
</span>
     [4] Y. Qiu, N. Tziortziotis, M. Hue, M. Vazirgiannis, Predicting conversions in display advertising based on URL embeddings, in: AdKDD, 2020.
    </li>
<li block-type="ListItem">
<span id="page-8-4">
</span>
     [5] T. Gu, K. Kuang, H. Zhu, J. Li, Z. Dong, W. Hu, Z. Li, X. He, Y. Liu, Estimating true post-click conversion via group-stratified counterfactual inference, in: AdKDD, 2021.
    </li>
<li block-type="ListItem">
<span id="page-8-5">
</span>
     [6] J. Wilander, Full Third-Party Cookie Blocking and More, 2020.
     <a href="https://webkit.org/blog/10218/full-third-party-cookie-blocking-and-more/">
      https://webkit.org/blog/10218/full-thi
     </a>
<a href="https://webkit.org/blog/10218/full-third-party-cookie-blocking-and-more/">
      rd-party-cookie-blocking-and-more/.
     </a>
</li>
<li block-type="ListItem">
<span id="page-8-6">
</span>
     [7] M. Wood, Today's Firefox Blocks Third-Party Tracking Cookies and Cryptomining by Default, 2019.
     <a href="https://blog.mozilla.org/en/products/firefox/todays-firefox-blocks-third-party-tracking-cookies-and-cryptomining-by-default/">
      https://blog.mozilla.org/en/products/firefox/tod
     </a>
<a href="https://blog.mozilla.org/en/products/firefox/todays-firefox-blocks-third-party-tracking-cookies-and-cryptomining-by-default/">
      ays-firefox-blocks-third-party-tracking-cookies
     </a>
<a href="https://blog.mozilla.org/en/products/firefox/todays-firefox-blocks-third-party-tracking-cookies-and-cryptomining-by-default/">
      -and-cryptomining-by-default/.
     </a>
</li>
<li block-type="ListItem">
<span id="page-8-7">
</span>
     [8] J. Schuh, Building a more private web: A path towards making third party cookies obsolete, 2020.
     <a href="https://blog.chromium.org/2020/01/building-more-private-web-path-towards.html">
      https://blog.chromium.org/2020/01/building-mor
     </a>
<a href="https://blog.chromium.org/2020/01/building-more-private-web-path-towards.html">
      e-private-web-path-towards.html.
     </a>
</li>
<li block-type="ListItem">
<span id="page-8-8">
</span>
     [9] M. Nalpas, A. White, Attribution Reporting, 2021.
     <a href="https://developer.chrome.com/en/docs/privacy-sandbox/attribution-reporting/">
      https://developer.chrome.com/en/docs/privacy-s
     </a>
<a href="https://developer.chrome.com/en/docs/privacy-sandbox/attribution-reporting/">
      andbox/attribution-reporting/.
     </a>
</li>
<li block-type="ListItem">
<span id="page-8-9">
</span>
     [10] Attribution reporting: Aggregatable reports API, 2021.
     <a href="https://developer.android.com/design-for-safety/privacy-sandbox/attribution#aggregatable-reports-api">
      https://developer.android.com/design-for-s
     </a>
<a href="https://developer.android.com/design-for-safety/privacy-sandbox/attribution#aggregatable-reports-api">
      afety/privacy-sandbox/attribution#aggregatable-r
     </a>
<a href="https://developer.android.com/design-for-safety/privacy-sandbox/attribution#aggregatable-reports-api">
      eports-api.
     </a>
</li>
<li block-type="ListItem">
<span id="page-8-10">
</span>
     [11] M. Hay, V. Rastogi, G. Miklau, D. Suciu, Boosting the accuracy of differentially-private histograms through consistency, in: VLDB, 2010, pp. 1021– 1032.
    </li>
<li block-type="ListItem">
<span id="page-8-11">
</span>
     [12] G. Cormode, C. Procopiuc, D. Srivastava, E. Shen, T. Yu, Differentially private spatial decompositions, in: ICDE, 2012, pp. 20–31.
    </li>
<li block-type="ListItem">
<span id="page-8-12">
</span>
     [13] C. Dwork, F. McSherry, K. Nissim, A. D. Smith, Calibrating noise to sensitivity in private data analysis, in: TCC, 2006, pp. 265–284.
    </li>
<li block-type="ListItem">
<span id="page-8-14">
</span>
     [14] K. Chaudhuri, C. Monteleoni, A. D. Sarwate, Differentially private empirical risk minimization., JMLR 12 (2011).
    </li>
</ul>
<p block-type="ListGroup">
</p><ul>
<li block-type="ListItem">
<span id="page-8-15">
</span>
     [15] B. Ghazi, N. Golowich, R. Kumar, P. Manurangsi, C. Zhang, Deep learning with label differential privacy, in: NeurIPS, 2021, pp. 27131–27145.
    </li>
<li block-type="ListItem">
<span id="page-8-16">
</span>
     [16] H. Esfandiari, V. Mirrokni, U. Syed, S. Vassilvitskii, Label differential privacy via clustering, in: AIS-TATS, 2022, pp. 7055–7075.
    </li>
<li block-type="ListItem">
<span id="page-8-17">
</span>
     [17] B. Ghazi, P. Kamath, R. Kumar, E. Leeman, P. Manurangsi, A. Varadarajan, C. Zhang, Regression with label differential privacy, in: ICLR, 2023. URL:
     <a href="https://openreview.net/pdf?id=h9O0wsmL-cT">
      https://openreview.net/pdf?id=h9O0wsmL-cT.
     </a>
</li>
<li block-type="ListItem">
<span id="page-8-13">
</span>
     [18] C. Dwork, A. Roth, et al., The algorithmic foundations of differential privacy, Foundations and Trends® in Theoretical Computer Science 9 (2014) 211–407.
    </li>
<li block-type="ListItem">
<span id="page-8-18">
</span>
     [19] Attribution Reporting Draft Community Group Report, 2021.
     <a href=" https://wicg.github.io/attribution-reporting-api/">
      https://wicg.github.io/attribution-repor
     </a>
<a href=" https://wicg.github.io/attribution-reporting-api/">
      ting-api/.
     </a>
</li>
<li block-type="ListItem">
<span id="page-8-19">
</span>
     [20] Attribution reporting: Trigger filters, 2021.
     <a href=" https://developer.android.com/design-for-safety/privacy-sandbox/attribution#trigger-filters">
      https:
     </a>
<a href=" https://developer.android.com/design-for-safety/privacy-sandbox/attribution#trigger-filters">
      //developer.android.com/design-for-safety/privac
     </a>
<a href=" https://developer.android.com/design-for-safety/privacy-sandbox/attribution#trigger-filters">
      y-sandbox/attribution#trigger-filters.
     </a>
</li>
<li block-type="ListItem">
<span id="page-8-20">
</span>
     [21] Set up Aggregation Service for Aggregatable Reports: Collect and Batch Aggregatable Reports, 2021.
     <a href=" https://github.com/privacysandbox/aggregation-service#collect-and-batch-aggregatable-reports">
      https://github.com/privacysandbox/aggr
     </a>
<a href=" https://github.com/privacysandbox/aggregation-service#collect-and-batch-aggregatable-reports">
      egation-service#collect-and-batch-aggregatable-r
     </a>
<a href=" https://github.com/privacysandbox/aggregation-service#collect-and-batch-aggregatable-reports">
      eports.
     </a>
</li>
<li block-type="ListItem">
<span id="page-8-21">
</span>
     [22] A. Nadan, A. White, A. Cucu, M. Nalpas, Z. Mastromatto, Experiment with summary report design decisions, 2022.
     <a href="https://developer.chrome.com/docs/privacy-sandbox/summary-reports/design-decisions/">
      https://developer.chrome.com/doc
     </a>
<a href="https://developer.chrome.com/docs/privacy-sandbox/summary-reports/design-decisions/">
      s/privacy-sandbox/summary-reports/design-dec
     </a>
<a href="https://developer.chrome.com/docs/privacy-sandbox/summary-reports/design-decisions/">
      isions/.
     </a>
</li>
<li block-type="ListItem">
<span id="page-8-22">
</span>
     [23] M. Tallis, P. Yadav, Reacting to variations in product demand: An application for conversion rate (CR) prediction in sponsored search, in: IEEE BigData, 2018, pp. 1856–1864.
    </li>
<li block-type="ListItem">
<span id="page-8-23">
</span>
     [24] J. Meynet, Criteo attribution modeling for bidding dataset, 2017.
     <a href=" https://ailab.criteo.com/criteo-attribution-modeling-bidding-dataset/">
      https://ailab.criteo.com/criteo-attri
     </a>
<a href=" https://ailab.criteo.com/criteo-attribution-modeling-bidding-dataset/">
      bution-modeling-bidding-dataset/.
     </a>
</li>
<li block-type="ListItem">
<span id="page-8-24">
</span>
     [25] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, M. Naor, Our data, ourselves: Privacy via distributed noise generation, in: EUROCRYPT, 2006, pp. 486–503.
    </li>
<li block-type="ListItem">
<span id="page-8-25">
</span>
     [26] Privacy Sandbox Aggregation Service: Query Models, 2021.
     <a href=" https://github.com/google/privacy-sandbox-aggregation-service#query-models">
      https://github.com/google/privacy-sandb
     </a>
<a href=" https://github.com/google/privacy-sandbox-aggregation-service#query-models">
      ox-aggregation-service#query-models.
     </a>
</li>
<li block-type="ListItem">
<span id="page-8-26">
</span>
     [27] Attribution Reporting: Event-level Reports, 2021.
     <a href=" https://developer.android.com/design-for-safety/privacy-sandbox/attribution#event-level-reports">
      https://developer.android.com/design-for-safety/
     </a>
<a href=" https://developer.android.com/design-for-safety/privacy-sandbox/attribution#event-level-reports">
      privacy-sandbox/attribution#event-level-reports.
     </a>
</li>
<li block-type="ListItem">
<span id="page-8-27">
</span>
     [28] S. Silvey, Statistical Inference, Chapman &amp; Hall/CRC Monographs on Statistics &amp; Applied Probability, Taylor &amp; Francis, 1975.
    </li>
</ul>
<h2>
<span id="page-9-0">
</span>
<b>
    A. Proof of Least Squares Optimality
   </b>
</h2>
<p block-type="Text">
   We provide the proof of
   <a href="#page-4-3">
    Theorem 8,
   </a>
   starting with the proof of
   <a href="#page-4-2">
    Lemma 9,
   </a>
   restated below for convenience.
  </p>
<p block-type="Text">
<b>
    Lemma 9.
   </b>
<i>
    For any and
   </i>
   (; var)∈
   <i>
    , let
   </i>
   (̂︀; var ̂︁)∈
   <i>
    be the output of
    <a href="#page-4-0">
     Algorithm 2.
    </a>
    Then, the following hold:
   </i>
</p>
<p block-type="ListGroup">
</p><ul>
<li block-type="ListItem">
<i>
      (Consistency) For all internal :
     </i>
     ̂︀
     <sup>
      =
     </sup>
     ∑︀ ∈child() ̂︀
     <i>
      .
     </i>
</li>
<li block-type="ListItem">
<i>
      (Weighted Root-to-Leaf Sum Preservation) For each leaf ,
     </i>
     ∑︀ ∈anc()  var = ∑︀ ∈anc() ̂︀ var
     <i>
      , where
     </i>
     anc()
     <i>
      denotes the nodes on the path from to (inclusive).
     </i>
</li>
</ul>
<p block-type="Text">
<i>
    Proof.
   </i>
   We will prove this by (strong) induction on the number of nodes in . The base case where  has a single node is immediate as the bottom-up and top-down passes are vacuous. We use the inductive hypothesis that both
   <i>
    consistency
   </i>
   and
   <i>
    weighted root-to-leaf sum preservation
   </i>
   properties hold for the output of
   <a href="#page-4-0">
    Algorithm 2
   </a>
   on any tree of at most  nodes for  ∈ N.
  </p>
<p block-type="TextInlineMath">
   Let  be any tree with  + 1 nodes. For any input (; var)∈ , let ( ↑  ; var
   <sup>
    ↑
   </sup>
   ), ( ⇑  ; var⇑  ), ( ↓  ; var
   <sup>
    ↓
   </sup>
   ), ( ⇓  ; var⇓  ), (̂︀; var ̂︁) be the values computed by
   <a href="#page-4-0">
    Algo
   </a>
<a href="#page-4-0">
    rithm 2
   </a>
   for every  ∈
  </p>
<p block-type="TextInlineMath">
   Let  * be any internal node whose children are all leaves, and  ′ denote the tree with its children removed. For all  ∈  ′ , define
  </p>
<p block-type="Equation">
<math display="block">
    (x'_v; \mathsf{var}'_v) = \begin{cases} (x_v; \mathsf{var}_v) &amp; \text{if } v \neq v^*, \\ (z_v^{\Uparrow}; \mathsf{var}_v^{\Uparrow}) &amp; \text{if } v = v^*. \end{cases} \tag{1}
   </math>
</p>
<p block-type="TextInlineMath">
   Similar to above, let( ′  ↑ ; var′  ↑ ),( ′  ⇑ ; var′  ⇑ ),( ′  ↓ ; var′  ↓ ), ( ′  ⇓ ; var′  ⇓ ), (̂︀ ′ ; var ̂︁′ ) be as defined in
   <a href="#page-4-0">
    Algorithm 2
   </a>
   when run on the tree  ′ with input( ′ ; var′ )∈ ′ . From
  </p>
<p block-type="TextInlineMath">
   the inductive hypothesis, for all internal nodes  ∈  ′ , we have
  </p>
<p block-type="Equation">
<math display="block">
    \widehat{x}'_v = \sum_{u \in \text{child}(v)} \widehat{x}'_u,\tag{2}
   </math>
</p>
<p block-type="Text">
   and for every leaf  ∈  ′ , we have
  </p>
<p block-type="Equation">
<math display="block">
    \sum_{u \in \text{anc}(v)} \frac{x'_u}{\text{var}_u'} = \sum_{u \in \text{anc}(v)} \frac{\widehat{x}'_u}{\text{var}_u'}.
   </math>
   (3)
  </p>
<p block-type="TextInlineMath">
   When we run
   <a href="#page-4-0">
    Algorithm 2
   </a>
   on , after setting  ⇑ * and var ↑ * , the rest of the bottom-up pass is exactly the same as that of the run on  ′ . Similarly, the top-down pass of  ′ is the same as that of  except that in  we also set the values of ̂︀ and var ̂︁ for all
   <sup>
    ∈
   </sup>
   child( * ). Therefore,
  </p>
<span id="page-9-1">
</span>
<p block-type="Equation">
<math display="block">
    \widehat{x}_v = \begin{cases}\n\widehat{x}_v' &amp; \text{if } v \notin \text{child}(v^*), \\
\frac{\text{var}_v^{\perp} \cdot x_v + \text{var}_v \cdot z_v^{\perp}}{\text{var}_v^{\perp} + \text{var}_v} &amp; \text{if } v \in \text{child}(v^*),\n\end{cases} \tag{4}
   </math>
</p>
<p block-type="Text">
   where
  </p>
<p block-type="Equation">
<math display="block">
    (z_v^{\downarrow}; \mathsf{var}_v^{\downarrow}) \ = \ (\widehat{x}_{v^*} - z_{v^*}^{\uparrow} + x_v; \widehat{\mathsf{var}}_{v^*} + \mathsf{var}_v^{\uparrow} - \mathsf{var}_v).
   </math>
</p>
<p block-type="TextInlineMath">
   Here we used the observation that for all leaves  of  ′ (including  * ), it holds that ( ′  ⇑ ; var′  ⇑ ) = (; var) and hence ( ′  ⇓ ; var′  ⇓ ) = (̂︀ ′ ; var ̂︁′ ) = (̂︀; var ̂︁).
  </p>
<p block-type="TextInlineMath">
<b>
    (Consistency)
   </b>
   For  ̸=  * ,
   <a href="#page-9-1">
    Equation (4)
   </a>
   implies that the LHS and RHS of the desired consistency condition is exactly the same as that of
   <a href="#page-9-2">
    Equation (2).
   </a>
   So it only remains to show consistency for  =  * . First, we simplify
   <a href="#page-9-1">
    Equation (4)
   </a>
   by noting that var
   <sup>
    ↓
   </sup>
   +var = var ⇓ * +var ↑ * for all  ∈ child( * ), and hence for  ∈ child( * ) we have
  </p>
<span id="page-9-4">
</span>
<p block-type="Equation">
<math display="block">
    \hat{x}_v = x_v + \frac{\mathsf{var}_v}{\mathsf{var}_v^{\downarrow} + \mathsf{var}_v^{\uparrow}} \left( z_{v^*}^{\downarrow} - z_{v^*}^{\uparrow} \right)
   </math>
   \n
   <math display="block">
    = x_v + \frac{\mathsf{var}_v}{\mathsf{var}_v^{\uparrow}} \left( \frac{\mathsf{var}_v^{\downarrow} z_{v^*}^{\downarrow} + \mathsf{var}_v^{\downarrow} z_{v^*}^{\uparrow}}{\mathsf{var}_v^{\downarrow} z_{v^*}^{\downarrow} + \mathsf{var}_v^{\uparrow} z_{v^*}^{\uparrow}} - z_{v^*}^{\uparrow} \right)
   </math>
   \n
   <math display="block">
    = x_v + \frac{\mathsf{var}_v}{\mathsf{var}_v^{\uparrow}} \left( \hat{x}_{v^*} - z_{v^*}^{\uparrow} \right).
   </math>
</p>
<p block-type="Text">
   Hence, we have
  </p>
<span id="page-9-2">
</span>
<p block-type="Equation">
<math display="block">
    \sum_{u \in \text{child}(v^*)} \hat{x}_u
   </math>
   \n
   <math display="block">
    = \sum_{u \in \text{child}(v^*)} \left( x_u + \frac{\text{var}_u}{\text{var}_v^{\uparrow}} \cdot (\hat{x}_{v^*} - z_{v^*}^{\uparrow}) \right)
   </math>
   \n
   <math display="block">
    = \hat{x}_{v^*}
   </math>
</p>
<p block-type="TextInlineMath">
<span id="page-9-3">
</span>
   where we use that  ↑ * = ∑︀ ∈child(*) . Thus, the consistency condition holds for every internal node  ∈ as desired.
  </p>
<p block-type="TextInlineMath">
<b>
    (Weighted Root-to-Leaf Sum Preservation)
   </b>
   Again, for  ̸=  * ,
   <a href="#page-9-1">
    Equation (4)
   </a>
   and
   <a href="#page-9-3">
    Equation (3)
   </a>
   imply the weighted root-to-leaf sum preservation property for all leaves  /∈ child( * ). Meanwhile, for  ∈ child( * ), we have
  </p>
<p block-type="Equation">
<math display="block">
    \sum_{u \in \text{anc}(v)} \frac{\widehat{x}_u}{\text{var}_u}
   </math>
   \n
   <math display="block">
    = \frac{\widehat{x}_v}{\text{var}_v} + \frac{\widehat{x}_{v^*}}{\text{var}_{v^*}} - \frac{\widehat{x}_{v^*}}{\text{var}_{v^*}^0} + \sum_{u \in \text{anc}(v^*)} \frac{\widehat{x}_u'}{\text{var}_u'}
   </math>
   \n
   <math display="block">
    \stackrel{(3)}{=} \frac{\widehat{x}_v}{\text{var}_v} + \frac{\widehat{x}_{v^*}}{\text{var}_{v^*}} - \frac{\widehat{x}_{v^*}}{\text{var}_{v^*}^0} + \sum_{u \in \text{anc}(v^*)} \frac{x_u'}{\text{var}_u'}
   </math>
   \n
   <math display="block">
    \stackrel{(1)}{=} \frac{\widehat{x}_v}{\text{var}_v} + \frac{\widehat{x}_{v^*}}{\text{var}_{v^*}} - \frac{\widehat{x}_{v^*}}{\text{var}_{v^*}^0} - \frac{x_{v^*}}{\text{var}_{v^*}^0} + \frac{z_{v^*}^{\dagger}}{\text{var}_{v^*}^0}
   </math>
   \n
   <math display="block">
    + \sum_{u \in \text{anc}(v^*)} \frac{x_u}{\text{var}_u}. \tag{5}
   </math>
</p>
<p block-type="Text">
   Recall that
  </p>
<p block-type="Equation">
<math display="block">
    \begin{array}{lcl} \mathsf{var}^{\Uparrow}_{v^{*}} &amp; = &amp; \frac{\mathsf{var}_{v^{*}} \cdot \mathsf{var}^{\uparrow}_{v^{*}}}{\mathsf{var}_{v^{*}} + \mathsf{var}^{\uparrow}_{v^{*}}} \, , \\ &amp; &amp; \\ \widehat{x}_{v} &amp; = &amp; x_{v} + \frac{\mathsf{var}_{v}}{\mathsf{var}^{\uparrow}_{v^{*}}} \left( \widehat{x}_{v^{*}} - z^{\uparrow}_{v^{*}} \right), \\ &amp; &amp; \\ z^{\Uparrow}_{v^{*}} &amp; = &amp; \mathsf{var}^{\Uparrow}_{v^{*}} \cdot \left( \frac{x_{v^{*}}}{\mathsf{var}_{v^{*}}} + \frac{z^{\uparrow}_{v^{*}}}{\mathsf{var}^{\uparrow}_{v^{*}}} \right). \end{array}
   </math>
</p>
<p block-type="Text">
   Hence the first five terms in
   <a href="#page-10-0">
    Equation (5)
   </a>
   can be written as
  </p>
<p block-type="Equation">
<math display="block">
    \frac{\widehat{x}_v}{\text{var}_v} + \frac{\widehat{x}_{v^*}}{\text{var}_{v^*}} - \frac{\widehat{x}_{v^*}}{\text{var}_{v^*}} - \frac{x_{v^*}}{\text{var}_{v^*}} + \frac{z_{v^*}^{\uparrow}}{\text{var}_{v^*}^{\uparrow}}
   </math>
   \n
   <math display="block">
    = \frac{1}{\text{var}_v} \left( x_v + \frac{\text{var}_v}{\text{var}_{v^*}^{\uparrow}} \cdot (\widehat{x}_{v^*} - z_{v^*}^{\uparrow}) \right)
   </math>
   \n
   <math display="block">
    + \frac{\widehat{x}_{v^*}}{\text{var}_{v^*}} - \frac{\text{var}_{v^*} + \text{var}_{v^*}^{\uparrow}}{\text{var}_{v^*}^{\uparrow}} \cdot \widehat{x}_{v^*} - \frac{x_{v^*}}{\text{var}_{v^*}}
   </math>
   \n
   <math display="block">
    + \frac{x_{v^*}}{\text{var}_{v^*}} + \frac{z_{v^*}^{\uparrow}}{\text{var}_{v^*}^{\uparrow}} + \frac{z_{v^*}^{\uparrow}}{\text{var}_{v^*}^{\uparrow}}
   </math>
   \n
   <math display="block">
    = \frac{x_v}{\text{var}_{v^*}}.
   </math>
</p>
<p block-type="Text">
   Thus, we get that
  </p>
<p block-type="Equation">
<math display="block">
    \sum_{u \in \text{anc}(v)} \frac{\widehat{x}_u}{\textsf{var}_u} \ = \ \sum_{u \in \text{anc}(v)} \frac{x_u}{\textsf{var}_u},
   </math>
</p>
<p block-type="TextInlineMath">
   holds for all  ∈ . This completes our proof.
  </p>
<p block-type="Text">
<span id="page-10-1">
</span>
   We additionally need the Gauss–Markov theorem stated below for noise with non-uniform diagonal covariance.
  </p>
<p block-type="TextInlineMath">
<b>
    Theorem 10
   </b>
   (Gauss–Markov (see e.g.,
   <a href="#page-8-27">
    [28]
   </a>
   ))
   <b>
    .
   </b>
<i>
    Fix
   </i>
   ∈ R ×
   <i>
    . For an unknown
   </i>
   ∈ R
   <i>
    , suppose we observe
   </i>
   =  +
   <i>
    where
   </i>
   ∈ R
   <i>
    is drawn such that 's are independent with
   </i>
   E  = 0
   <i>
    and variance
   </i>
   var
   <i>
    respectively. Then, the least squares estimator
   </i>
   ˆ
   <i>
    defined as the minimizer of
   </i>
   ∑︀  ( − (ˆ)) 2 /var
   <i>
    , is the best unbiased linear estimator (BLUE), namely, for all
   </i>
   ∈ R
   <i>
    it holds that
   </i>
   Var(   ˆ)
   <i>
    is the smallest among all linear unbiased estimators of
   </i>
<sup>
    ⊤
   </sup>
<i>
    .
   </i>
</p>
<p block-type="Text">
   Finally, we prove
   <a href="#page-4-3">
    Theorem 8
   </a>
   (restated below) using
   <a href="#page-4-2">
    Lemma 9
   </a>
   and
   <a href="#page-10-1">
    Theorem 10.
   </a>
</p>
<p block-type="TextInlineMath">
<b>
    Theorem 8
   </b>
   (Optimality of Post-Processing)
   <b>
    .
   </b>
<i>
    For every
   </i>
<sup>
    ∈
   </sup>
<i>
    ,
   </i>
   ̂︀
   <i>
    is the best linear unbiased estimator (BLUE) of the count and has variance
   </i>
   var ̂︁
   <i>
    . In particular,
   </i>
   (̂︀)∈
   <i>
    minimizes
   </i>
   RMSRE (, ̂︀)
   <i>
    among all linear unbiased estimators, for all
   </i>
   ∈
   <i>
    .
   </i>
</p>
<p block-type="TextInlineMath">
<span id="page-10-0">
</span>
<i>
    Proof.
   </i>
   Corresponding to any tree , we can associate the matrix  ∈ R × , where  is the number of nodes (both internal and leaf nodes), and  is the number of leaf nodes, such that , is 1 if leaf  is either equal to or a descendant of  and 0 otherwise. The estimated counts are given as  =  +  where  ∈ R  is such that  is the true count for leaf . We have that  ˆ is a least squares estimator minimizing ( ˜) := ∑︀  ( − (˜)) 2 /var if and only if it satisfies ∇( ˆ) = 0 (due to convexity of squared loss). Setting the derivative w.r.t.  ˆ equal to 0, implies that for each leaf ,
  </p>
<p block-type="Equation">
<math display="block">
    \sum_{u} \frac{x_u - (A\hat{\theta})_u}{\text{var}_u} \cdot A_{u,v} = 0
   </math>
<math display="block">
    \iff \sum_{u \in \text{anc}(v)} \frac{x_u}{\text{var}_u} = \sum_{u \in \text{anc}(v)} \frac{(A\hat{\theta})_u}{\text{var}_u}.
   </math>
</p>
<p block-type="TextInlineMath">
   Thus, the best linear unbiased estimate for () is given by ̂︀ = (ˆ), which clearly satisfies
   <i>
    consistency
   </i>
   and as shown above also satisfies the
   <i>
    weighted root-to-leaf sum preservation
   </i>
   properties of
   <a href="#page-4-2">
    Lemma 9.
   </a>
   Conversely, if (̂︀) satisfies consistency, then it must be of the form ˜ for  ˜
   <sup>
    =
   </sup>
   ̂︀ for all leaves , and if it satisfies the
   <i>
    weighted root-to-leaf sum preservation
   </i>
   property, then as shown above  ˜ must be the least-squares estimator.
  </p>
<p block-type="TextInlineMath">
   Thus, from
   <a href="#page-4-2">
    Lemma 9,
   </a>
   we have that the (̂︀) returned by
   <a href="#page-4-0">
    Algorithm 2
   </a>
   satisfies the two properties, we have that each ̂︀ is the BLUE for the corresponding true count  by
   <a href="#page-10-1">
    Theorem 10.
   </a>
</p>
<p block-type="TextInlineMath">
   Finally, to see that var ̂︁ is indeed the variance of estimate ̂︀, we recursively show that var
   <sup>
    ↑
   </sup>
   , var⇑  , var
   <sup>
    ↓
   </sup>
   , var⇓  are the variances corresponding to  ↑  ,  ⇑  ,  ↓  ,  ⇓  respectively. The key property to verify is that each  quantity involves a linear combination of estimates which depend on noisy counts of disjoint parts of the tree and hence are independent. Thus, we can repeatedly use the property that for independent drawn  and  , it holds that Var( +  ) =
   <sup>
    2
   </sup>
   Var() +
   <sup>
    2
   </sup>
   Var( ).
  </p>
<h2>
<span id="page-11-0">
</span>
<b>
    B. Greedy Iterative Budgeting
   </b>
</h2>
<p block-type="TextInlineMath">
<a href="#page-11-1">
    Algorithm 3
   </a>
   presents the greedy iterative approach we used for optimizing the privacy budget allocation using true counts , as alluded to in
   <a href="#page-5-0">
    Section 5.
   </a>
   The high level idea is as follows. We choose a parameter  to be a number of phases (e.g.,  = 20) corresponding to the granularity of the allocation.
  </p>
<p block-type="TextInlineMath">
   Initially, allocate an infinitesimal privacy budget to each level; this is done so that we can use
   <a href="#page-4-0">
    Algorithm 2
   </a>
   to compute var ̂︁ for each node of the tree; we need this infinitesimal allocation because
   <a href="#page-4-0">
    Algorithm 2
   </a>
   as written does not allow var to be ∞ for any .
   <a href="#page-11-2">
    4
   </a>
</p>
<p block-type="TextInlineMath">
   We divide the (remaining) privacy budget of ̂︀ into  units of size / ̂︀ . In each of  phases, we consider adding / ̂︀ budget to all nodes at level , choosing an  that results in the lowest RMSRE (), which can be computed using
   <a href="#page-4-0">
    Algorithm 2;
   </a>
   for any budgeting sequence (0, . . . , ), we set var to be the variance of DLap(1/) for all nodes  in level . Observe that RMSRE () can be computed directly using the variance var ̂︁ of each post-processed estimate ̂︀ as returned by
   <a href="#page-4-0">
    Algorithm 2
   </a>
   since
  </p>
<p block-type="Equation">
<math display="block">
    \text{RMSRE}_{\tau}(c_v, \widehat{x}_v) = \sqrt{\frac{\widehat{\text{var}}_v}{\max(\tau, c_v)^2}}.
   </math>
</p>
<p block-type="Text">
<b>
    Algorithm 3
   </b>
   Privacy budgeting via greedy iterations
  </p>
<p block-type="TextInlineMath">
<span id="page-11-1">
</span>
<b>
    Params:
   </b>
   Tree , with levels 0, 1, . . . , .
   <b>
    Input:
   </b>
   Total privacy budget , Number of phases
   <b>
    Output:
   </b>
   Budget split 0, 1, . . . ,  such that ∑︀   = .
  </p>
<p block-type="TextInlineMath">
   Choose an infinitesimal , e.g.,  ← 10
   <sup>
    −
   </sup>
<sup>
    5
   </sup>
   .
   <b>
    for
   </b>
   = 0, . . . ,
   <b>
    do
   </b>
   ←  · / ̂︀
   <sup>
    ←
   </sup>
   (1
   <sup>
    −
   </sup>
   ) (remaining privacy budget)
   <b>
    for
   </b>
   = 1, . . . ,
   <b>
    do for
   </b>
   = 0, . . . ,
   <b>
    do
   </b>
   ← RMSRE () using privacy budget split of (0, . . . ,
   <sup>
    +
   </sup>
   /, . . . ,  ̂︀ ) (computed using (var ̂︁)∈ from
   <a href="#page-4-0">
    Algorithm 2)
   </a>
   ℓ ← argmin
   <sup>
    ℓ
   </sup>
<sup>
    ←
   </sup>
<sup>
    ℓ
   </sup>
<sup>
    +
   </sup>
   / ̂︀
   <b>
    return
   </b>
   (0, . . . , )
  </p>
<p>
<span id="page-11-2">
</span>
<sup>
    4
   </sup>
   While it is possible to modify
   <a href="#page-4-0">
    Algorithm 2
   </a>
   to support var = ∞ for certain subsets of the nodes, we avoid doing so for retaining clarity.
  </p>
</div>
