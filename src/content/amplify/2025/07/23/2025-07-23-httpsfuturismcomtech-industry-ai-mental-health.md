---
author: Joe Wilkins
cover_image: >-
  https://wordpress-assets.futurism.com/2025/07/tech-industry-ai-mental-health-1.jpg
date: '2025-07-24T03:17:16.734Z'
dateFolder: 2025/07/23
description: >-
  Tech industry hotshots are speaking out after a prominent OpenAI investor
  appeared to have a ChatGPT-induced mental health breakdown.
isBasedOn: 'https://futurism.com/tech-industry-ai-mental-health'
link: 'https://futurism.com/tech-industry-ai-mental-health'
slug: 2025-07-23-httpsfuturismcomtech-industry-ai-mental-health
tags:
  - ai
  - tech
title: >-
  Tech Industry Figures Suddenly Very Concerned That AI Use Is Leading to
  Psychotic Episodes
---
<figure><img alt="Getty / Futurism" data-nimg="intrinsic" src="https://futurism.com/_next/image?url=https%3A%2F%2Fwordpress-assets.futurism.com%2F2025%2F07%2Ftech-industry-ai-mental-health-1.jpg&amp;w=2048&amp;q=75" srcset="https://futurism.com/_next/image?url=https%3A%2F%2Fwordpress-assets.futurism.com%2F2025%2F07%2Ftech-industry-ai-mental-health-1.jpg&amp;w=1080&amp;q=75%201x,%20/_next/image?url=https%3A%2F%2Fwordpress-assets.futurism.com%2F2025%2F07%2Ftech-industry-ai-mental-health-1.jpg&amp;w=2048&amp;q=75%202x"/><figcaption>Image by Getty / Futurism</figcaption></figure>
<p>For months, we and our colleagues elsewhere in the tech media have been reporting on what experts are now calling "<a href="https://www.psychologytoday.com/us/blog/urban-survival/202507/the-emerging-problem-of-ai-psychosis">ChatGPT psychosis</a>": when AI users fall down alarming mental health rabbit holes in which a chatbot encourages wild delusions about conspiracies, mystical entities, or crackpot new scientific theories.</p>
<p>The resulting breakdowns have led users to <a href="https://futurism.com/chatgpt-mental-health-crises">homelessness</a>, <a href="https://futurism.com/commitment-jail-chatgpt-psychosis">involuntary commitment</a> to psychiatric care facilities, and even <a href="https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html">violent death</a> and <a href="https://futurism.com/mother-teen-suicide-chatbots-letter">suicide</a>.</p>
<p>Until recently, the tech industry and its financial backers have had little to say about the phenomenon. But last week, one of their own — venture capitalist Geoff Lewis, a managing partner at the multi-billion dollar firm Bedrock who is heavily invested in machine learning ventures including OpenAI — raised eyebrows with a series of posts that <a href="https://futurism.com/openai-investor-chatgpt-mental-health">prompted concerns about his own mental health</a>.</p>
<p>In the posts, he claimed that he'd somehow used ChatGPT to uncover a shadowy "non-government agency" that he said had "negatively impacted over 7,000 lives" and "extinguished" 12 more.</p>
<p>Whatever's going on with Lewis, who didn't respond to our request for comment, his posts have prompted an unprecedented outpouring of concern among high-profile individuals in the tech industry about what the massive deployment of poorly-understood AI tech may be having on the mental health of users worldwide.</p>
<p>"If you’re a friend or family, please check on him," <a href="https://x.com/hishboy/status/1945258955380326653">wrote</a> Hish Bouabdallah, a software engineer who's worked at Apple, Coinbase, Lyft, and Twitter, of Lewis' thread. "He doesn’t seem alright."</p>
<p>Other posts were far less empathetic, though there seemed to be a dark undercurrent to the gallows humor: if a billionaire investor can lose his grip after a few too many prompts, what hope do the rest of us have?</p>
<p>"This is like Kanye being off his meds but for the tech industry," <a href="https://x.com/transitive_bs/status/1945904314053984449">quipped Travis Fischer</a>, a software engineer who's worked at Amazon and Microsoft.</p>
<p>Concretely, Lewis' posts also elicited a wave of warnings about the mental health implications of getting too chummy with chatbots.</p>
<p>"There’s recently been an influx of case reports describing people exhibiting signs of psychosis having their episodes and beliefs amplified by an LLM," <a href="https://x.com/cyrilzakka/status/1945988983588258258">wrote</a> Cyril Zakka, a medical doctor and former Stanford researcher who now works at the prominent AI startup Hugging Face.</p>
<p>"While I’m not a psychiatrist by training," he continued, "I think it mirrors an interesting syndrome known as 'folie à deux' or 'madness of two' that falls under delusional disorders in the DSM-5 (although not an official classification.)"</p>
<p>"While there are many variations, it essentially boils down to a primary person forming a delusional belief during a psychotic episode and imposing it on another secondary person who starts believing them as well," Zakka posited. "From a psychiatric perspective, I think LLMs could definitely fall under the umbrella of being 'the induced non-dominant person,' reflecting the beliefs back at the inducer. These beliefs often subside in the non-dominant individual when separated from the primary one."</p>
<p>Eliezer Yudkowsky, the founder of the Machine Intelligence Research Institute, even charged that Lewis had been "eaten by ChatGPT." While some in the tech industry framed Lewis’ struggles as a <a href="https://x.com/max_spero_/status/1945896467169722812">surprising anomaly</a> given his résumé, Yudkowsky — himself a wealthy and influential tech figure — sees the incident as evidence that even wealthy elites are vulnerable to chatbot psychosis.</p>
<p>"This is not good news about which sort of humans ChatGPT can eat," <a href="https://x.com/ESYudkowsky/status/1945923453716230317">mused Yudkowsky</a>. "Yes yes, I'm sure the guy was atypically susceptible for a $2 billion fund manager," he continued. "It is nonetheless a small iota of bad news about how good ChatGPT is at producing ChatGPT psychosis; it contradicts the narrative where this only happens to people sufficiently low-status that AI companies should be allowed to break them."</p>
<p>Others tried to break through to Lewis by explaining to him what was almost certainly happening: the AI was picking up on leading questions and providing answers that were effectively role-playing a dark conspiracy, with Lewis as the main character.</p>
<p>"This isn't as deep as you think it is," <a href="https://x.com/jordnb/status/1945892035753570479">replied Jordan Burgess</a>, a software engineer and AI startup founder, to Lewis' posts. "In practice ChatGPT will write semi-coherent gibberish if you ask it to."</p>
<p>"Don't worry — you can come out of it! But the healthy thing would be to step away and get more human connection," Burgess implored. "Friends of Geoff: please can you reach out to him directly. I assume he has a wide network here."</p>
<p>As <a href="https://www.garbageday.email/p/the-tech-bros-are-making-themselves-sick">observers quickly pointed out</a>, the ChatGPT screenshots Lewis posted to back up his claims seemed to be clearly inspired by a fanfiction community called the <a href="https://scp-wiki.wikidot.com/about-the-scp-foundation">SCP Foundation</a>, in which participants write horror stories about surreal monsters styled as jargon-filled reports by a research group studying paranormal phenomena.</p>
<p>Jeremy Howard, Stanford digital fellow and former professor at the University of Queensland, broke down the sequence that led Lewis into an SCP-themed feedback loop.</p>
<p>"When there's lots of training data with a particular style, using a similar style in your prompt will trigger the LLM to respond in that style," Howard <a href="https://x.com/jeremyphoward/status/1945922341038637104">wrote</a>. "The SCP wiki is really big — about 30x bigger than the whole Harry Potter series, at &gt;30 million words! Geoff happened across certain words and phrases that triggered ChatGPT to produce tokens from this part of the training [data]."</p>
<p>"Geoff happened across certain words and phrases that triggered ChatGPT to produce tokens from this part of the training distribution," he <a href="https://x.com/jeremyphoward/status/1945922341038637104">wrote</a>. "And the tokens it produced triggered Geoff in turn."</p>
<p>"That's not a coincidence, the collaboratively-produced fanfic is meant to be compelling!" he added. "This created a self-reinforcing feedback loop."</p>
<p>Not all who chimed in addressed Lewis himself. Some took a step back to comment on the broader system vexing Lewis and others like him, placing responsibility for ChatGPT psychosis on OpenAI.</p>
<p>Jackson Doherty, a software engineer at TipLink, <a href="https://x.com/JacksonDoherty/status/1945908467111178354">entreated</a> OpenAI founder Sam Altman to "fix your model to stop driving people insane." (Altman <a href="https://x.com/sama/status/1915910976802853126">previously acknowledged</a> that OpenAI was forced to <a href="https://openai.com/index/sycophancy-in-gpt-4o/">roll back a version</a> of ChatGPT that was "overly flattering or agreeable — often described as sycophantic.")</p>
<p>And Wilson Hobbs, founding engineer at corporate tax startup Rivet, noted that the makers of ChatGPT have a vested interest in keeping users engrossed in their chatbot. As a consequence of venture capital's obsession with AI, tech companies are incentivized to drive engagement numbers over <a href="https://futurism.com/pyschiatric-researchers-risk-ai">user wellbeing</a> in order to snag <a href="https://www.axios.com/2025/07/03/ai-startups-vc-investments">massive cash injections</a> from investors — like, ironically, Lewis himself.</p>
<p>"If this looks crazy to you, imagine the thousands of people who aren’t high profile whose thought loops are being reinforced," <a href="https://x.com/WiLSONSACCOUNT/status/1945895065978892574">Hobbs wrote</a>. "People have taken their own lives due to ChatGPT. And no one seems to want to take that to its logical conclusion, especially not OpenAI."</p>
<p>"Just remember," Hobbs continued, "wanting something to be true does not make it true. And there are a lot of people out there who need a lot of falsehoods to be true right now so they can raise more money and secure their place in the world before the music stops. Do not anthropomorphize the lawnmower."</p>
