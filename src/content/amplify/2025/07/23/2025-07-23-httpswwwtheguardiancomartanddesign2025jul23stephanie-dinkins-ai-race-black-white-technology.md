---
author: Melissa Hellmann
cover_image: >-
  https://i.guim.co.uk/img/media/fdb2812ab13a4b862005f52c0652eed5d889f82b/573_0_4620_3699/master/4620.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0f23493e7a1f2789bf95110345f096b5
date: '2025-07-24T03:47:18.026Z'
dateFolder: 2025/07/23
description: >-
  Stephanie Dinkins challenges the racialized AI space by highlighting Black
  ethos and cultural cornerstones
isBasedOn: >-
  https://www.theguardian.com/artanddesign/2025/jul/23/stephanie-dinkins-ai-race-black-white-technology
link: >-
  https://www.theguardian.com/artanddesign/2025/jul/23/stephanie-dinkins-ai-race-black-white-technology
slug: >-
  2025-07-23-httpswwwtheguardiancomartanddesign2025jul23stephanie-dinkins-ai-race-black-white-technology
tags:
  - ai
  - race
title: >-
  ‘Pretty revolutionary’: a Brooklyn exhibit interrogates white-dominated AI to
  make it more inclusive
---
<figure><picture><source media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/fdb2812ab13a4b862005f52c0652eed5d889f82b/0_0_5791_3699/master/5791.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 980px)" srcset="https://i.guim.co.uk/img/media/fdb2812ab13a4b862005f52c0652eed5d889f82b/0_0_5791_3699/master/5791.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 740px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 740px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/fdb2812ab13a4b862005f52c0652eed5d889f82b/0_0_5791_3699/master/5791.jpg?width=700&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 740px)" srcset="https://i.guim.co.uk/img/media/fdb2812ab13a4b862005f52c0652eed5d889f82b/0_0_5791_3699/master/5791.jpg?width=700&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/fdb2812ab13a4b862005f52c0652eed5d889f82b/0_0_5791_3699/master/5791.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 660px)" srcset="https://i.guim.co.uk/img/media/fdb2812ab13a4b862005f52c0652eed5d889f82b/0_0_5791_3699/master/5791.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/fdb2812ab13a4b862005f52c0652eed5d889f82b/0_0_5791_3699/master/5791.jpg?width=645&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 480px)" srcset="https://i.guim.co.uk/img/media/fdb2812ab13a4b862005f52c0652eed5d889f82b/0_0_5791_3699/master/5791.jpg?width=645&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/fdb2812ab13a4b862005f52c0652eed5d889f82b/0_0_5791_3699/master/5791.jpg?width=465&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 320px)" srcset="https://i.guim.co.uk/img/media/fdb2812ab13a4b862005f52c0652eed5d889f82b/0_0_5791_3699/master/5791.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none"/><img alt="a screen on a container panted yellow and black" src="https://i.guim.co.uk/img/media/fdb2812ab13a4b862005f52c0652eed5d889f82b/0_0_5791_3699/master/5791.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none"/></picture><figcaption data-spacefinder-role="inline">The If We Don’t, Who Will? AI laboratory in downtown Brooklyn, New York City. Photograph: Avery J Savage</figcaption></figure>
<h2 data-gu-name="standfirst">Stephanie Dinkins challenges the racialized AI space by highlighting Black ethos and cultural cornerstones </h2>
<p>At the Plaza at 300 Ashland Place in downtown Brooklyn, patrons mill around a large yellow shipping container with black triangles painted on its side. A nod to the <a data-link-name="in body link" href="https://www.npr.org/2024/03/03/1235158989/the-enduring-story-for-underground-railroad-quilts">flying geese quilt pattern</a>, which may have served as a coded message for enslaved people escaping to freedom along the Underground Railroad, the design and container serve as a bridge between the past and the future of the African diaspora. At the center of the art project by the Brooklyn-based transmedia artist Stephanie Dinkins, a large screen displays artificial intelligence (AI) generated images that showcase the diversity of the city.</p>
<p>Commissioned by the New York-based art non-profit More Art and designed in collaboration with the architects LOT-EK, the AI laboratory <a data-link-name="in body link" href="https://moreart.org/projects/if-we-dont-who-will/">If We Don’t, Who Will?</a> will be on display until 28 September. It seeks to challenge a white-dominated generative-AI space by highlighting Black ethos and cultural cornerstones.</p>
<p>During a time when society has become increasingly reliant on AI, Dinkins wants the models to learn the history, hopes and dreams of Black and brown people to more accurately represent US demographics. She sees her work as shifting the AI landscape, which has been trained on biased data and encapsulates a worldview that is not reflective of the global majority. Black people are underrepresented in the AI field, with Black workers composing just <a data-link-name="in body link" href="https://www.eeoc.gov/sites/default/files/2024-09/20240910_Diversity%20in%20the%20High%20Tech%20Workforce%20and%20Sector%202014-2022.pdf">7.4% of the hi-tech workforce</a>. Research has shown that lack of representation in AI can lead to discriminatory outcomes, such as <a data-link-name="in body link" href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">predictive policing tools that target Black communities</a> and <a data-link-name="in body link" href="https://www.law.georgetown.edu/poverty-journal/blog/the-discriminatory-impacts-of-ai-powered-tenant-screening-programs/">tenant screening programs that reject renters of color</a>.</p>
<p>“What stories can we tell machines that will help them know us better from the inside of the community out, instead of the way that we’re often described, from outside in, which is often incorrect or misses a mark in some way, or knows us as a consumerist body, not as a human body,” Dinkins said. “I have this question: ‘Can we make systems of care and generosity?’”</p>
<figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><picture><source media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/b49990c42ee5c74ac71eaa1ec801722374cff50d/0_0_2099_1500/master/2099.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 660px)" srcset="https://i.guim.co.uk/img/media/b49990c42ee5c74ac71eaa1ec801722374cff50d/0_0_2099_1500/master/2099.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/b49990c42ee5c74ac71eaa1ec801722374cff50d/0_0_2099_1500/master/2099.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 480px)" srcset="https://i.guim.co.uk/img/media/b49990c42ee5c74ac71eaa1ec801722374cff50d/0_0_2099_1500/master/2099.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/b49990c42ee5c74ac71eaa1ec801722374cff50d/0_0_2099_1500/master/2099.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 320px)" srcset="https://i.guim.co.uk/img/media/b49990c42ee5c74ac71eaa1ec801722374cff50d/0_0_2099_1500/master/2099.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none"/><img alt="a women looking into a container " src="https://i.guim.co.uk/img/media/b49990c42ee5c74ac71eaa1ec801722374cff50d/0_0_2099_1500/master/2099.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none"/></picture><figcaption data-spacefinder-role="inline">A person examines the If We Don’t, Who Will? AI laboratory in downtown Brooklyn, New York City. Photograph: Driely Carter</figcaption></figure>
<p>At the AI laboratory, one image on the screen is of a young Black girl with an afro hairstyle who stares at the viewer, her steady gaze belying her artificial nature. QR codes stationed around the public art project lead to an <a data-link-name="in body link" href="https://thestorieswetellourmachines.app/">app</a> where people are invited to submit their own personal stories or to answer prompts such as “what privileges do you have in society?” People around the world can also answer questions through the app. A ramp leads to the inside of the container, where after a few minutes, a large screen displays a generated image that reflects the information that patrons submitted in the app. Images that appear on a loop until another response is uploaded are mostly portraits of people of color, even if the person who submitted it is not one themselves.</p>
<p>Dinkins programmed the generative art to prioritize Black and brown worldviews and figures. She did so by fine-tuning different AI models, programs that recognize patterns through datasets. Dinkins and her team of developers fed the models images by the Black photographer Roy DeCarava, who captured photos of Black people in Harlem. They also programmed it using African American Vernacular English so that the models would learn to recognize its tonality and better generate images based on the stories of people who use it. She also created imagery of okra, a main ingredient in the dishes of enslaved Africans and their descendants, which are displayed in the portraits as a talisman that she sees as connecting the past and present.</p>
<p>“We’re in this AI technological landscape that is changing our world. I don’t have a clue how it can do well by us if it does not know us,” Dinkins said. While she empathizes with the public’s desire to protect their privacy in the AI era, she said, “We also have to have those spaces where we say this information isn’t for ourselves. It should be shared because it is a way that we are current, training and nurturing the technology that we are living under.”</p>
<h2>Democratizing AI</h2>
<p>Dinkins, who was named one of the<a data-link-name="in body link" href="https://time.com/collection/time100-ai/6309453/stephanie-dinkins/"> 100 most influential people in AI in 2023 by Time magazine</a>, is a self-proclaimed “tinkerer” without formal technology training. She became interested in AI more than a decade ago after coming across a YouTube video of a Black woman AI robot, Bina48, which depicts Bina Rothblatt, co-founder of the not-for-profit Terasem Movement Foundation, which researches ways to extend human life.</p>
<p>Her ongoing project <a data-link-name="in body link" href="https://www.stephaniedinkins.com/conversations-with-bina48.html">Conversations With Bina48</a>, which began in 2014, features recorded video interviews of her talking with the robot. She later created her own AI system that served as a Black American family memoir. In her project <a data-link-name="in body link" href="https://www.seattletimes.com/business/technology/artist-works-to-merge-artificial-intelligence-and-art/">Not the Only One,</a> Dinkins created a voice-interactive device that spoke to passersby and was trained on conversations that she had with her niece and aunt.</p>
<p>Dinkins’s projects are a step toward democratizing AI by bringing technology to underrepresented people in spaces where they normally would not have access to it, said Louis Chude-Sokei, a Boston University English professor. There is a long history of algorithms outputting racist or sexist material because they are trained on the internet, which is teeming with racist and sexist stereotypes, said Chude-Sokei, who specializes in literature as well as technology and race.</p>
<figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><picture><source media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/62e64702bbf47fd9929355e8d8b825e95a3d0572/0_0_2097_1500/master/2097.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 660px)" srcset="https://i.guim.co.uk/img/media/62e64702bbf47fd9929355e8d8b825e95a3d0572/0_0_2097_1500/master/2097.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/62e64702bbf47fd9929355e8d8b825e95a3d0572/0_0_2097_1500/master/2097.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 480px)" srcset="https://i.guim.co.uk/img/media/62e64702bbf47fd9929355e8d8b825e95a3d0572/0_0_2097_1500/master/2097.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/62e64702bbf47fd9929355e8d8b825e95a3d0572/0_0_2097_1500/master/2097.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 320px)" srcset="https://i.guim.co.uk/img/media/62e64702bbf47fd9929355e8d8b825e95a3d0572/0_0_2097_1500/master/2097.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none"/><img alt="a women on a screen " src="https://i.guim.co.uk/img/media/62e64702bbf47fd9929355e8d8b825e95a3d0572/0_0_2097_1500/master/2097.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none"/></picture><figcaption data-spacefinder-role="inline">An image from the If We Don’t, Who Will? AI laboratory in downtown Brooklyn, New York City. Photograph: Driely Carter</figcaption></figure>
<p>“What Stephanie wants to do is [pose the question]: ‘What if we can start to train different algorithms to respond to different datasets that have liberating content or socially just content?’” Chude-Sokei said. “Let’s just take a hold of the datasets and create different patterns for it to recognize and see what kind of conclusions it will produce based on different materials and different patterns.”</p>
<p>Dinkins and other artists of color focusing on technology are shifting the paradigm of the AI landscape, he said, by putting the tools into the hands of the global majority. “There’s a much larger reorientation of the social world, the political world, the cultural world that’s happening with AI,” Chude-Sokei said. Dinkins’s work, he added, embraces a philosophy she coined called <a data-link-name="in body link" href="https://artgalleries.tufts.edu/events/120-design-a-i-and-afro-nowism">Afro-now-ism</a>, which she defines as taking action toward a better world today. It’s a “celebration of seeing technology, not as this horrific thing that we have no control over”, Chude-Sokei said, “but something that we can engage in very joyful, creative and positive ways, while at the same time, being aware of the dangers”.</p>
<p>For Beth Coleman, a professor at the University of Toronto who specializes in technology and society, it’s imperative that AI models be trained on a wide range of datasets to ensure that they produce an accurate representation of the world. Dinkins’ work, she said, interrogates which voices are included in technical systems.</p>
<p>“There’s a good spirit of ‘how can we build a better world together?’ in Stephanie’s work,” Coleman said, “and at this moment in time that feels pretty revolutionary.”</p>
