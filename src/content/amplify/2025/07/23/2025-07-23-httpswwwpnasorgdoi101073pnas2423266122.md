---
author: PNAS
cover_image: >-
  https://www.pnas.org/cms/asset/fd7b09c6-1e18-423f-acf9-f4574f667606/keyimage.jpg
date: '2025-07-24T03:22:07.309Z'
dateFolder: 2025/07/23
description: >-
  This paper examines the relationship between democratization and the
  development of

  AI and information and communication technology (ICT). Our empi...
isBasedOn: 'https://www.pnas.org/doi/10.1073/pnas.2423266122'
link: 'https://www.pnas.org/doi/10.1073/pnas.2423266122'
slug: 2025-07-23-httpswwwpnasorgdoi101073pnas2423266122
tags:
  - ai
  - politics
title: Why does AI hinder democratization?
---
<p>Does information and communication technology (ICT) facilitate democracy or stabilize autocracy? Do the recent advancements in AI play any special role? The purpose of this paper is to investigate the relationship between democratization and the development of ICT and to explore the role of AI in this relationship. Our analysis helps explain recent political regime changes that reveal the fragility of democracy.</p>
<p>The conventional theory of democratization suggests that AI/ICT advancements broaden the scope for democratic representation by decentralizing information systems and communication platforms, ushering in a new era of participatory democracy. These technologies are expected to bolster informational autonomy for citizens by improving information gathering and participation in political processes and facilitating campaigning, networking, voting, information-seeking, and protesting. Thus, it was expected that autocrats would be less likely to maintain the same power that they had in the past.</p>
<p>Despite the fact that ICT indeed facilitated democratization during the Arab Spring in the early 2010s, recent evidence stands in contradiction to the conventional wisdom. <a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fig01">Fig. 1</a> shows that while the number of AI/ICT-granted patents worldwide is steadily increasing<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fn4"><sup>*</sup></a>, the Democracy Index [released by the Economist Intelligence Unit (EIU)] and Political Rights [released by Freedom House (FH)] have both moved in the opposite direction (although there was a temporary uptick after the Arab Spring during 2011 to 2015). Using the structural break test, we find that the structural break year for ICT-granted patents and the EIU’s Democracy Index and FH’s Political Rights is 2012, while the structural break year for AI-granted patents and these two democracy scores is 2017 due to the recent rapid progress in AI.<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fn5"><sup>†</sup></a></p>
<figure><img src="https://www.pnas.org/cms/10.1073/pnas.2423266122/asset/21312052-4e56-48b5-b2f7-910de896a1bc/assets/images/large/pnas.2423266122fig01.jpg"/><figcaption>Democracy/political rights and AI/ICT-granted patents. Notes: (1) The data for the Democracy Index and Political Rights are normalized so that 2006 = 100. The AI/ICT industry taxonomy is based on Eurostat Metadata. (2) The structural break test indicates that the structural break year for ICT-granted patents and the EIU’s Democracy Index and FH’s Political Rights is 2012, while the structural break year for AI-granted patents and these two democracy scores is 2017.</figcaption></figure>
<p>In addition, the global average score of the Democracy Index in 2023 hit a record low, falling to 5.23 (out of 10) from 5.52 in 2006 when the EIU began compiling the index. Of 167 countries, 108 have regressed while only 59 have improved in the past 17 y. FH’s Political Rights index in 2023 also hit a record low, having fallen by 8.18% in the past 17 y. By measuring the degree of overall freedom, FH’s Global Freedom Scores indicate that between 2006 and 2023, ten countries transitioned from “free” to “partly free” status<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fn6"><sup>‡</sup></a>, and eighteen countries transitioned from partly free to “not free” status<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fn7"><sup>§</sup></a>, with one country (Mali) dramatically shifting from free to not free status. The regime changes indicate the recent fragility of democracy, which has motivated us to examine the nexus between AI/ICT and democratic development in greater depth.</p>
<p>This paper decomposes AI/ICT capacities into different dimensions and offers a broader, more general analysis of AI/ICT’s political impact across countries. Our analysis explains why post-Arab Spring optimism about the Internet’s role in democratization faded. Empirically, we show how authoritarian and fragile democratic countries use AI/ICT to strengthen control and how checks and balances in healthier democratic regimes can limit this administrative power. Theoretically, we show that when autocrats outpace civil society in exploiting big data, the “narrow democracy corridor” becomes even narrower.</p>
<p>The traditional optimism that ICT may help the realization of democracy reached its peak in the early 2010 s, as the Internet and social media facilitated the ouster of four of the world’s longest-ruling dictators in countries in the Middle East—Egypt, Libya, Tunisia, and Yemen—known as the Arab Spring movement. People had placed great faith in the role of information technologies, such as websites, chat rooms, and media stories that contained numerous references to a “Facebook Revolution” or “YouTube Revolt.” They believed that ICT would facilitate political mobilization and lead to democracy (<a data-xml-rid="r1" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r1">1</a>, <a data-xml-rid="r2" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r2">2</a>).</p>
<p>Early empirical evidence also seems to be consistent with this optimistic conjecture. Between 1946 and 2000, before the prevalence of the Internet, most authoritarian regimes were ousted by coups rather than by protests. Between 2001 and 2017, however, coups unseated only 9% of the dictatorships, while mass movements toppled twice as many (<a data-xml-rid="r3" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r3">3</a>). Such a positive perception regarding the impact of ICT, nevertheless, turns out to be overly optimistic. In the past decade, many people have begun to think the opposite: ICT may help autocracies stabilize their control, and make democracy less likely to arise.</p>
<h3>Why Did the Tide Turn?</h3>
<p>There are two main reasons why ICT has changed its role from facilitating democracy to stabilizing autocracy. First, antigovernment groups are not the only ones that can use ICT; autocracies may also take advantage of such technology advancements by screening information, shutting down websites, intercepting rallies, enacting laws that restrict anonymity, and implementing cyber-assaults against opposition websites, so that large-scale protests can be suppressed ex ante. When both civil society and the government can use ICT as tools to confront each other, which side has an advantage depends on which side benefits more from the technology. In terms of economics, one would conjecture that a party can benefit more when its force is more complementary to ICT.</p>
<p>The second reason why the tide turned in the past decade is the advancement of AI, thanks to the increases in computing power and big data. The advancement of AI that makes ICT more complementary to the authoritarian ruler is indeed appealing. Researchers argue that AI is a game changer for authoritarian efforts to shape discourses and crush the opposition (<a data-xml-rid="r4" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r4">4</a>). By 1989 when the Berlin Wall fell, there were roughly 100,000 police employees in East Germany’s Stasi, and between 500,000 and two million informants (<a data-xml-rid="r3" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r3">3</a>). East Germany had only 16 million people then. If we call Stasi employees and informants “spies”, then roughly one spy only covered seven citizens. This number suggests that surveillance appears to be rather inefficient for authoritarian rulers. In recent years, however, much of the “spy work” can be done by AI, and hence the surveillance efficiency is much improved. Another cost of the traditional repression model is the principal-agent problem: The more the authoritarian regime relies on police and soldiers, the more vulnerable the regime is to insurrection by these soldiers (<a data-xml-rid="r4" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r4">4</a>). By contrast, monitoring and surveillance using AI and ICT are less costly and can reduce the risk of insurrection, thereby improving monitoring efficiency.</p>
<p>The power of AI/ICT is further strengthened by the increasing prevalence of big data. In addition to the traditional government-controlled administrative data from tax returns, property registrations, (public) bank accounts, criminal records, and birth and death certificates (from which kinship can be inferred), authoritarian states such as China can easily access data from social media (WeChat), search engines (Baidu), e-commerce platforms (Alibaba), and the huge amount of video recording from increasingly widespread cameras.<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fn8"><sup>¶</sup></a> The dataset would be even more horrifyingly gigantic if individual genetic data were to be included (<a data-xml-rid="r5" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r5">5</a>). Moreover, when most telecommunication facilities are operated by companies that are owned, controlled, or franchised with periodic review by the state, governments have much easier access to social media, web searches, e-commerce, and surveillance data. This has been referred to as the data processing model of administrative control (<a data-xml-rid="r6" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r6">6</a>). Finally, as data localization requires data or domains to operate within their borders and be accessible to the government, it becomes a core component of strategies for authoritarian countries to achieve cyber sovereignty and develop digital authoritarianism (<a data-xml-rid="r7" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r7">7</a>, <a data-xml-rid="r8" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r8">8</a>).<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fn9"><sup>#</sup></a></p>
<p>These big datasets provide ample information for AI to improve monitoring and surveillance efficiency. In fact, China has exported its AI techniques to Cambodia, Russia, Africa, Malaysia, Singapore, and many other countries associated with China’s Belt and Road Initiative project (<a data-xml-rid="r3" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r3">3</a>, <a data-xml-rid="r4" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r4">4</a>). Exporting the AI algorithm for analyzing big data to other authoritarian or semiauthoritarian countries suggests that China’s AI programs are very efficient for government control purposes.</p>
<p>AI and ICT can further microtarget individuals, allowing autocracies to tailor information to specific individuals. Such tailored information can be sent to individuals through social media or messengers. AI/ICT can also produce deep-fakes, audios and videos that are difficult to distinguish from authentic ones. These techniques allow autocracies to send information to individuals to either soften their opposition, discredit the opponents, or undermine a social movement (<a data-xml-rid="r3" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r3">3</a>). Given the big data owned by the ruler, these technology tools, of course, favor the autocrat.</p>
<p>In authoritarian and fragile democratic countries, this lopsided data advantage in favor of the state rulers increases their incentive to acquire supercomputing power and to apply AI/ICT for their own purposes. By contrast, a lack of access to big data undermines the usefulness of AI to civil society forces. As a result, AI/ICT, associated with big data, may favor the state and hinder the development of democracy, either by making democracy less likely to arise from autocracy or by easily shaking an originally fragile democracy toward autocracy.</p>
<p>We first provide an intuitive layout regarding our empirical analysis, and explain why governments in authoritarian and fragile democratic countries apply AI/ICT to dimensions very different from those in mature democratic regimes. We then derive testable hypotheses to check whether our conjecture makes sense.</p>
<p>Our empirical analysis is performed using the survey of the Digital Society Project (DSP) dataset (consisting of 164 countries). In Section 2.2 of the DSP dataset (<a href="http://www.pnas.org/lookup/doi/10.1073/pnas.2423266122#supplementary-materials"><i>SI Appendix</i></a>), there are three ICT measures of the Internet and social media: Cyber Security (CS), Content Filtering (CF), and Shut Down (SD). As stressed by the DSP survey, independent of whether they actually do so in practice, CS, CF, and SD measure the technological capacities available to be adopted by state rulers (see <a href="http://www.pnas.org/lookup/doi/10.1073/pnas.2423266122#supplementary-materials"><i>SI Appendix</i>, <i>Appendix A</i></a>, for a detailed data description).</p>
<p>We first explain the key differences between CS, CF, and SD. CS is to prevent outside attacks, to ensure the defense and resilience of cyberspace, and to protect the Internet users (the country, citizens, and firms) and web nodes from cyberattacks (<a data-xml-rid="r9" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r9">9</a>). CS is in general not individual specific because what or who would be attacked cannot be predicted in advance (<a data-xml-rid="r10" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r10">10</a>). By contrast, CF and SD are usually individual-specific, targeted at internal users or platforms. CF enables actors to pick out “harmful” information or target “problematic” individuals on the Internet and social media platforms (<a data-xml-rid="r11" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r11">11</a>). SD enables the government, according to their target list, to take down social media posts and platform-specific user accounts from social media and restrain access to social media or even the Internet itself (<a data-xml-rid="r12" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r12">12</a>). Successful operations of CF and SD rely on the capability to identify the characteristics of targets (<a data-xml-rid="r13" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r13">13</a>).</p>
<p>The capability to identify and eliminate targets depends on whether the user can access individual data and whether the algorithm used can analyze the acquired individual data.<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fn10"><sup>||</sup></a> Precisely targeting problematic individuals and instantaneously taking down targets demand highly sophisticated AI algorithms and heavy computing resources (<a data-xml-rid="r12" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r12">12</a>, <a data-xml-rid="r13" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r13">13</a>). With large individual data, the marginal productivity of AI and ICT increases. This is the intrinsic complementarity between AI/ICT and the state ruler.</p>
<p>Although the above-mentioned intrinsic complementarity makes it easier for the states to invest more in CF and SD, they may not be able to accomplish such investments. Here, the critical difference in data governance between democratic and authoritarian countries arises (<a data-xml-rid="r7" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r7">7</a>, <a data-xml-rid="r8" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r8">8</a>). In democratic countries, the government’s incentive to invest in CF and SD is hindered by various checks and balances, whereas in authoritarian or fragile democratic countries, these checks and balances are weak, or even nonexistent. In authoritarian or fragile democratic countries, the related data regulations often allow the government to have the exclusive right to access individual data. This convenience gives the state a strong incentive to invest in CF and SD to stabilize its political regime, which makes the intrinsic complementarity a realistic one. However, a democracy obeys the rules set by its laws and constitutions, and cyber and data regulations are put forth under the guidance of protecting individuals’ privacy or security. In general, democratic checks and balances greatly decrease the incentive to invest in CF and SD, even though the government may have the AI and ICT talents to operate them.</p>
<p>Given the above analysis, our first hypothesis is that we expect to observe more state investments in CF and SD in autocratic or fragile democratic countries. Because CS is not individual-specific, there is no definite pattern in CS investments. As such, one may predict that advances in AI and ICT would drive autocratic and fragile democratic regimes to increase their CF and SD capacity, but not that of CS. <a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#t01">Table 1</a> summarizes the relationship between various ICT measures and political regimes.</p>
<figure><figcaption>Different Adoption of ICT Measures in Different Countries—Heuristics</figcaption><table><tr><th data-xml-align="left">Three ICT Measures<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#tfn1"><sup>(1)</sup></a></th><th>Individual Specificity?<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#tfn2"><sup>(2)</sup></a></th><th>Big Data Helpful?<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#tfn3"><sup>(3)</sup></a></th><th>State Advantage?<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#tfn4"><sup>(4)</sup></a></th><th>Checks &amp; Balances?<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#tfn5"><sup>(5)</sup></a></th><th>More State Investment?<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#tfn6"><sup>(6)</sup></a></th><th>Away from Narrow Corridor?<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#tfn7"><sup>(7)</sup></a></th></tr><tbody><tr data-xml-align="center"><td data-xml-align="left">CS</td><td>×</td><td>×</td><td>×</td><td>–</td><td>–</td><td>–</td></tr><tr data-xml-align="center"><td data-xml-align="left">CF</td><td>✓</td><td>✓</td><td>✓</td><td>Democrats ✓Autocrats ×</td><td>Democrats ×Autocrats ✓</td><td>Democrats ×Autocrats ✓</td></tr><tr data-xml-align="center"><td data-xml-align="left">SD</td><td>✓</td><td>✓</td><td>✓</td><td>Democrats ✓Autocrats ×</td><td>Democrats ×Autocrats ✓</td><td>Democrats ×Autocrats ✓</td></tr></tbody></table></figure>
<p>To test this hypothesis, we conduct a grouping for these 164 countries based on the democracy indices of FH (or the EIU) during 2006-2023. In light of the status quo effect, we use the 2006 democracy index (the beginning year of the sample period) to divide the countries into two quantile groups in which group L is the less democratic one, consisting of countries whose democracy indices are in the lower 50%, while group H is the more democratic one, consisting of countries whose democracy indices are in the upper 50%.</p>
<p>For both group L and group H in <a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fig02">Fig. 2</a>, there are 18 blue (red) points in each panel, and each point denotes a democracy (or political rights) index on the horizontal axis (demean) and an ICT capacity index on the vertical axis. L-group points are in blue and H-group points are in red, with points for earlier (later) years being lightly (densely) marked.</p>
<figure><img src="https://www.pnas.org/cms/10.1073/pnas.2423266122/asset/a5d6ab81-48c1-4823-8dd8-63ae00c81492/assets/images/large/pnas.2423266122fig02.jpg"/><figcaption>Governments’ technological capacities for low (blue) and high (red) democracy groups. Notes: (1) Countries are grouped based on their 2006 scores. Colors are shaded darker to represent more recent years. Annual democracy scores are demeaned by groups. Technological capability scores are simply averaged annually. (2) Governments in group L have stronger technological capacities in CF and SD, while governments in group H have stronger technological capacities in CS. (3) Group L exhibits an inverted-C relationship between the democracy scores and CF and SD capacities; the turning point is 2014 for the EIU democracy index and 2015 for the FH political rights. (4) Overall, governments’ technological capacities in CF and SD are negatively correlated with the democracy scores, but governments’ technological capacities in CS are positively correlated with the democracy scores. </figcaption></figure>
<p>We can observe several patterns in <a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fig02">Fig. 2</a>: First, for governments in group L (authoritarian and fragile democratic countries), the technological capacities in CF and SD are higher than those in group H (more democratic countries). Second, for group L countries, in the CF and SD panels, we observe an intriguing inverted-C turning, and the turning time is 2014 for the EIU democracy index and 2015 for the FH political rights index. This indicates that, for group L countries, these capacities first increase and then decrease with democracy scores, which is consistent with our discussion in Section 1 (<a href="http://www.pnas.org/lookup/doi/10.1073/pnas.2423266122#supplementary-materials"><i>SI Appendix</i></a>). For group H countries, however, both the CF and SD indexes monotonically decrease with democracy scores, and there is no inverted-C pattern. Third, governments in group H possess stronger technological capacities in CS, compared with group L countries. Overall, governments’ technological capacities in CF and SD are negatively correlated with the democracy scores, but governments’ technological capacities in CS are positively correlated with the democracy scores.<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fn11"><sup>**</sup></a> These results are statistically significant and robust to alternative democracy indices in terms of FH’s Political Rights and Global Freedom Score as well as the EIU’s Democracy Index. The detailed regression results are provided in <a href="http://www.pnas.org/lookup/doi/10.1073/pnas.2423266122#supplementary-materials"><i>SI Appendix</i>, <i>Appendix A</i> and <i>C</i></a>.</p>
<p>Next, we examine how governments translate their technological capacities into surveillance and censorship practices. The DSP dataset contains six measurements of actual <i>practice</i>, as shown in <a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#t02">Table 2</a> (for additional information, refer to <a href="http://www.pnas.org/lookup/doi/10.1073/pnas.2423266122#supplementary-materials"><i>SI Appendix</i>, <i>Appendix A</i></a>). Our second hypothesis is as follows: Because of the differences in checks and balances, the CF and SD capacity indexes are more likely to translate into practices for group L countries than for group H countries.</p>
<figure><figcaption>Governments’ Technological Capacities and Their Actual Practices for Different Democracy Groups</figcaption><table><tr><th data-xml-align="left">Dependent variable <i>Z</i><sub><i>it</i></sub></th><th colspan="2">Internet Filtering</th><th colspan="2">Internet SD</th><th colspan="2">Social Media SD</th><th colspan="2">Social Media Alternatives</th><th colspan="2">Social Media Monitoring</th><th colspan="2">Social Media Censorship</th></tr><tr><th data-xml-align="left">Selected Regressors</th><th>Coeff.</th><th>SE</th><th>Coeff.</th><th>SE</th><th>Coeff.</th><th>SE</th><th>Coeff.</th><th>SE</th><th>Coeff.</th><th>SE</th><th>Coeff.</th><th>SE</th></tr><tbody><tr><td><b>Group L</b></td><td colspan="12"> </td></tr><tr data-xml-align="center"><td data-xml-align="left">Internet Filtering Capacity</td><td>0.180***</td><td>(0.035)</td><td>0.164***</td><td>(0.038)</td><td>0.241***</td><td>(0.038)</td><td>0.068**</td><td>(0.026)</td><td>0.164***</td><td>(0.036)</td><td>0.136***</td><td>(0.033)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Internet SD Capacity</td><td>0.155***</td><td>(0.038)</td><td>0.140***</td><td>(0.041)</td><td>0.138***</td><td>(0.041)</td><td>0.064*</td><td>(0.028)</td><td>0.279***</td><td>(0.039)</td><td>0.213***</td><td>(0.036)</td></tr><tr data-xml-align="center"><td data-xml-align="left">CS Capacity</td><td>0.043</td><td>(0.050)</td><td>−0.060</td><td>(0.055)</td><td>−0.103+</td><td>(0.054)</td><td>0.123***</td><td>(0.037)</td><td>0.049</td><td>(0.053)</td><td>0.069</td><td>(0.047)</td></tr><tr><td><b>Group H</b></td><td colspan="12"> </td></tr><tr data-xml-align="center"><td data-xml-align="left">Internet Filtering Capacity</td><td>0.146***</td><td>(0.043)</td><td>0.027</td><td>(0.047)</td><td>0.077</td><td>(0.047)</td><td>0.027</td><td>(0.033)</td><td>0.078+</td><td>(0.046)</td><td>0.182***</td><td>(0.041)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Internet SD Capacity</td><td>0.018</td><td>(0.048)</td><td>0.075</td><td>(0.051)</td><td>0.126*</td><td>(0.051)</td><td>−0.021</td><td>(0.036)</td><td>0.102*</td><td>(0.050)</td><td>0.022</td><td>(0.045)</td></tr><tr data-xml-align="center"><td data-xml-align="left">CS Capacity</td><td>−0.014</td><td>(0.048)</td><td>0.026</td><td>(0.052)</td><td>−0.058</td><td>(0.051)</td><td>0.073*</td><td>(0.036)</td><td>−0.022</td><td>(0.050)</td><td>0.049</td><td>(0.045)</td></tr></tbody></table></figure>
<p>To shed light on this group-specific distinction, we examine the capacities–practice relationship for groups H and L, including the lagged effect. The Im–Pesaran–Shin panel unit-root test suggests that indices in some countries contain unit roots (<a data-xml-rid="r14" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r14">14</a>) (<a href="http://www.pnas.org/lookup/doi/10.1073/pnas.2423266122#supplementary-materials"><i>SI Appendix</i>, <i>Appendix B</i></a>). Thus, we take the first-order differences for all indices and then run regressions by applying the linear dynamic panel-data estimation, where country and year fixed effects have been taken into account.</p>
<p><a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#t02">Table 2</a> shows that stronger technological capacities in CF and SD enable governments to increase surveillance and censorship practices in less democratic countries (group L), and this positive relationship between governments’ CF and SD capacities and their actual practices is statistically significant in all surveillance and censorship practices. As shown in <a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#t02">Table 2</a>, these statistically significant results are for the current variables of governments’ technological capacities, implying that governments’ CF and SD capacities can immediately be translated into their surveillance and censorship practices. Literally, this means that “bad means always lead to bad activities” in group L countries. By contrast, as for the more democratic countries (group H), the positive relationship is not statistically significant in most of the surveillance and censorship practices. The fact that “bad means may not lead to bad activities” suggests the possible function of checks and balances. <a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#t02">Table 2</a> only shows the case where the democracy grouping is based on FH’s Political Rights. The empirical findings we obtain are also valid when the democracy grouping is based on FH’s Global Freedom or the EIU’s Democracy Index.</p>
<p>Finally, we run regressions to examine the effects of governments’ surveillance and censorship practices on democracy, as measured by FH’s Political Rights and Global Freedom as well as the EIU’s Democracy Index. This regression facilitates the testing of our third hypothesis: More surveillance and censorship lead to the deterioration of democracy.</p>
<p>Because the governments’ surveillance and censorship practices will take time to affect democracy, <a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#t03">Table 3</a> only reports the effects with a lag (see <a href="http://www.pnas.org/lookup/doi/10.1073/pnas.2423266122#supplementary-materials"><i>SI Appendix</i>, <i>Appendix E</i></a> for the comprehensive regression results). Overall, these government implementations give rise to an unfavorable impact on democracy. The negative effects are particularly significant for those government implementations in relation to internet filtering and SD. Governments’ surveillance and censorship practices on the Internet hurt democracy more than on social media. <a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#t03">Table 3</a> further indicates that the negative effects are mainly attributed to group L (authoritarian or fragile democratic countries).<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fn12"><sup>††</sup></a> As for group H (democratic countries), the negative effects of the governments’ implementations are almost statistically insignificant. It is worth noting that our regressions have accounted for country and year fixed effects, and our results remain robust even when we further address the issue of population size.<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fn13"><sup>‡‡</sup></a></p>
<figure><figcaption>Effects of the Government’s Implementation Practices on Democracy</figcaption><table><tr><th data-xml-align="left">Dependent Variable <i>Y</i><sub><i>it</i></sub></th><th colspan="2">FH’s Global Freedom</th><th colspan="2">FH’s Political Rights</th><th colspan="2">EIU’s Democracy Index</th></tr><tr><th data-xml-align="left">Selected Regressors</th><th>Coeff.</th><th>SE</th><th>Coeff.</th><th>SE</th><th>Coeff.</th><th>SE</th></tr><tbody><tr><td colspan="7">Lagged Variables (t-1)—All</td></tr><tr data-xml-align="center"><td data-xml-align="left">Internet Filtering</td><td>−2.521***</td><td>(0.372)</td><td>−1.492***</td><td>(0.245)</td><td>−0.113***</td><td>(0.033)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Internet SD</td><td>−0.691+</td><td>(0.353)</td><td>−0.473*</td><td>(0.232)</td><td>0.068*</td><td>(0.030)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Social Media SD</td><td>−0.498</td><td>(0.350)</td><td>−0.109</td><td>(0.230)</td><td>−0.104***</td><td>(0.031)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Social Media Alternatives</td><td>−0.491</td><td>(0.430)</td><td>−0.128</td><td>(0.284)</td><td>0.044</td><td>(0.036)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Social Media Monitoring</td><td>−0.199</td><td>(0.336)</td><td>−0.151</td><td>(0.222)</td><td>0.006</td><td>(0.030)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Social Media Censorship</td><td>−0.610</td><td>(0.388)</td><td>−0.235</td><td>(0.256)</td><td>0.046</td><td>(0.034)</td></tr><tr><td colspan="7">Lagged Variables (t-1)—Group L</td></tr><tr data-xml-align="center"><td data-xml-align="left">Internet Filtering</td><td>−2.973***</td><td>(0.468)</td><td>−1.661***</td><td>(0.303)</td><td>−0.046</td><td>(0.049)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Internet SD</td><td>−0.356</td><td>(0.401)</td><td>−0.337</td><td>(0.261)</td><td>0.115**</td><td>(0.039)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Social Media SD</td><td>−0.585</td><td>(0.407)</td><td>0.020</td><td>(0.267)</td><td>−0.122**</td><td>(0.042)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Social Media Alternatives</td><td>−0.799</td><td>(0.515)</td><td>−0.231</td><td>(0.337)</td><td>0.052</td><td>(0.045)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Social Media Monitoring</td><td>−0.749+</td><td>(0.449)</td><td>−0.482+</td><td>(0.287)</td><td>0.003</td><td>(0.042)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Social Media Censorship</td><td>−0.527</td><td>(0.549)</td><td>−0.426</td><td>(0.348)</td><td>−0.055</td><td>(0.049)</td></tr><tr><td colspan="7">Lagged Variables (t-1)—Group H</td></tr><tr data-xml-align="center"><td data-xml-align="left">Internet Filtering</td><td>−0.695</td><td>(0.590)</td><td>−0.678+</td><td>(0.399)</td><td>0.006</td><td>(0.049)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Internet SD</td><td>−0.524</td><td>(0.683)</td><td>−0.304</td><td>(0.469)</td><td>−0.067</td><td>(0.055)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Social Media SD</td><td>−0.288</td><td>(0.617)</td><td>−0.252</td><td>(0.413)</td><td>−0.133**</td><td>(0.046)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Social Media Alternatives</td><td>−0.140</td><td>(0.724)</td><td>0.309</td><td>(0.487)</td><td>−0.032</td><td>(0.061)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Social Media Monitoring</td><td>0.267</td><td>(0.489)</td><td>0.290</td><td>(0.337)</td><td>0.078+</td><td>(0.042)</td></tr><tr data-xml-align="center"><td data-xml-align="left">Social Media Censorship</td><td>−0.445</td><td>(0.518)</td><td>0.231</td><td>(0.355)</td><td>−0.001</td><td>(0.046)</td></tr></tbody></table>i</figure>
<p>To sum up, the above results are consistent with our observations described in the previous sections. In authoritarian or fragile democratic countries, democratic checks and balances are weak, allowing the state to have access to individual data and improve the efficiency of surveillance and censorship. The state rulers in authoritarian or fragile democratic countries therefore have a strong incentive to invest in the capacities of CF and SD and to use them in surveillance and censorship practices, which has finally led to the deterioration of democracy. By contrast, in democratic countries checks and balances may disturb all of the above three channels.</p>
<p>The availability of individual big data to rulers in authoritarian and fragile democratic countries may be the key reason why AI has become a more worthwhile investment for these rulers (<a data-xml-rid="r15" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r15">15</a>). In economic terminology, the government’s convenient access to big data means that AI technology is intrinsically more complementary to the ruler than to other potential users in civil society groups. In the next section, we theoretically analyze why this is the case.</p>
<p>Consider a society where the aggregate output (we can think of it as the GDP) is produced by the joint force of the state  and the society : , where f is the aggregate production function and t is time. Their forces are accumulated by , , where the dot describes an instantaneous increase, i is the gross investment, and δ is the depreciation rate. There are cost functions  and  associated with the investment. In particular, to capture the increasing returns property of effort devotion, there is a threshold γ such that whenever one side does not invest sufficiently so that its state variable falls below the threshold, it then becomes more difficult to restore the momentum.</p>
<p>The output shares to be received by the state and civil society are, respectively,  and , where  represents the reward function. As stressed by Acemoglu and Robinson, the distribution function  should capture the following two properties: i) when  and  are close, both the state and the society are motivated to engage in more investment, and ii) when  and  are far apart, neither the state nor the society is willing to engage in investment. The final distribution of the output is determined by the usual Nash solution. That is, given any , the state maximizes its net expected return: , and given any , the society maximizes its net expected return:</p>
<p>In the model of state–society interactions, the dynamics are divided into three equilibrium regimes: the despotism region (Region D), the weak-state region (Region W), and the inclusive democracy region (Region I), as shown in <a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fig03">Fig. 3</a>. Given the properties of the investment cost function and the distribution function, Acemoglu and Robinson show that if the powers of the state and society are far apart, either the state or the society fully dominates the other and, as a result, the dynamics will lead to an extreme case, either a despotic (the despotism equilibrium) or an anarchic state (the weak-state equilibrium). In other words, once the increasing returns property is triggered, we then reach a state of no return: An originally strong government will become even stronger as time passes, and eventually become a despotic one. By contrast, an originally weak government will become weaker under the ever-increasing pressure of the civil society forces, and finally reach a state of anarchy.</p>
<p>If the forces of the state and the society are roughly equal and balanced, then ongoing competition will make both sides stronger over time. Because both the joint production and the checks and balances are efficient, there is an inclusive democracy. This inclusive democracy equilibrium can be reached only in the region where the forces of the state and the civil society are roughly balanced, which is why they call this region a narrow corridor. Given the above scenario, our contribution in this paper is to analyze the comparative dynamics of the model of Acemoglu and Robinson. In particular, we ask the question: How does AI/ICT affect the width of the democracy corridor?</p>
<p>To address this question, we need to understand which side AI/ICT helps more, i.e., the state or the civil society. In terms of economics, the key notion is “complementarity.” The discussion in Section 2 (<a href="http://www.pnas.org/lookup/doi/10.1073/pnas.2423266122#supplementary-materials"><i>SI Appendix</i></a>) informs us that AI/ICT advancements are more complementary to the side that has bigger data. In authoritarian and fragile democratic countries, the lopsided data advantage in favor of the state rulers makes the AI/ICT more complementary to the force of the state than to that of the society. To formalize the idea, we consider a three-factor generalized CES production function developed by Krusell et al. (<a data-xml-rid="r18" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r18">18</a>)  to capture the difference. The details are provided in supplementary Theoretical Analysis of <a href="http://www.pnas.org/lookup/doi/10.1073/pnas.2423266122#supplementary-materials"><i>SI Appendix</i>, <i>Appendix B</i></a>. Here, we summarize the results of the comparative dynamics.</p>
<p>In <a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fig03">Fig. 3</a> we derive the marginal change in the trajectory slope at any point, in response to an outside change in technology. We prove the following Proposition: Suppose a) AI/ICT and the state’s force are complementary (i.e., an increase in technology T raises the marginal productivity of the state’s force), and b) the complementarity between AI/ICT and the state’s force is stronger than that between AI/ICT and the society’s force (i.e., AI/ICT is more complementary to the force of the state than that of the society). Then in the neighborhood of the upper boundary of the democracy corridor, where a fragile democracy or an unstable autocrat is in play, the marginal effects of a rise in T always result in the trajectories bending upward. Before technology increases, an original point a on the upper boundary will move along . After technology increases, the dynamics change to . These marginal changes would make some points originally in the democracy corridor move outside the corridor after T increases. As such, the new corridor is narrower than it was before.</p>
<p>Intuitively, an advance in AI/ICT has two conflicting effects. On the one hand, technological advancement increases the marginal return from exerting effort for both the state and society. This not only enhances national output but also facilitates democratization since technology leads the strengths of the state and society to grow in a balanced way. This is referred to as the output effect. On the other hand, if information technology is more complementary to the force of the state than to that of the society, it gives the state a stronger incentive to invest its political capacity compared to civil society. This asymmetry generates a detrimental effect on democratization. This is referred to as the relative productivity effect. We also note that in the classic analysis of Acemoglu and Robinson, where the technology involved is a linear one, the relative productivity effect never arises.</p>
<p>This paper investigates the relationship between democratization and ICT development and explores the role of AI in this relationship. A novel analytical theory is also provided to demonstrate the comparative dynamics of the interactions between the state and the social force, which explains why AI/ICT innovations may hinder democratic development.</p>
<p>Our analysis explains why authoritarian countries in the Middle East have failed to democratize over the past decade. Faced with growing pressure from citizens and fearing loss of power, dictators have chosen to embrace the new technologies, thereby enhancing their authoritarian control. As a result, the Arab Spring eventually failed to flourish as originally expected. As for China, big data provide ample information for AI and ICT to improve the efficiency of government monitoring and surveillance. Furthermore, newer and more advanced information technologies reinforce the centralized structure of control, rather than facilitating political participation and democracy. As such, the optimistic expectation that economic growth in China would foster democracy has not been realized.</p>
<p>Our findings indicate that in authoritarian and fragile democratic countries, the lopsided data advantage in favor of the state rulers makes AI/ICT more complementary to the force of the state than to that of the society. Thus, the advancements in AI/ICT and worldwide democracy are negatively correlated.</p>
<p>Previous research has already identified a link between political stability and economic development: An extremely poor economy tends to spark revolt, while modern economic growth can foster democratization. How is this relationship affected by the technological change that we brought up in our discussion? Conceptually, economic distress that is sufficiently serious would certainly undermine authoritarian control, even though the government would try to suppress it. In a historical context, Usher (<a data-xml-rid="r19" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r19">19</a>) and Chu and Lee (<a data-xml-rid="r20" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r20">20</a>) have presented this “tipping point” analysis, highlighting that most peasant revolutions in history were triggered by severe famine. As regards the context of modern democratization, a similar argument has been made by Huntington (<a data-xml-rid="r21" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r21">21</a>), although he emphasized the variability of the tipping point, arguing that transitions to democracy do not follow a one-size-fits-all model. Our analysis in this paper is consistent with the above-mentioned tipping point argument, but we emphasize that AI/ICT may make the democratization threshold more difficult to reach, ceteris paribus.</p>
<p>As for the relationship between authoritarian regimes and AI, our emphasis in this paper is on the complementarity between big data owned by the government and the procurement of AI facilities. Another line of discussion has emphasized how big data helps AI innovation. Beraja and his research team identified a mutually reinforcing mechanism to explain how state involvement and data accessibility influence AI innovation in China (<a data-xml-rid="r22" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r22">22</a>, <a data-xml-rid="r23" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r23">23</a>). On the one hand, an authoritarian government can leverage its big data to support AI training, strengthening its surveillance and censorship capabilities. On the other hand, private AI firms that contract with the government can utilize these big data to enhance AI training and drive innovation. Since many AI products (such as facial recognition) are used by both the public and private sectors, the mutually reinforcing dynamics may lead to a prosperous private AI industry alongside a stable autocracy. In China, the above-mentioned mutually reinforcing mechanism provides an alternative explanation for the symbiotic relationship between AI advancement and the resilience of authoritarian control.</p>
<p>In addition to surveillance industries such as facial recognition and monitoring, the mutually reinforcing mechanism may also appear in other sectors. For instance, suppose the government compiles comprehensive individual financial data, including all their bank accounts, e-commerce purchasing records, stock and bond transactions, search engine history, etc., and shares these data with banks. As one can imagine, with the help of such big data, FinTech software is likely to become more refined and efficient.<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fn14"><sup>§§</sup></a> As AI-driven financial tools become more advanced, they help improve banking sector efficiency, increase competitiveness in the FinTech industry, and simultaneously strengthen state control over individual economic activities. Again, such developments are more likely to occur in authoritarian states rather than in democratic ones, where concerns over privacy, individual rights, and democratic checks and balances create significant barriers to large-scale data integration and government-led AI initiatives.<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fn15"><sup>¶¶</sup></a></p>
<p>Although our analysis suggests that AI primarily benefits state rulers, future AI/ICT advancements could potentially shift the balance in favor of civilians. After all, generative AI has only been around for a decade, and a rigorous causal analysis of the relationship between AI/ICT advancement and democracy requires more empirical observation and further investigation. In the final two paragraphs of this paper, we provide some diversified perspectives on the future of AI/ICT development.</p>
<p>The first example concerns the advancement of low Earth orbit (LEO) satellites, which may challenge the centralized digital control of information in authoritarian states. LEO satellites operate at altitudes of about 200-350 km above the Earth’s surface and can function as “base stations in the sky.”<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fn16"><sup>##</sup></a> With thousands of LEO satellites serving as base stations, authoritarian rulers may have difficulty intercepting the data transmission between civilian smartphones and satellites because the transmission to LEO is vertical and does not pass through any terrestrial infrastructure along the horizontal dimension. During the 2022 protests in Iran, the use of SpaceX’s Starlink, together with encrypted communication apps, hindered the Iranian government’s ability to control information and enforce internet censorship.</p>
<p>In his 2024 book, Harari argues that advanced generative AI may facilitate reasoning beyond an autocrat’s conventional thinking (<a data-xml-rid="r24" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r24">24</a>). As such, AI’s ability to produce novel insights and decisions introduces unpredictability, potentially destabilizing authoritarian regimes. Even if an autocrat attempts to use AI to reinforce control, the outcome may be counterproductive. The impact of these new technologies on the development of democracy warrants our continued attention and further in-depth research in the future.</p>
<p>In terms of the democracy indicators, we collect from the FH annual global report, and the Democracy Index is compiled by the EIU. As for the governments’ ICT capacities and surveillance and censorship practices, we use the survey of the DSP dataset. In Section 2.2 (Digital Media Freedom, <a href="http://www.pnas.org/lookup/doi/10.1073/pnas.2423266122#supplementary-materials"><i>SI Appendix</i></a>) of the DSP dataset, there are three ICT capacity measures for the Internet and social media: CS, CF, and SD, and six variables that relate to the implementation in practice: Internet Filtering in Practice, Internet SD in Practice, Social Media SD in Practice, Social Media Alternatives, Social Media Monitoring, and Social Media Censorship in Practice. In <a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#fig01">Fig. 1</a>, we collect the number of AI/ICT-granted patents from the Global Patent Search System.</p>
<p>As for the second hypothesis (<a href="https://www.pnas.org/doi/10.1073/pnas.2423266122#t02">Table 2</a>), we take the first-order differences for all indices and then perform a linear dynamic panel-data estimation, accounting for both country and year fixed effects. The regression model is</p>
<p>where  is the government’s implementation practice,  is the government’s technological capacity, and  () is a dummy variable that equals 1 if country i is in group H (group L).  measures the country fixed effect,  measures the year fixed effect, and  captures the difference in the year fixed effect between groups L and H. The interaction terms of the group dummy variables are included in order to control for the autoregressive and lag distributed effects for different democratic groups. The Arellano–Bond method for the linear dynamic panel-data regression is used to estimate the parameters (<a data-xml-rid="r25" href="https://www.pnas.org/doi/10.1073/pnas.2423266122#r25">25</a>). We also use high-order lagged independent variables as IVs to control for the endogeneity of  caused by simultaneous effects.</p>
<p>where  denotes FH’s Global Freedom, FH’s Political Rights, or the EIU’s Democracy Index, and  are the government’s implementation practices. In the second regression model, we further consider the difference in groups H and L as follows</p>
<p>We would like to thank Joseph Stiglitz, Mikhail Golosoy, David W. Savitski, Shu-Chun S. Yang, Ching-Chong Lai, Chih-Sheng Hsieh, Po-Hsuan Hsu, Kong-Pin Chen, Wei-Neng Wang, Chung-Li Wu, and seminar participants at Academia Sinica and National Taiwan University for their suggestions, comments, and encouragement on earlier drafts of this paper. Any remaining errors are, of course, our own responsibility.</p>
<h3>Author contributions</h3>
<p>C.Y.C.C. designed research; C.Y.C.C., J.-J.C., and C.-C.L. performed research; C.Y.C.C., J.-J.C., and C.-C.L. analyzed data; and C.Y.C.C., J.-J.C., and C.-C.L. wrote the paper.</p>
<h3>Competing interests</h3>
<p>The authors declare no competing interest.</p>
