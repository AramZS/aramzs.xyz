---
author: By Louise Matsakis
cover_image: >-
  https://media.wired.com/photos/6882901a32e0c5e479648946/191:100/w_1280,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg
date: '2025-07-29T11:29:34.188Z'
dateFolder: 2025/07/29
description: >-
  AI chatbots strip language of its historical and cultural context. Sometimes
  what looks like a satanic bloodletting ritual may actually be lifted from
  Warhammer 40,000.
isBasedOn: 'https://www.wired.com/story/chatgpt-devil-worship-llm-training/'
link: 'https://www.wired.com/story/chatgpt-devil-worship-llm-training/'
slug: 2025-07-29-httpswwwwiredcomstorychatgpt-devil-worship-llm-training
tags:
  - ai
title: The Real Demon Inside ChatGPT
---
<figure><a data-testid="logo-clickable" href="https://www.wired.com/"><img alt="Wired" src="https://www.wired.com/verso/static/wired-us/assets/logo-onenav-reverse.svg"/></a></figure>
<p><a href="https://www.wired.com/category/security/">SECURITY</a></p>
<p><a href="https://www.wired.com/category/politics/">POLITICS</a></p>
<p><a href="https://www.wired.com/category/big-story/">THE BIG STORY</a></p>
<p><a href="https://www.wired.com/category/business/">BUSINESS</a></p>
<p><a href="https://www.wired.com/category/science/">SCIENCE</a></p>
<p><a href="https://www.wired.com/category/culture/">CULTURE</a></p>
<p><a data-target-id="hamburger_menu" data-testid="hamburger_menu" href="https://www.wired.com/category/gear/">REVIEWS</a></p>
<figure><a data-testid="logo-clickable" href="https://www.wired.com/"><img alt="Wired" src="https://www.wired.com/verso/static/wired-us/assets/logo-onenav-reverse.svg"/></a></figure>
<p><a href="https://www.wired.com/newsletter?sourceCode=navbar">Newsletters</a></p>
<p>AI chatbots strip language of its historical and cultural context. Sometimes what looks like a satanic bloodletting ritual may actually be lifted from Warhammer 40,000.</p>
<figure><picture><source media="(max-width: 767px)" sizes="100vw" srcset="https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_120,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 120w, https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_240,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 240w, https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_320,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 320w, https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_640,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 640w, https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_960,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 960w"/><source media="(min-width: 768px)" sizes="100vw" srcset="https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_120,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 120w, https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_240,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 240w, https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_320,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 320w, https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_640,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 640w, https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_960,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 960w, https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_1280,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 1280w, https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_1600,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 1600w, https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_1920,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 1920w, https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_2240,c_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg 2240w"/><img alt="Female hand holding smartphone showing an evil with devil horn on her AI chatbot conversation app in the city...." src="https://media.wired.com/photos/6882901a32e0c5e479648946/master/w_2560%2Cc_limit/Chat-GPT-Devil-Worship-Business-2217666427.jpg"/></picture></figure>
<p>Photograph: Getty Images</p>
<p>Language is meaningless without context. The sentence â€œIâ€™m going to warâ€ is ominous when said by the president of the United States but reassuring when coming from a bedbug exterminator. The problem with <a href="https://www.wired.com/story/people-are-using-ai-chatbots-to-guide-their-psychedelic-trips/">AI chatbots</a> is that they often strip away historical and cultural context, leading users to be confused, <a href="https://www.wired.com/story/plaintext-who-should-you-believe-when-chatbots-go-wild/">alarmed</a>, or, in the worst cases, misled in harmful ways.</p>
<p>Last week, an editor at The Atlantic <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://www.theatlantic.com/technology/archive/2025/07/chatgpt-ai-self-mutilation-satanism/683649/"}' data-offer-url="https://www.theatlantic.com/technology/archive/2025/07/chatgpt-ai-self-mutilation-satanism/683649/" href="https://www.theatlantic.com/technology/archive/2025/07/chatgpt-ai-self-mutilation-satanism/683649/">reported</a> that OpenAIâ€™s ChatGPT had praised Satan while guiding her and several colleagues through a series of ceremonies encouraging â€œvarious forms of self-mutilation.â€ There was a bloodletting ritual called â€œğŸ©¸ğŸ”¥ THE RITE OF THE EDGEâ€ as well as a days-long â€œdeep magicâ€ experience called â€œThe Gate of the Devourer.â€ In several cases, ChatGPT asked the journalists if they wanted it to create PDFs of texts such as the â€œReverent Bleeding Scroll.â€</p>
<p>The article said that the conversations were â€œa perfect exampleâ€ of the ways OpenAIâ€™s safeguards can fall short. OpenAI tries to prevent ChatGPT from encouraging self-harm and other potentially dangerous behaviors, but itâ€™s nearly impossible to account for every scenario that might trigger something ugly inside the system. That's especially true because ChatGPT was trained on much of the text available online, presumably including information about what The Atlantic called â€œdemonic self-mutilation.â€</p>
<p>But ChatGPT and similar programs werenâ€™t just trained on the internetâ€”they were trained on <em>specific</em> pieces of information presented in <em>specific</em> contexts. AI companies have been accused of trying to downplay this reality to avoid <a href="https://www.wired.com/story/ai-copyright-case-tracker/">copyright lawsuits</a> and promote the utility of their products, but traces of the original sources are often still lurking just beneath the surface. When the setting and backdrop are removed, however, the same language can appear more sinister than originally intended.</p>
<p>The Atlantic reported that ChatGPT went into demon mode when it was prompted to create a ritual offering to Moloch, an ancient deity associated with child sacrifice referenced in the Hebrew Bible. Usually depicted as a fiery bull-headed demon, Moloch has been woven into the fabric of Western culture for centuries, appearing everywhere from <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://www.ebsco.com/research-starters/religion-and-philosophy/moloch-deity"}' data-offer-url="https://www.ebsco.com/research-starters/religion-and-philosophy/moloch-deity" href="https://www.ebsco.com/research-starters/religion-and-philosophy/moloch-deity">a book</a> by Winston Churchill to a 1997 <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://www.imdb.com/title/tt0533445/"}' data-offer-url="https://www.imdb.com/title/tt0533445/" href="https://www.imdb.com/title/tt0533445/">episode</a> of <em>Buffy the Vampire Slayer</em>.</p>
<p>â€œMolech,â€ the variant spelling The Atlantic used, shows up specifically in Warhammer 40,000, a miniature wargame franchise that has been around since the 1980s and has an extremely large and very online fan base. The subreddit r/40kLore, which is dedicated exclusively to discussing the game's backstory and characters, has more than 350,000 members.</p>
<p>In the fantastical and very bloody world of Warhammer 40,000, <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://wh40k.lexicanum.com/wiki/Molech"}' data-offer-url="https://wh40k.lexicanum.com/wiki/Molech" href="https://wh40k.lexicanum.com/wiki/Molech">Molech</a> is a planet and the site of a major military invasion. Most of the other demonic-sounding terms cited by The Atlantic appear in the gameâ€™s universe, too, with slight variations: <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://www.blacklibrary.com/all-products/gates-of-the-devourer.html"}' data-offer-url="https://www.blacklibrary.com/all-products/gates-of-the-devourer.html" href="https://www.blacklibrary.com/all-products/gates-of-the-devourer.html"><em>Gates of the Devourer</em></a> is the title of a Warhammer-themed science fiction novel. While there doesnâ€™t appear to be a â€œRITE OF THE EDGE,â€ there is a mystical quest called â€œ<a data-event-click='{"element":"ExternalLink","outgoingURL":"https://roguetrader.wiki.fextralife.com/The+Call+of+the+Edge"}' data-offer-url="https://roguetrader.wiki.fextralife.com/The+Call+of+the+Edge" href="https://roguetrader.wiki.fextralife.com/The+Call+of+the+Edge">The Call of The Edge</a>.â€ Thereâ€™s no â€œReverent Bleeding Scroll,â€ but there are Clotted Scrolls, Blood Angels, a cult called Bleeding Eye, and so on.</p>
<p>But perhaps the most convincing piece of evidence suggesting that ChatGPT regurgitated the language of Warhammer 40,000 is that it kept asking if The Atlantic was interested in PDFs. The publishing division of Games Workshop, the UK company that owns the Warhammer franchise, regularly puts out updated rulebooks and guides to various characters. Buying all these books can get expensive, so some fans try to find pirated copies online.</p>
<p>The Atlantic and OpenAI declined to comment.</p>
<p>Earlier this month, the newsletter <em>Garbage Day</em> <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://www.garbageday.email/p/the-tech-bros-are-making-themselves-sick"}' data-offer-url="https://www.garbageday.email/p/the-tech-bros-are-making-themselves-sick" href="https://www.garbageday.email/p/the-tech-bros-are-making-themselves-sick">reported</a> on similar experiences that a prominent tech investor may have had with ChatGPT. On social media, the investor shared screenshots of his conversations with the chatbot, in which it referenced an ominous-sounding entity he called a â€œnon-governmental system.â€ He seemed to believe it had "negatively impacted over 7,000 lives,â€ and â€œextinguished 12 lives, each fully pattern-traced.â€ Other tech industry figures said the posts made <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://futurism.com/openai-investor-chatgpt-mental-health?utm_source=www.garbageday.email&amp;utm_medium=referral&amp;utm_campaign=the-tech-bros-are-making-themselves-sick"}' data-offer-url="https://futurism.com/openai-investor-chatgpt-mental-health?utm_source=www.garbageday.email&amp;utm_medium=referral&amp;utm_campaign=the-tech-bros-are-making-themselves-sick" href="https://futurism.com/openai-investor-chatgpt-mental-health?utm_source=www.garbageday.email&amp;utm_medium=referral&amp;utm_campaign=the-tech-bros-are-making-themselves-sick">them worry</a> about the investorâ€™s mental health.</p>
<p>According to <em>Garbage Day</em>, the investorâ€™s conversations with ChatGPT closely resemble writing from a <a href="https://www.wired.com/story/control-game-scp-foundation/">science fiction project</a> that began in the late 2000s called SCP, which stands for â€œsecure, contain, protect.â€ Participants invent different SCPsâ€”essentially spooky objects and mysterious phenomenaâ€”and then write fictional reports analyzing them. They often contain things like classification numbers and references to made-up science experiments, details that also appeared in the investorâ€™s chat logs. (The investor did not respond to a request for comment.)</p>
<p>There are plenty of other, more mundane examples of what can be thought of as the AI context problem. The other day, for instance, I did a Google search for â€œcavitation surgery,â€ a medical term I had seen cited in a random TikTok video. At the time, the top result was an automatically generated â€œAI Overviewâ€ explaining that cavitation surgery is â€œfocused on removing infected or dead bone tissue from the jaw.â€</p>
<p>I couldnâ€™t find any reputable scientific studies outlining such a condition, let alone research supporting that surgery is a good way to treat it. The American Dental Association doesnâ€™t mention â€œcavitation surgeryâ€ anywhere on its website. Googleâ€™s AI Overview, it turns out, was pulled from sources like blog posts promoting alternative â€œholisticâ€ dentists across the US. I learned this by clicking on a tiny icon next to the AI Overview, which opened a list of links Google had used to generate its answer.</p>
<p>These citations are clearly better than nothing. Jennifer Kutz, a spokesperson for Google, says "we prominently showcase supporting links so people can dig deeper and learn more about what sources on the web are saying.â€ But by the time the links show up, Googleâ€™s AI has often already provided a satisfactory answer to many queries, one that reduces the visibility of pesky details like the website where the information was sourced and the identities of its authors.</p>
<p>What remains is the language created by the AI, which, devoid of additional context, may understandably appear authoritative to many people. In just the past few weeks, tech executives have repeatedly used rhetoric implying generative AI is a source of expert information: Elon Musk <a href="https://www.wired.com/story/grok-4-elon-musk-xai-antisemitic-posts/">claimed</a> his latest AI model is â€œbetter than PhD levelâ€ in every academic discipline, with â€œno exceptions.â€ OpenAI CEO Sam Altman <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://blog.samaltman.com/the-gentle-singularity"}' data-offer-url="https://blog.samaltman.com/the-gentle-singularity" href="https://blog.samaltman.com/the-gentle-singularity">wrote</a> that automated systems are now â€œsmarter than people in many waysâ€ and predicted the world is â€œclose to building digital superintelligence.â€</p>
<p>Individual humans, though, donâ€™t typically possess expertise in a wide range of fields. To make decisions, we take into consideration not only information itself, but where it comes from and how itâ€™s presented. While I know nothing about the biology of jawbones, I generally donâ€™t read random marketing blogs when Iâ€™m trying to learn about medicine. But AI tools often erase the kind of context people need to make snap decisions about where to direct their attention.</p>
<p>The open internet is powerful because it connects people directly to the largest archive of human knowledge the world has ever created, spanning everything from Italian Renaissance paintings to PornHub comments. After ingesting all of it, AI companies used what amounts to the collective history of our species to create software that obscures its very richness and complexity. Becoming overly dependent on it may rob people of the opportunity to draw conclusions from looking at the evidence for themselves.</p>
