---
author: Ashley Belanger
cover_image: >-
  https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-1152x648-1751471454.jpg
date: '2025-07-02T22:05:09.000Z'
dateFolder: 2025/07/02
description: >-
  The New York Times will soon search deleted ChatGPT logs after winning a court
  case against OpenAI. Only a small, anonymized sample of the data will be
  reviewed using agreed keywords. Experts worry that private chat logs might not
  help the case and could be risky to handle securely.
isBasedOn: >-
  https://arstechnica.com/tech-policy/2025/07/nyt-to-start-searching-deleted-chatgpt-logs-after-beating-openai-in-court/
link: >-
  https://arstechnica.com/tech-policy/2025/07/nyt-to-start-searching-deleted-chatgpt-logs-after-beating-openai-in-court/
slug: >-
  2025-07-02-httpsarstechnicacomtech-policy202507nyt-to-start-searching-deleted-chatgpt-logs-after-beating-openai-in-court
tags:
  - ai
  - law and order
title: OpenAI lost its fight over retaining ChatGPT logs “indefinitely”—now what?
---
<figure></figure><p> <em> Peeping deleted chats </em></p>
<p>What are the odds NYT will access your ChatGPT logs in OpenAI court battle?</p>
<p><a href="https://arstechnica.com/author/ashleybelanger/"> Ashley Belanger </a> –  Jul 2, 2025 4:34 PM |</p>
<figure><a data-cropped="true" data-pswp-height="1414" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080.jpg 2121w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-640x427.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-1024x683.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-768x512.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-1536x1024.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-2048x1365.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-980x653.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-1440x960.jpg 1440w" data-pswp-width="2121" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080.jpg"><img alt="" sizes="(max-width: 1152px) 100vw, 1152px" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-1536x864-1751471455.jpg" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-1152x648-1751471454.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-384x216-1751471453.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-768x432-1751471454.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2200528080-1536x864-1751471455.jpg 1536w"/></a><figcaption>/ Credit:Pakorn Supajitsoontorn | iStock / Getty Images Plus</figcaption></figure>
<figure></figure><figure></figure><p>Last week, OpenAI raised objections in court, hoping to overturn a court order requiring the AI company <a href="https://arstechnica.com/tech-policy/2025/06/openai-confronts-user-panic-over-court-ordered-retention-of-chatgpt-logs/">to retain all ChatGPT logs "indefinitely,"</a> including deleted and temporary chats.</p>
<p>But Sidney Stein, the US district judge reviewing OpenAI's request, immediately denied OpenAI's objections. He was seemingly unmoved by the <a href="https://arstechnica.com/tech-policy/2025/06/openai-confronts-user-panic-over-court-ordered-retention-of-chatgpt-logs/">company's claims</a> that the order forced OpenAI to abandon "long-standing privacy norms" and weaken privacy protections that users expect based on ChatGPT's terms of service. Rather, Stein suggested that OpenAI's user agreement specified that their data could be retained as part of a legal process, which Stein said is exactly what is happening now.</p>
<p>The order was issued by magistrate judge Ona Wang just days after news organizations, led by The New York Times, requested it. The news plaintiffs claimed the order was urgently needed to preserve potential evidence in their copyright case, alleging that ChatGPT users are likely to delete chats where they attempted to use the chatbot to skirt paywalls to access news content.</p>
<p>A spokesperson told Ars that OpenAI plans to "keep fighting" the order, but the ChatGPT maker seems to have few options left. They could possibly petition the Second Circuit Court of Appeals for a rarely granted emergency order that could intervene to block Wang's order, but the appeals court would have to consider Wang's order an extraordinary abuse of discretion for OpenAI to win that fight.</p>
<p>OpenAI's spokesperson declined to confirm if the company plans to pursue this extreme remedy.</p>
<p>In the meantime, OpenAI is negotiating a process that will allow news plaintiffs to search through the retained data. Perhaps the sooner that process begins, the sooner the data will be deleted. And that possibility puts OpenAI in the difficult position of having to choose between either caving to some data collection to stop retaining data as soon as possible or prolonging the fight over the order and potentially putting more users' private conversations at risk of exposure through litigation or, worse, a data breach.</p>
<h2>News orgs will soon start searching ChatGPT logs</h2>
<p>The clock is ticking, and so far, OpenAI has not provided any official updates since a June 5 <a href="https://openai.com/index/response-to-nyt-data-demands/">blog post</a> detailing which ChatGPT users will be affected.</p>
<p>While it's clear that OpenAI has been and will continue retaining mounds of data, it would be impossible for The New York Times or any news plaintiff to search through all that data.</p>
<p>Instead, only a small sample of the data will likely be accessed, based on keywords that OpenAI and news plaintiffs agree on. That data will remain on OpenAI's servers, where it will be anonymized, and it will likely never be directly produced to plaintiffs.</p>
<p>Both sides are negotiating the exact process for searching through the chat logs, with both parties seemingly hoping to minimize the amount of time the chat logs will be preserved.</p>
<p>For OpenAI, sharing the logs risks revealing instances of infringing outputs that could further spike damages in the case. The logs could also expose how often outputs attribute misinformation to news plaintiffs.</p>
<p>But for news plaintiffs, accessing the logs is not considered key to their case—perhaps providing additional examples of copying—but could help news organizations argue that ChatGPT dilutes the market for their content. That could weigh against the fair use argument, as a <a href="https://arstechnica.com/tech-policy/2025/06/book-authors-made-the-wrong-arguments-in-meta-ai-training-case-judge-says/">judge opined in a recent ruling</a> that evidence of market dilution could tip an AI copyright case in favor of plaintiffs.</p>
<p>Jay Edelson, a leading consumer privacy lawyer, told Ars that he's concerned that judges don't seem to be considering that any evidence in the ChatGPT logs wouldn't "advance" news plaintiffs' case "at all," while really changing "a product that people are using on a daily basis."</p>
<p>Edelson warned that OpenAI itself probably has better security than most firms to protect against a potential data breach exposing these private chat logs. But "lawyers have notoriously been pretty bad about securing data," Edelson suggested, so "the idea that you've got a bunch of lawyers who are going to be doing whatever they are" with "some of the most sensitive data on the planet" and "they're the ones protecting it against hackers should make everyone uneasy."</p>
<p>So even though odds are pretty good that the majority of users' chats won't end up in the sample, Edelson said the mere threat of being included might push some users to rethink how they use AI. He further warned that ChatGPT users turning to OpenAI rival services like Anthropic's Claude or Google's Gemini could suggest that Wang's order is improperly influencing market forces, which also seems "crazy."</p>
<p>To Edelson, the most "cynical" take could be that news plaintiffs are possibly hoping the order will threaten OpenAI's business to the point where the AI company agrees to a settlement.</p>
<p>Regardless of news plaintiffs' motives, the order sets an alarming precedent, Edelson said. He joined critics suggesting that more AI data may be frozen in the future, potentially affecting even more users as a result of the sweeping order surviving scrutiny in this case. Imagine if litigation one day targets Google's AI search summaries, Edelson suggested.</p>
<h2>Lawyer slams judges for giving ChatGPT users no voice</h2>
<p>Edelson told Ars that the order is so potentially threatening to OpenAI's business that the company may not have a choice but to explore every path available to continue fighting it.</p>
<p>"They will absolutely do something to try to stop this," Edelson predicted, calling the order "bonkers" for overlooking millions of users' privacy concerns while "strangely" excluding enterprise customers.</p>
<p>From court filings, it seems possible that enterprise users were excluded to protect OpenAI's competitiveness, but Edelson suggested there's "no logic" to their exclusion "at all." By excluding these ChatGPT users, the judge's order may have removed the users best resourced to fight the order, Edelson suggested.</p>
<p>"What that means is the big businesses, the ones who have the power, all of their stuff remains private, and no one can touch that," Edelson said.</p>
<p>Instead, the order is "only going to intrude on the privacy of the common people out there," which Edelson said "is really offensive," given that Wang <a href="https://arstechnica.com/tech-policy/2025/06/judge-rejects-claim-that-forcing-openai-to-keep-chatgpt-logs-is-mass-surveillance/">denied two ChatGPT users' panicked request to intervene</a>.</p>
<p>"We are talking about billions of chats that are now going to be preserved when they weren't going to be preserved before," Edelson said, noting that he's input information about his personal medical history into ChatGPT. "People ask for advice about their marriages, express concerns about losing jobs. They say really personal things. And one of the bargains in dealing with OpenAI is that you're allowed to delete your chats and you're allowed to temporary chats."</p>
<p>The greatest risk to users would be a data breach, Edelson said, but that's not the only potential privacy concern. Corynne McSherry, legal director for the digital rights group the Electronic Frontier Foundation, previously told Ars that as long as users' data is retained, it could also be exposed through future law enforcement and private litigation requests.</p>
<p>Edelson pointed out that most privacy attorneys don't consider OpenAI CEO Sam Altman to be a "privacy guy," despite Altman <a href="https://techcrunch.com/2025/06/25/sam-altman-comes-out-swinging-at-the-new-york-times/">recently slamming</a> the NYT, alleging it sued OpenAI because it doesn't "like user privacy."</p>
<p>"He's trying to protect OpenAI, and he does not give a hoot about the privacy rights of consumers," Edelson said, echoing one ChatGPT user's dismissed concern that OpenAI may not prioritize users' privacy concerns in the case if it's financially motivated to resolve the case.</p>
<p>"The idea that he and his lawyers are really going to be the safeguards here isn't very compelling," Edelson said. He criticized the judges for dismissing users' concerns and rejecting OpenAI's request that users get a chance to testify.</p>
<p>"What's really most appalling to me is the people who are being affected have had no voice in it," Edelson said.</p>
