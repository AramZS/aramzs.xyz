---
author: Justin Hendrix
cover_image: >-
  https://cdn.sanity.io/images/3tzzh18d/production/ca8393b380961a234123ad924f89ed855aed0c1d-1200x675.png
date: '2025-07-16T12:17:55.065Z'
dateFolder: 2025/07/16
description: >-
  A conversation with ECNL's Marlena Wisniak on her report, Algorithmic
  Gatekeepers: The Human Rights Impacts of LLM Content Moderation.
isBasedOn: >-
  https://www.techpolicy.press/considering-the-human-rights-impacts-of-llm-content-moderation/
link: >-
  https://www.techpolicy.press/considering-the-human-rights-impacts-of-llm-content-moderation/
slug: >-
  2025-07-16-httpswwwtechpolicypressconsidering-the-human-rights-impacts-of-llm-content-moderation
tags:
  - ai
  - ai-created-labor
title: Considering the Human Rights Impacts of LLM Content Moderation
---
<p><a href="https://techpolicypress.captivate.fm/listen"><em>Audio of this conversation is available via your favorite podcast service.</em></a></p>
<p>At Tech Policy Press weâ€™ve been <a href="https://www.techpolicy.press/syllabus-large-language-models-content-moderation-and-political-communication/">tracking</a> the emerging application of generative AI systems in content moderation. Recently, the European Center for Not-for-Profit Law (ECNL) released a comprehensive report titled <a href="https://ecnl.org/sites/default/files/2025-04/ECNL_LLM_CM_Excecutive%20Summary_2025.pdf"><em>Algorithmic Gatekeepers: The Human Rights Impacts of LLM Content Moderation</em></a>, which looks at the opportunities and challenges of using generative AI in content moderation systems at scale. I spoke to its primary author, ECNL senior legal manager <strong>Marlena Wisniak</strong>.</p>
<p><em>A transcript is forthcoming.</em></p>
