---
author: Joanna Gerber
cover_image: 'https://www.adexchanger.com/wp-content/uploads/2021/09/losing_money_header.jpg'
date: '2025-07-14T18:15:46.840Z'
dateFolder: 2025/07/14
description: >-
  The IAB Tech Lab's new initiative suggests regulations for how AI bots can
  access content, ensuring that publishers are fairly compensated.
isBasedOn: >-
  https://www.adexchanger.com/publishers/behind-the-iab-tech-labs-new-initiative-to-deal-with-ai-scraping-and-publisher-revenue-loss/
link: >-
  https://www.adexchanger.com/publishers/behind-the-iab-tech-labs-new-initiative-to-deal-with-ai-scraping-and-publisher-revenue-loss/
slug: >-
  2025-07-14-httpswwwadexchangercompublishersbehind-the-iab-tech-labs-new-initiative-to-deal-with-ai-scraping-and-publisher-revenue-loss
tags:
  - ai
  - media
  - ad tech
title: >-
  Behind The IAB Tech Lab’s New Initiative To Deal With AI Scraping And
  Publisher Revenue Loss
---
<figure><img alt="App developers aren’t making as much money as they could from in-app auctions despite the promise of increased average revenue per daily user." data-uw-rm-alt="ALT" data-uw-rm-alt-original="App developers aren’t making as much money as they could from in-app auctions despite the promise of increased average revenue per daily user." sizes="(max-width: 911px) 100vw, 911px" src="https://www.adexchanger.com/wp-content/uploads/2021/09/losing_money_feature.jpg" srcset="https://www.adexchanger.com/wp-content/uploads/2021/09/losing_money_feature-911x1024.jpg 911w, https://www.adexchanger.com/wp-content/uploads/2021/09/losing_money_feature-267x300.jpg 267w, https://www.adexchanger.com/wp-content/uploads/2021/09/losing_money_feature-768x863.jpg 768w, https://www.adexchanger.com/wp-content/uploads/2021/09/losing_money_feature.jpg 1000w"/><figcaption>App developers aren’t making as much money as they could from in-app auctions despite the promise of increased average revenue per daily user.</figcaption></figure>
<p>In June, the IAB Tech Lab proposed a new initiative to create guardrails around how AI bots are permitted to access content, with an emphasis on publisher monetization.</p>
<p>It’s hoping that its new solution will get publishers back on their feet – and keep them there.</p>
<p>Publishers are like “the plankton of the digital media ecosystem,” said IAB Tech Lab CEO Anthony Katsur.</p>
<p>Every living thing in an aquatic environment depends on plankton. If they die out, the rest of the ocean goes down with them. And if publishers collapse, that would be an “extinction-level event” for digital media, Katsur said. </p>
<p>Many publishers are still managing to stay afloat, but the water is choppy, with <a data-uw-original-href="https://www.adexchanger.com/the-sell-sider/from-clicks-to-connections-three-essential-tips-for-the-post-traffic-era/" data-uw-rm-brl="PR" data-wpel-link="internal" href="https://www.adexchanger.com/the-sell-sider/from-clicks-to-connections-three-essential-tips-for-the-post-traffic-era/">traffic</a> falling off the metaphorical cliff and no metaphorical harness in sight.</p>
<p><strong>A life raft for publishers</strong></p>
<p>The IAB’s initiative, currently called the LLM Content Ingest API Initiative (“which we need to rename,” Katsur joked; it’s “a mouthful”) can be broken down into four major components.</p>
<p>The first is access controls, which determine who is allowed to access a publisher’s content in the first place.</p>
<p>Once controls are established, access terms come into place, such as licensing models and content tiers. Under the IAB’s guidelines, content will be segregated into tiers based on relevance and value.</p>
<p>“Your archival content from 10 years ago is not worth as much as your late-breaking news or your interview with Taylor Swift,” Katsur said.</p>
<p>The guidelines would also mandate logging the use of content, which Katsur defines as “tracking and recording when and how publisher content is accessed or used by an LLM or AI system,” so publishers can accurately invoice and track usage of their data.</p>
<p>Content logging ties into the final part of the initiative, which Katsur believes is the most important facet: tokenization. Tokenization involves breaking content down into smaller units made up of words, parts of words, punctuation or metadata, Katsur said. These units, called tokens, are used to train LLMs and generate their responses. Publisher content gets tokenized and uniquely assigned to each publisher.</p>
<p>Then, “using the logging and reporting functions that we are proposing,” he explained, publishers can see exactly how the information scraped from their sites is being used.</p>
<p>Tokenization is useful for brands, too, so they can see what is being said about their products and by whom. Many LLMs scrape sites like Reddit, for example, and parrot back what they find as fact – despite the information often being outdated, if not outright incorrect.</p>
<p>As AI continues to make a name for itself in search, a set of guidelines like the LLM Content Ingest API Initiative (looking forward to that new name) is the best way to ensure that query responses are accurate, Katsur said, and that publishers – and with them, the rest of the ad tech ecosystem – continue to thrive.</p>
<p><strong>The big picture</strong></p>
<p>But let’s zoom out.</p>
<p>What actually happens when a bot scrapes a website?</p>
<p>First, it’s important to note that AI isn’t born with limitless knowledge. It has to get that knowledge from somewhere. That’s why AI bots mine websites, which are vast troves of information.</p>
<p>Sometimes, scraping is one-and-done. When a query is for something straightforward, like a chocolate chip cookie recipe, a bot typically won’t need to continue scraping a site for more updated information, Katsur explained, since a cookie recipe doesn’t generally update or evolve. And once an AI model has a good recipe, it can feed it (no pun intended) to the hundreds of thousands of people requesting it.</p>
<p>It’s not guaranteed that after a page is scraped once it never will be scraped again. There is a common misconception “that once an LLM crawls, it stores all the data and never crawls again,” said Katsur. IAB research has shown that crawlers will recrawl content they have already accessed.</p>
<p>Still, scraping the same page a handful of additional times doesn’t scale against the pay-per-visit model that publishers are used to.</p>
<p>With a pay-per-crawl model, a publisher gets paid when a bot pulls information from its site – and that’s basically the end of the story. No matter how many of a generative AI search engine’s users benefit from that information down the line, the publisher only gets paid once per scrape.</p>
<p>Pay per query, on the other hand, is more similar to the way publishers currently drive revenue, and is the model favored by the IAB Tech Lab. “Now you’re getting paid per use,” said Katsur, “which is similar to getting paid per visit.”</p>
<p>“Pay per query scales,” he said. “Pay per crawl does not.”</p>
<p>Problem is, even pay per crawl isn’t guaranteed. Plenty of bots are <a data-uw-original-href="https://www.404media.co/ai-scraping-bots-are-breaking-open-libraries-archives-and-museums/" data-uw-rm-brl="PR" data-uw-rm-ext-link="" data-wpel-link="external" href="https://www.404media.co/ai-scraping-bots-are-breaking-open-libraries-archives-and-museums/">scraping sites without providing any compensation</a> and, technically, that’s allowed – for now.</p>
<p>But that seems to be changing, as more companies develop models that put publisher monetization at the forefront.</p>
<p>Earlier this month, <a data-uw-original-href="https://www.adexchanger.com/daily-news-roundup/wednesday-20250207/" data-uw-rm-brl="PR" data-wpel-link="internal" href="https://www.adexchanger.com/daily-news-roundup/wednesday-20250207/">Cloudflare</a> implemented a new pay-per-crawl model that gives publishers full rein over the access they provide to bots. Publishers can give full access, block all scraping or opt into the new pay-per-crawl model, which requires bots to share payment information so they can be charged for each scrape.</p>
<p>That’s something – although, until this sort of model is widely adopted, publisher traffic is still in serious danger.</p>
<p>But, hey, along with the LLM Content Ingest API Initiative, it’s definitely a start.</p>
