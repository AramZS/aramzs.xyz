---
author: Kyle Orland
cover_image: >-
  https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-1152x648.jpg
date: '2025-07-14T20:31:16.309Z'
dateFolder: 2025/07/14
description: >-
  Coders spent more time prompting and reviewing AI generations than they saved
  on coding.
isBasedOn: >-
  https://arstechnica.com/ai/2025/07/study-finds-ai-tools-made-open-source-software-developers-19-percent-slower/?utm_source=bsky&utm_medium=social
link: >-
  https://arstechnica.com/ai/2025/07/study-finds-ai-tools-made-open-source-software-developers-19-percent-slower/?utm_source=bsky&utm_medium=social
slug: >-
  2025-07-14-httpsarstechnicacomai202507study-finds-ai-tools-made-open-source-software-developers-19-percent-slowerutmsourcebskyandutmmediumsocial
tags:
  - ai
  - tech
title: Study finds AI tools made open source software developers 19 percent slower
---
<figure></figure><p>  going for speed </p>
<p>Coders spent more time prompting and reviewing AI generations than they saved on coding.</p>
<p><a href="https://arstechnica.com/author/kyle-orland/"> Kyle Orland </a> â€“  Jul 14, 2025 4:02 PM |</p>
<figure><a data-cropped="true" data-pswp-height="1237" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524.jpg 2424w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-640x327.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-1024x523.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-768x392.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-1536x784.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-2048x1045.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-980x500.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-1440x735.jpg 1440w" data-pswp-width="2424" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524.jpg"><img alt="" sizes="(max-width: 1152px) 100vw, 1152px" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-1536x864.jpg" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1409587524-1536x864.jpg 1536w"/></a></figure>
<p>Oh no, my AI-generated code is being sucked into a time vortex again!  Credit: Getty Images </p>
<figure></figure><figure></figure><p>When it comes to concrete use cases for large language models, AI companies <a href="https://arstechnica.com/ai/2024/10/google-ceo-says-over-25-of-new-google-code-is-generated-by-ai/">love</a> to <a href="https://arstechnica.com/ai/2025/05/anthropic-calls-new-claude-4-worlds-best-ai-coding-model/">point out</a> the ways coders and software developers can <a href="https://arstechnica.com/gaming/2023/03/are-robloxs-new-ai-coding-and-art-tools-the-future-of-game-development/">use these models</a> to <a href="https://arstechnica.com/science/2023/06/ars-frontiers-recap-what-happens-to-developers-when-ai-can-code/">increase their productivity and overall efficiency</a> in <a href="https://arstechnica.com/ai/2025/03/is-vibe-coding-with-ai-gnarly-or-reckless-maybe-some-of-both/">creating computer code</a>. However, <a href="https://metr.org/Early_2025_AI_Experienced_OS_Devs_Study.pdf">a new randomized controlled trial</a> has found that experienced open source coders became less efficient at coding-related tasks when they used current AI tools.</p>
<p>For <a href="https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/">their study</a>, researchers at <a href="https://metr.org/about">METR</a> (Model Evaluation and Threat Research) recruited 16 software developers, each with multiple years of experience working on specific open source repositories. The study followed these developers across 246 individual "tasks" involved with maintaining those repos, such as "bug fixes, features, and refactors that would normally be part of their regular work." For half of those tasks, the developers used AI tools like <a href="https://cursor.com/en/pricing">Cursor Pro</a> or Anthropic's Claude; for the others, the programmers were instructed not to use AI assistance. Expected time forecasts for each task (made before the groupings were assigned) were used as a proxy to balance out the overall difficulty of the tasks in each experimental group, and the time needed to fix pull requests based on reviewer feedback was included in the overall assessment.</p>
<figure><p> </p><p> </p><p> </p><a data-cropped="false" data-pswp-height="541" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart.png 1093w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart-640x317.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart-1024x507.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart-768x380.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart-980x485.png 980w" data-pswp-width="1093" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart.png"><img alt="" sizes="auto, (max-width: 1093px) 100vw, 1093px" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart.png" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart.png 1093w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart-640x317.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart-1024x507.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart-768x380.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingchart-980x485.png 980w"/></a><p> </p><p> </p><p> </p><figcaption> <p> </p><p> </p><p> Experts and the developers themselves expected time savings that didn't materialize when AI tools were actually used. </p> Credit: <a href="https://metr.org/Early_2025_AI_Experienced_OS_Devs_Study.pdf"> METR </a> <p> </p><p> </p> </figcaption></figure>
<p>Before performing the study, the developers in question expected the AI tools would lead to a 24 percent reduction in the time needed for their assigned tasks. Even after completing those tasks, the developers believed that the AI tools had made them 20 percent faster, on average. In reality, though, the AI-aided tasks ended up being completed 19 percent <em>slower</em> than those completed without AI tools.</p>
<h2>Trade-offs</h2>
<p>By analyzing screen recording data from a subset of the studied developers, the METR researchers found that AI tools tended to reduce the average time those developers spent actively coding, testing/debugging, or "reading/searching for information." But those time savings were overwhelmed in the end by "time reviewing AI outputs, prompting AI systems, and waiting for AI generations," as well as "idle/overhead time" where the screen recordings show no activity.</p>
<p>Overall, the developers in the study accepted less than 44 percent of the code generated by AI without modification. A majority of the developers reported needing to make changes to the code generated by their AI companion, and a total of 9 percent of the total task time in the "AI-assisted" portion of the study was taken up by this kind of review.</p>
<figure><p> </p><p> </p><p> </p><a data-cropped="false" data-pswp-height="737" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime.png 1141w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime-640x413.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime-1024x661.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime-768x496.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime-980x633.png 980w" data-pswp-width="1141" href="https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime.png"><img alt="" sizes="auto, (max-width: 1141px) 100vw, 1141px" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime.png" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime.png 1141w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime-640x413.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime-1024x661.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime-768x496.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/07/aicodingtime-980x633.png 980w"/></a><p> </p><p> </p><p> </p><figcaption> <p> </p><p> </p><p> Time saved on things like active coding was overwhelmed by the time needed to prompt, wait on, and review AI outputs in the study. </p> Credit: <a href="https://metr.org/Early_2025_AI_Experienced_OS_Devs_Study.pdf"> METR </a> <p> </p><p> </p> </figcaption></figure>
<p>On the surface, METR's results seem to contradict other <a href="https://arxiv.org/abs/2501.01257">benchmarks</a> and <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4945566">experiments</a> that demonstrate increases in coding efficiency when AI tools are used. But those often also measure productivity in terms of total lines of code or the number of discrete tasks/code commits/pull requests completed, all of which can be poor proxies for actual coding efficiency.</p>
<p>Many of the existing coding benchmarks also focus on synthetic, algorithmically scorable tasks created specifically for the benchmark test, making it hard to compare those results to those focused on work with pre-existing, real-world code bases. Along those lines, the developers in METR's study reported in surveys that the overall complexity of the repos they work with (which average 10 years of age and over 1 million lines of code) limited how helpful the AI could be. The AI wasn't able to utilize "important tacit knowledge or context" about the codebase, the researchers note, while the "high developer familiarity with [the] repositories" aided their very human coding efficiency in these tasks.</p>
<p>These factors lead the researchers to conclude that current AI coding tools may be particularly ill-suited to "settings with very high quality standards, or with many implicit requirements (e.g., relating to documentation, testing coverage, or linting/formatting) that take humans substantial time to learn." While those factors may not apply in "many realistic, economically relevant settings" involving simpler code bases, they could limit the impact of AI tools in this study and similar real-world situations.</p>
<p>And even for complex coding projects like the ones studied, the researchers are also optimistic that further refinement of AI tools could lead to future efficiency gains for programmers. Systems that have better reliability, lower latency, or more relevant outputs (via techniques such as prompt scaffolding or fine-tuning) "could speed up developers in our setting," the researchers write. Already, they say there is "preliminary evidence" that the recent release of Claude 3.7 "can often correctly implement the core functionality of issues on several repositories that are included in our study."</p>
<p>For now, however, METR's study provides some strong evidence that AI's much-vaunted usefulness for coding tasks may have significant limitations in certain complex, real-world coding scenarios.</p>
<figure><a href="https://arstechnica.com/author/kyle-orland/"><img alt="Photo of Kyle Orland" src="https://cdn.arstechnica.net/wp-content/uploads/2016/05/k.orland-13.jpg"/></a></figure>
<p><a href="https://arstechnica.com/author/kyle-orland/"> Kyle Orland </a> Senior Gaming Editor</p>
<p>Kyle Orland has been the Senior Gaming Editor at Ars Technica since 2012, writing primarily about the business, tech, and culture behind video games. He has journalism and computer science degrees from University of Maryland. He once <a href="https://bossfightbooks.com/collections/books/products/minesweeper-by-kyle-orland">wrote a whole book about <em>Minesweeper</em></a>.</p>
