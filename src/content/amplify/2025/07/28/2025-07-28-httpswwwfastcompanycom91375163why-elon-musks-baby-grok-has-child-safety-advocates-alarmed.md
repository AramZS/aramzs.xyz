---
author: Chris Stokel-Walker
cover_image: >-
  https://images.fastcompany.com/image/upload/f_webp,q_auto,c_fit/wp-cms-2/2025/07/p-1-91375163-why-elon-musks-baby-grok-has-child-safety-advocates-alarmed.jpg
date: '2025-07-28T12:03:40.185Z'
dateFolder: 2025/07/28
description: >-
  Experts voice concern over Musk’s new kid-focused chatbot, pointing to xAI’s
  troubling track record and lack of safeguards for young users.
isBasedOn: >-
  https://www.fastcompany.com/91375163/why-elon-musks-baby-grok-has-child-safety-advocates-alarmed
link: >-
  https://www.fastcompany.com/91375163/why-elon-musks-baby-grok-has-child-safety-advocates-alarmed
slug: >-
  2025-07-28-httpswwwfastcompanycom91375163why-elon-musks-baby-grok-has-child-safety-advocates-alarmed
tags:
  - ai
  - youth
title: Why Elon Musk’s ‘Baby Grok’ has child safety advocates alarmed
---
<figure><img alt="Why Elon Musk’s ‘Baby Grok’ has child safety advocates alarmed" data-nimg="1" src="https://images.fastcompany.com/image/upload/f_webp,c_fit,w_1920,q_auto/wp-cms-2/2025/07/p-1-91375163-why-elon-musks-baby-grok-has-child-safety-advocates-alarmed.jpg"/><figcaption>[Photo: BillionPhotos.com/Adobe Stock]</figcaption></figure>
<p>The <a data-internallinksmanager029f6b8e52c="1" href="https://www.fastcompany.com/section/artificial-intelligence">AI</a> companion space will soon see another new entrant. Elon Musk, the owner of xAI and social media platform X, <a href="https://x.com/elonmusk/status/1946763642231500856">announced recently</a>, “We’re going to make Baby Grok @xAI, an app dedicated to kid-friendly content.”</p>
<p>The decision to enter the AI chatbot and companion market seems logical for X: Around <a href="https://techcrunch.com/2025/07/21/72-of-u-s-teens-have-used-ai-companions-study-finds/">three in every four U.S. teens</a> have already used AI companions, and the platform will naturally want to build brand loyalty early.</p>
<p>However, experts in child protection and social media use are raising concerns. Musk, xAI, and child-focused apps may not be a good combination, they warn. “The concern is that if X or xAI are going to try to get into the children products zone, clearly they just have a terrible track record with prioritizing child safety,” says Haley McNamara, SVP of strategic initiatives and programs at the National Center on Sexual Exploitation (NCOSE). “They’ve just proven themselves to not really care, so I think that they should stay away from kids.”</p>
<p>McNamara is not alone in her concerns. The apprehension is shared internationally. “Elon Musk’s plans to launch a child-focused version of Grok will cause alarm across civil society, with growing evidence about the risks posed by persuasive design choices in AI chatbots, a lack of effective safeguarding in most major industry models, and no clear strategy to prevent hallucinations,” says Andy Burrows, CEO of the Molly Rose Foundation, an organization founded by the parents of U.K. teenager Molly Russell, a 14-year-old who died by suicide after being exposed to harmful content on social media.</p>
<p>Beyond the fact that “Baby Grok” would come from the same organization that developed “Ani,” a sexualized AI chatbot that users have quickly coerced into explicit conversations, and “Bad Rudi,” a red panda chatbot that <a href="https://www.businessinsider.com/grok-bad-rudi-ani-levels-ai-companion-xai-elon-musk-2025-7">defaults to insults</a>, experts see broader dangers. Burrows is particularly worried about introducing AI chatbots to children since they may easily form emotional attachments to such technology.</p>
<p>“Chatbots can simulate deep and emotional relationships with child users, and there are evident risks that children may use chatbots to seek mental health support or advice in ways that may ultimately prove harmful,” Burrows says. Even adults have <a href="https://techcrunch.com/2025/07/24/ai-companions-a-threat-to-love-or-an-evolution-of-it/">formed inappropriate emotional bonds</a> with AI chatbots, struggling to differentiate between artificial and real relationships.</p>
<p>For more impressionable children, these connections could take hold more quickly, with potential long-term effects on their mental health. McNamara says companies have an obligation to consider how their platforms affect kids and to take steps to protect them—something she believes a Grok-bot for children fails to do. (Neither xAI nor Musk responded to <em>Fast Company</em>’s request for comment.)</p>
<p>NCOSE also raises concerns about whether Musk’s platforms can adequately protect young users. McNamara notes that after Musk acquired what was then Twitter, many child safety staff were let go.</p>
<p>“X also allows pornography on its platform, which does not require any kind of stringent age or consent verification for those videos,” she says, contending that such “lax policies have led to a widespread presence of abusive material,” and so far there’s been little sign that the company is taking meaningful action to address these issues.</p>
<p>Burrows, for his part, points to the U.K.’s new Online Safety Act as one layer of oversight that would apply to Baby Grok, though he notes that X has been slow to meet the requirements of the legislation. His larger concern is global. In many countries, he warns, “the lack of regulation will mean the rollout of badly designed products will go effectively unchecked.”</p>
<p>Musk may see a business opportunity. But for those responsible for protecting children online, the stakes are far higher.</p>
