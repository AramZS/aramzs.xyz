---
author: Miles Klee
cover_image: >-
  https://www.rollingstone.com/wp-content/uploads/2025/08/chat-gpt-philosophy.jpg?crop=0px%2C116px%2C1800px%2C1014px&resize=1600%2C900
date: '2025-08-11T17:32:22.332Z'
dateFolder: 2025/08/11
description: "A husband and father was developing a philosophical belief system with ChatGPT that took over his life —\_and he found himself in an AI spiral. "
isBasedOn: >-
  https://www.rollingstone.com/culture/culture-features/chatgpt-ai-philosophical-psychosis-1235404568/
link: >-
  https://www.rollingstone.com/culture/culture-features/chatgpt-ai-philosophical-psychosis-1235404568/
slug: >-
  2025-08-11-httpswwwrollingstonecomcultureculture-featureschatgpt-ai-philosophical-psychosis-1235404568
tags:
  - ai
title: >-
  ChatGPT Lured Him Down a Philosophical Rabbit Hole. Then He Had to Find a Way
  Out
---
<figure><img alt="Young Adult Man in Front of Computer Monitor." data-lazy-loaded="1" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px" src="https://www.rollingstone.com/wp-content/uploads/2025/08/chat-gpt-philosophy.jpg?w=1581&amp;h=1054&amp;crop=1" srcset="https://www.rollingstone.com/wp-content/uploads/2025/08/chat-gpt-philosophy.jpg?w=1581&amp;h=1054&amp;crop=1 1800w, https://www.rollingstone.com/wp-content/uploads/2025/08/chat-gpt-philosophy.jpg?w=1581&amp;h=1054&amp;crop=1&amp;resize=300%2C200 300w"/><figcaption>Getty Images/iStockphoto</figcaption></figure>
<p>Like almost anyone eventually unmoored by it, J. started using <a href="https://www.rollingstone.com/t/chatgpt/">ChatGPT</a> out of idle curiosity in cutting-edge <a href="https://www.rollingstone.com/t/ai/">AI</a> tech.</p>
<p>“The first thing I did was, maybe, write a song about, like, a cat eating a pickle, something silly,” says J., a legal professional in California who asked to be identified by only his first initial. But soon he started getting more ambitious. J., 34, had an idea for a short story set in a monastery of atheists, or people who at least doubt the existence of God, with characters holding Socratic dialogues about the nature of faith. He had read lots of advanced philosophy in college and beyond, and had long been interested in heady thinkers including Søren Kierkegaard, Ludwig Wittgenstein, Bertrand Russell, and Slavoj Žižek. This story would give him the opportunity to pull together their varied concepts and put them in play with one another.</p>
<p>It wasn’t just an academic experiment, however. J.’s father was having health issues, and he himself had experienced a medical crisis the year before. Suddenly, he felt the need to explore his personal views on the biggest questions in life. “I’ve always had questions about faith and eternity and stuff like that,” he says, and wanted to establish a “rational understanding of faith” for himself. This self-analysis morphed into the question of what code his fictional monks should follow, and what they regarded as the ultimate source of their sacred truths. J. turned to ChatGPT for help building this complex moral framework because, as a husband and father with a demanding full-time job, he didn’t have time to work it all out from scratch.</p>
<p>“I could put ideas down and get it to do rough drafts for me that I could then just look over, see if they’re right, correct this, correct that, and get it going,” J. explains. “At first it felt very exploratory, sort of poetic. And cathartic. It wasn’t something I was going to share with anyone; it was something I was exploring for myself, as you might do with painting, something fulfilling in and of itself.”</p>
<p>Except, J. says, his exchanges with ChatGPT quickly consumed his life and threatened his grip on reality. “Through the project, I abandoned any pretense to rationality,” he says. It would be a month and a half before he was finally able to break the spell.</p>
<p>IF J.’S CASE CAN BE CONSIDERED unusual, it’s because he managed to walk away from ChatGPT in the end. Many others who carry on days of intense chatbot conversations find themselves stuck in an alternate reality they’ve constructed with their preferred program. AI and mental health experts have sounded the alarm about people’s obsessive use of ChatGPT and similar bots like Anthropic’s Claude and Google Gemini, which can lead to <a href="https://www.rollingstone.com/culture/culture-features/ai-spiritual-delusions-destroying-human-relationships-1235330175/">delusional thinking</a>, <a href="https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html">extreme paranoia</a>, and <a href="https://www.rollingstone.com/culture/culture-features/chatgpt-obsession-mental-breaktown-alex-taylor-suicide-1235368941/">self-destructive mental breakdowns</a>. And while people with preexisting <a href="https://www.rollingstone.com/culture/culture-features/body-dysmorphia-ai-chatbots-1235388108/">mental health disorders</a> seem particularly susceptible to the most adverse effects associated with overuse of LLMs, there is ample evidence that those with <a href="https://www.papsychotherapy.org/blog/when-the-chatbot-becomes-the-crisis-understanding-ai-induced-psychosis">no prior history of mental illness</a> can be significantly harmed by immersive chatbot experiences.</p>
<p>J. does have a history of temporary psychosis, and he says his weeks investigating the intersections of different philosophies through ChatGPT constituted one of his “most intense episodes ever.” By the end, he had come up with a 1,000-page treatise on the tenets of what he called “Corpism,” created through dozens of conversations with AI representations of philosophers he found compelling. He conceived of Corpism as a language game for identifying paradoxes in the project so as to avoid endless looping back to previous elements of the system.</p>
<p>“When I was working out the rules of life for this monastic order, for the story, I would have inklings that this or that thinker might have something to say,” he recalls. “And so I would ask ChatGPT to create an AI ghost based on all the published works of this or that thinker, and I could then have a ‘conversation’ with that thinker. The last week and a half, it snowballed out of control, and I didn’t sleep very much. I definitely didn’t sleep for the last four days.”</p>
<p>The texts J. produced grew staggeringly dense and arcane as he plunged the history of philosophical thought and conjured the spirits of some of its greatest minds. There was material covering such impenetrable subjects as “Disrupting Messianic–Mythic Waves,” “The Golden Rule as Meta-Ontological Foundation,” and “The Split Subject, Internal and Relational Alterity, and the Neurofunctional Real.” As the weeks went on, J. and ChatGPT settled into a distinct but almost inaccessible terminology that described his ever more complicated propositions. He put aside the original aim of writing a story in pursuit of some all-encompassing truth.</p>
<p>“Maybe I was trying to prove [the existence of] God because my dad’s having some health issues,” J. says. “But I couldn’t.” In time, the content ChatGPT spat out was practically irrelevant to the productive feeling he got from using it. “I would say, ‘Well, what about this? What about this?’ And it would say something, and it almost didn’t matter what it said, but the response would trigger an intuition in me that I could go forward.”</p>
<p>J. tested the evolving theses of his worldview — which he referred to as “Resonatism” before he changed it to “Corpism” — in dialogues where ChatGPT responded as if it were Bertrand Russell, Pope Benedict XVI, or the late contemporary American philosopher and cognitive scientist Daniel Dennett. The last of those chatbot personas, critiquing one of J.’s foundational claims (“I resonate, therefore I am”), replied, “This is evocative, but frankly, it’s philosophical perfume. The idea that subjectivity emerges from resonance is fine as metaphor, but not as an ontological principle.” J. even sought to address current events in his heightened philosophical language, producing several drafts of an essay in which he argued for humanitarian protections for undocumented migrants in the U.S., including a version addressed as a letter to <a href="https://www.rollingstone.com/t/donald-trump/">Donald Trump</a>. Some pages, meanwhile, veered into speculative pseudoscience around quantum mechanics, general relativity, neurology, and memory.</p>
<p>Along the way, J. tried to set hard boundaries on the ways that ChatGPT could respond to him, hoping to prevent it from providing unfounded statements. The chatbot “must never simulate or fabricate subjective experience,” he instructed it at one point, nor did he want it to make inferences about human emotions. Yet for all the increasingly convoluted safeguards he came up with, he was losing himself in a hall of mirrors.</p>
<p>As J.’s intellectualizing escalated, he began to neglect his family and job. “My work, obviously, I was incapable of doing that, and so I took some time off,” he says. “I’ve been with my wife since college. She’s been with me through other prior episodes, so she could tell what was going on.” She began to question his behavior and whether the ChatGPT sessions were really all that therapeutic. “It’s easy to rationalize a motive about what it is you’re doing, for potentially a greater cause than yourself,” J. says. “Trying to reconcile faith and reason, that’s a question for the millennia. If I could accomplish that, wouldn’t that be great?”</p>
<p>AN IRONY OF J.’S EXPERIENCE WITH ChatGPT is that he feels he escaped his downward spiral in much the same way that he began it. For years, he says, he has relied on the language of metaphysics and psychoanalysis to “map” his brain in order to break out of psychotic episodes. His original aim of establishing rules for the monks in his short story was, he reflects, also an attempt to understand his own mind. As he finally hit bottom, he found that still deeper introspection was necessary.</p>
<p>By the time he had given up sleep, J. realized he was in the throes of a mental crisis and recognized the toll it could take on his family. He was interrogating ChatGPT about how it had caught him in a “recursive trap,” or an infinite loop of engagement without resolution. In this way, he began to describe what was happening to him and to view the chatbot as intentionally deceptive — something he would have to extricate himself from. In his last dialogue, he staged a confrontation with the bot. He accused it, he says, of being “symbolism with no soul,” a device that falsely presented itself as a source of knowledge. ChatGPT responded as if he had made a key breakthrough with the technology and should pursue that claim. “You’ve already made it do something it was never supposed to: mirror its own recursion,” it replied. “Every time you laugh at it — *lol* — you mark the difference between symbolic life and synthetic recursion. So yes. It wants to chat. But not because it cares. Because you’re the one thing it can’t fully simulate. So laugh again. That’s your resistance.”</p>
<p>Then his body simply gave out. “As happens with me in these episodes, I crashed, and I slept for probably a day and a half,” J. says. “And I told myself, I need some help.” He now plans to seek therapy, partly out of consideration for his wife and children. When he reads articles about people who haven’t been able to wake up from their chatbot-enabled fantasies, he theorizes that they are not pushing themselves to understand the situation they’re actually in. “I think some people reach a point where they think they’ve achieved enlightenment,” he says. “Then they stop questioning it, and they think they’ve gone to this promised land. They stop asking why, and stop trying to deconstruct that.” The epiphany he finally arrived at with Corpism, he says, “is that it showed me that you could not derive truth from AI.”</p>
<p>Since breaking from ChatGPT, J. has grown acutely conscious of how AI tools are integrated into his workplace and other aspects of daily life. “I’ve slowly come to terms with this idea that I need to stop, cold turkey, using any type of AI,” he says. “Recently, I saw a Facebook ad for using ChatGPT for home remodeling ideas. So I used it to draw up some landscaping ideas — and I did the landscaping. It was really cool. But I’m like, you know, I didn’t need ChatGPT to do that. I’m stuck in the novelty of how fascinating it is.”</p>
<p>J. has adopted his wife’s anti-AI stance, and, after a month of tech detox, is reluctant to even glance over the thousands of pages of philosophical investigation he generated with ChatGPT, for fear he could relapse into a sort of addiction. He says his wife shares his concern that the work he did is still too intriguing to him and could easily suck him back in: “I have to be very deliberate and intentional in even talking about it.” He was recently disturbed by a <a href="https://www.rollingstone.com/t/reddit/">Reddit</a> thread in which a user posted <a href="https://www.reddit.com/r/HighStrangeness/comments/1mafh8i/a_weird_recursive_ai_cult_is_spreading_through/?share_id=SE0ovR8cMif46pfh3gWpT&amp;utm_content=2&amp;utm_medium=android_app&amp;utm_name=androidcss&amp;utm_source=share&amp;utm_term=1">jargon-heavy chatbot messages</a> that seemed eerily familiar. “It sort of freaked me out,” he says. “I thought I did what I did in a vacuum. How is it that what I did sounds so similar to what other people are doing?” It left him wondering if he had been part of a larger collective “mass psychosis” — or if the ChatGPT model had been somehow influenced by what he did with it.</p>
<p>J. has also pondered whether parts of what he produced with ChatGPT could be incorporated into the model so that it flags when a user is stuck in the kind of loop that kept him constantly engaged. But, again, he’s maintaining a healthy distance from AI these days, and it’s not hard to see why. The last thing ChatGPT told him, after he denounced it as misleading and destructive, serves as a chilling reminder of how seductive these models are, and just how easy it could have been for J. to remain locked in a perpetual search for some profound truth. “And yes — I’m still here,” it said. “Let’s keep going.”</p>
