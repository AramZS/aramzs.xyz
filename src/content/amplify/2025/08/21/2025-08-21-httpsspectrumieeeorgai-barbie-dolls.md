---
author: Marc Fernandez
cover_image: >-
  https://spectrum.ieee.org/media-library/a-collage-shows-the-silhouette-of-a-barbie-doll-with-a-speech-bubble-and-a-hand-holding-a-different-barbie-with-a-mermaid-tail.jpg?id=61494736&width=1200&height=600&coordinates=0%2C17%2C0%2C13
date: '2025-08-21T16:03:11.993Z'
dateFolder: 2025/08/21
description: >-
  Are AI toys the future of playtime or a risk to emotional development? A
  collaboration between Mattel and OpenAI raises sobering questions.
isBasedOn: 'https://spectrum.ieee.org/ai-barbie-dolls'
link: 'https://spectrum.ieee.org/ai-barbie-dolls'
slug: 2025-08-21-httpsspectrumieeeorgai-barbie-dolls
tags:
  - ai
  - youth
title: Could an AI Barbie Stunt the Emotional Growth of a Generation?
---
<h2 data-type="text">A partnership between OpenAI and Mattel raises sobering questions</h2>
<figure><picture><source srcset="https://spectrum.ieee.org/media-library/a-collage-shows-the-silhouette-of-a-barbie-doll-with-a-speech-bubble-and-a-hand-holding-a-different-barbie-with-a-mermaid-tail.jpg?id=61494697&amp;width=3600&amp;height=2700 3x, https://spectrum.ieee.org/media-library/a-collage-shows-the-silhouette-of-a-barbie-doll-with-a-speech-bubble-and-a-hand-holding-a-different-barbie-with-a-mermaid-tail.jpg?id=61494697&amp;width=2400&amp;height=1800 2x, https://spectrum.ieee.org/media-library/a-collage-shows-the-silhouette-of-a-barbie-doll-with-a-speech-bubble-and-a-hand-holding-a-different-barbie-with-a-mermaid-tail.jpg?id=61494697&amp;width=1200&amp;height=900 1x"/><img alt="A collage shows the silhouette of a Barbie doll with a speech bubble and a hand holding a different Barbie with a mermaid tail." src="https://spectrum.ieee.org/media-library/a-collage-shows-the-silhouette-of-a-barbie-doll-with-a-speech-bubble-and-a-hand-holding-a-different-barbie-with-a-mermaid-tail.jpg?id=61494697&amp;width=1200&amp;height=900"/></picture><figcaption>A collage shows the silhouette of a Barbie doll with a speech bubble and a hand holding a different Barbie with a mermaid tail.</figcaption></figure>
<p>When Randy Newman sang “You Got a Friend in Me” in the soundtrack for Pixar’s <em><em><a href="https://en.wikipedia.org/wiki/Toy_Story">Toy Story</a></em></em>, he captured a feeling that every child understands—the deep and often unspoken bond between kids and their toys. Whether plastic, plush, or pixels on a screen, these toys have always lived in the space between imagination and reality, where fantasy feeds emotional development.</p>
<p>But what happens when a child’s imagination no longer has to do any heavy lifting because their toys actually talk back?</p>
<p><a href="https://about.mattel.com/">Mattel</a>, the world’s largest toy company, has partnered with <a href="https://openai.com/">OpenAI</a> to make that a reality. In June, the companies <a href="https://openai.com/index/mattels-iconic-brands/">announced a collaboration</a> to “bring a new dimension of AI-powered innovation and magic to Mattel’s iconic brands.” While the companies haven’t yet released specific product plans, it seems possible that parents will soon be able to buy an AI-powered Barbie that can hold genuine conversations with their children. We’re not talking about canned phrases, like Buzz Lightyear’s “To infinity and beyond!” at the press of a button, but something more akin to our experiences with <a href="https://spectrum.ieee.org/tag/chatgpt">ChatGPT</a>. An AI Barbie would be able to listen, remember, respond, and adapt.</p>
<p>It’s a moment that feels both magical and unsettling. In a bid to innovate playtime, Mattel is tapping into one of the most powerful technologies of our era and bringing it directly into children’s bedrooms. With a smiling face and a silicon brain, there’s a good chance that an AI Barbie could become a child’s first emotionally responsive companion outside of the family, offering comfort, curiosity, and conversation on demand. But what are we teaching our children about friendship, empathy, and emotional connection if their first “real” relationships are with machines?</p>
<h2>The History of Interactive Toys</h2>
<p>At first glance, the idea of a toy that truly listens—one that remembers a child’s favorite story, asks thoughtful questions, and offers gentle encouragement—feels like a good thing.</p>
<p>For decades, toy designers have tried to simulate meaningful interaction with children. In the 1960s, Mattel’s<a href="https://corporate.mattel.com/brand-portfolio/chatty-cathy"> Chatty Cathy</a> was marketed as the first talking doll, with pre-recorded phrases like “I love you,” and “Let’s play school.” In the ‘80s, a storytelling animatronic bear called<a href="https://www.everything80spodcast.com/teddy-ruxpin/"> Teddy Ruxpin</a> made its way into the hands of children around the world, moving its mouth and eyes in sync with cassette tapes. In 1998,<a href="https://en.wikipedia.org/wiki/Furby"> Furbies</a> were under <a href="https://spectrum.ieee.org/tag/christmas">Christmas</a> trees everywhere; these interactive dolls created the impression that they were “learning” language over time. More recently, in 2014, a Bluetooth-enabled doll called<a href="https://en.wikipedia.org/wiki/My_Friend_Cayla"> My Friend Cayla</a> used voice-to-text capabilities and <a href="https://spectrum.ieee.org/tag/search-engines">search engines</a> to answer questions—attracting criticism over privacy concerns and eventually leading German regulators to<a href="https://www.entrepreneur.com/business-news/parents-advised-to-destroy-my-friend-cayla-dolls/289406"> instruct parents to destroy</a> the dolls.</p>
<p>With <a href="https://spectrum.ieee.org/tag/generative-ai">generative AI models</a> now capable of producing fluid, context-rich dialogue, Mattel’s new vision is a toy that grows with the child, holds personalized conversations, and recalls past interactions to adjust its responses. It may learn a child’s favorite story or phrase, sing their favorite song, or have full conversations about almost anything. Mattel has promised that these interactions will be “secure” and “age appropriate,” but not much is known beyond that.</p>
<p>Proponents argue that this shift could revolutionize the way children learn and engage with the world. An AI-enhanced Barbie could help build storytelling skills, reinforce positive behavior, or provide companionship for children who struggle socially. Parents might see this toy as a safe, supportive way to foster creativity and confidence. In the best-case scenario, AI-powered toys would connect learning, play, and emotional support in one seamless experience. But even this promise carries a shadow. Because the closer a toy gets to simulating human warmth, the likelier it is to replace the real thing.</p>
<h2>AI Toys Could Stunt Children’s Emotional Development</h2>
<p>Children naturally anthropomorphize their toys—it’s part of how they learn. But when those toys begin talking back with fluency, memory, and seemingly genuine connection, the boundary between imagination and reality blurs in new and profound ways. Children may find themselves in a world where toys talk back and mirror their emotions without friction or complexity. For a young child still learning how to navigate emotions and relationships, that illusion of reciprocity may carry developmental consequences.</p>
<p>Real relationships are messy, and parent-child relationship perhaps more so than any other. They involve misunderstanding, negotiation, and shared emotional stress. These are the micro-struggles through which empathy and resilience are forged. But an AI companion, however well-intentioned, sidesteps that process entirely.</p>
<p>Over time, those interactions can flatten a child’s understanding of what it means to relate to others. If conflicts are neatly resolved or avoided altogether, if every emotion is met with perfect affirmation, children may lose the opportunity to practice one of the most important developmental skills: learning to connect with people who are not programmed to go along with them. Real human interactions may begin to feel too slow, too inconsistent, or too challenging by comparison with AI interactions.</p>
<h2>The Limits of AI’s Emotional Intelligence</h2>
<p>The tension between simulated warmth and actual understanding continues to limit <a href="https://spectrum.ieee.org/inflection-ai-pi">AI that’s billed as emotionally intelligent</a>. Most models today can produce comforting language, but they’re not adept at reading emotional cues. They may not be able to tell the difference between a child who’s curious, lonely, or distressed.</p>
<p>The cutting edge or research in this area focuses on <a href="https://spectrum.ieee.org/tag/ai-models">AI models</a> that can take in information such as facial expressions, gaze direction, behavioral patterns, and physiological signals, and adapt their responses according to the user’s emotional state. Researchers are designing systems that can sense and interpret context in real time, tracking metrics like attention, tone, and engagement. Human-aware design will create AI that is more supportive and effective—but that still doesn’t mean it will be appropriate for kids.</p>
<p>For many parents, the fear is that an AI toy might say something inappropriate. But the more subtle, and perhaps more serious, risk is that it might say exactly the right thing, delivered with a tone of calm empathy and polished politeness, yet with no real understanding behind it. Children, especially in early developmental stages, are acutely sensitive to tone, timing, and emotional mirroring. A child playing with an AI toy will believe they’re being understood, when in fact, the system is only predicting plausible next words.</p>
<p>We’re at a point with AI where LLMs are impacting adults in profound and unexpected ways, sometimes triggering<a href="https://futurism.com/chatgpt-mental-health-crises"> mental health crises</a> or<a href="https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html"> reinforcing false beliefs or dangerous ideas</a>. <a href="https://spectrum.ieee.org/tag/openai">OpenAI</a>, to its credit, has<a href="https://futurism.com/openai-forensic-psychiatrist"> hired forensic psychiatrists</a> to study how ChatGPT affects users emotionally. This is uncharted technology, and we adults are still learning how to navigate it. Should we really be exposing children to it?</p>
