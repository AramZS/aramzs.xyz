---
author: Charlie Warzel
cover_image: >-
  https://cdn.theatlantic.com/thumbor/oH6xW_pOm6a1yRbKZRIi3sai2Cc=/0x0:3200x4000/648x810/media/img/2025/08/18/TheAtlantic_AIPsychosis_f001/original.jpg
date: '2025-08-19T01:13:34.493Z'
dateFolder: 2025/08/18
description: >-
  A strange brew of shock, confusion, and ambivalence is the defining emotion of
  the generative-AI era, Charlie Warzel writes.
isBasedOn: >-
  https://www.theatlantic.com/technology/archive/2025/08/ai-mass-delusion-event/683909/?gift=bQgJMMVzeo8RHHcE1_KM0Yxw_pOVM_AK6Q1K5aHOCSs
link: >-
  https://www.theatlantic.com/technology/archive/2025/08/ai-mass-delusion-event/683909/?gift=bQgJMMVzeo8RHHcE1_KM0Yxw_pOVM_AK6Q1K5aHOCSs
slug: >-
  2025-08-18-httpswwwtheatlanticcomtechnologyarchive202508ai-mass-delusion-event683909giftbqgjmmvzeo8rhhce1km0yxwpovmak6q1k5ahocss
tags:
  - ai
title: AI Is a Mass-Delusion Event
---
<html><body><div>Three years in, one of AI’s enduring impacts is to make people feel like they’re losing it.</div><figure><img alt="abstract painting of figure typing at keyboard" src="https://cdn.theatlantic.com/thumbor/oH6xW_pOm6a1yRbKZRIi3sai2Cc=/0x0:3200x4000/648x810/media/img/2025/08/18/TheAtlantic_AIPsychosis_f001/original.jpg"/><figcaption> (Illustration by Niv Bavarsky for The Atlantic)</figcaption></figure><p>I<span class="smallcaps">t is a Monday afternoon in August,</span> and I am on the internet <a data-event-element="inline link" href="http://open.substack.com/pub/jimacosta/p/father-creates-ai-to-honor-son-lost?utm_source=post-email-title&amp;publication_id=3775894&amp;post_id=170112498&amp;utm_campaign=email-post-title&amp;isFreemail=true&amp;r=2f1r&amp;token=eyJ1c2VyX2lkIjoxMTI4MTUsInBvc3RfaWQiOjE3MDExMjQ5OCwiaWF0IjoxNzU0MzQxMDI2LCJleHAiOjE3NTY5MzMwMjYsImlzcyI6InB1Yi0zNzc1ODk0Iiwic3ViIjoicG9zdC1yZWFjdGlvbiJ9.mCjxSNYITaXhTmDJlJuWNtVkmxtfxbRBjUuri4GEgrU">watching</a> a former cable-news anchor interview a dead teenager on Substack. This dead teenager—Joaquin Oliver, killed in the mass shooting at Marjory Stoneman Douglas High School, in Parkland, Florida—has been reanimated by generative AI, his voice and dialogue modeled on snippets of his writing and home-video footage. The animations are stiff, the model’s speaking cadence is too fast, and in two instances, when it is trying to convey excitement, its pitch rises rapidly, producing a digital shriek. <em>How many people</em>, I wonder, <em>had to agree that this was a good idea to get us to this moment?</em> I feel like I’m losing my mind watching it.</p><p></p><p>Jim Acosta, the former CNN personality who’s conducting the interview, appears fully bought-in to the premise, adding to the surreality: He’s playing it straight, even though the interactions are so bizarre. Acosta asks simple questions about Oliver’s interests and how the teenager died. The chatbot, which was built with the full cooperation of Oliver’s parents to advocate for gun control, responds like a press release: “We need to create safe spaces for conversations and connections, making sure everyone feels seen.” It offers bromides such as “More kindness and understanding can truly make a difference.”</p><p></p><p>On the live chat, I watch viewers struggle to process what they are witnessing, much in the same way I am. “Not sure how I feel about this,” one writes. “Oh gosh, this feels so strange,” another says. Still another thinks of the family, writing, “This must be so hard.” Someone says what I imagine we are all thinking: “He should be here.”</p><p><a href="https://www.theatlantic.com/technology/archive/2024/07/openai-audacity-crisis/679212/">Read: AI’s real hallucination problem</a></p><p>The Acosta interview was difficult to process in the precise way that many things in this AI moment are difficult to process. I was grossed out by Acosta for “turning a murdered child into content,” <a data-event-element="inline link" href="http://open.substack.com/pub/readtpa/p/oh-no-what-is-jim-acosta-doing?utm_source=post-email-title&amp;publication_id=2282&amp;post_id=170182681&amp;utm_campaign=email-post-title&amp;isFreemail=false&amp;r=2f1r&amp;token=eyJ1c2VyX2lkIjoxMTI4MTUsInBvc3RfaWQiOjE3MDE4MjY4MSwiaWF0IjoxNzU0NDEzNjQ3LCJleHAiOjE3NTcwMDU2NDcsImlzcyI6InB1Yi0yMjgyIiwic3ViIjoicG9zdC1yZWFjdGlvbiJ9.z9rnsc17agxzhAt4ESxlFmy3HBZ4e2cUH1KKvBCVB3o">as the critic Parker Molloy put it</a>, and angry with the tech companies that now offer a monkey’s paw in the form of products that can reanimate the dead. I was alarmed when Oliver’s father told Acosta during their follow-up conversation that Oliver “is going to start having followers,” suggesting an era of murdered children as influencers. At the same time, I understood the compulsion of Oliver’s parents, still processing their profound grief, to do anything in their power to preserve their son’s memory and to make meaning out of senseless violence. How could I possibly judge the loss that leads Oliver’s mother to talk to the chatbot for hours on end, as his father described to Acosta—what could I do with the knowledge that she loves hearing the chatbot say “I love you, Mommy” in her dead son’s voice?</p><p></p><p>The interview triggered a feeling that has become exceedingly familiar over the past three years. It is the sinking feeling of a societal race toward a future that feels bloodless, hastily conceived, and shruggingly accepted. <em>Are we really doing this? Who thought this was a good idea?</em> In this sense, the Acosta interview is just a product of what feels like a collective delusion. This strange brew of shock, confusion, and ambivalence, I’ve realized, is the defining emotion of the generative-AI era. Three years into the hype, it seems that one of AI’s enduring cultural impacts is to make people feel like they’re losing it.</p><p>D<span class="smallcaps">uring his interview with Acosta,</span> Oliver’s father noted that the family has plans to continue developing the bot. “Any other Silicon Valley tech guy will say, ‘This is just the beginning of AI,’” he said. “‘This is just the beginning of what we’re doing.’”</p><p></p><p>Just the beginning. Perhaps you’ve heard that too. “<a data-event-element="inline link" href="https://qz.com/chatgpt-open-ai-sam-altman-genz-users-students-1851780458">Welcome to the ChatGPT generation</a>.” “<a data-event-element="inline link" href="https://hdsr.mitpress.mit.edu/pub/fblrvqes/release/1">The Generative AI Revolution</a>.” “<a data-event-element="inline link" href="https://www.meta.com/superintelligence/?srsltid=AfmBOordqJ_XLN0trQ2bUWOa56huDtxUjTo3agZX5BTjUE1gQ-i1BDTN">A new era for humanity</a>,” as Mark Zuckerberg recently put it. It’s the moment before the computational big bang—everything is about to change, we’re told; you’ll see. God may very well be in the machine. Silicon Valley has invented a new type of mind. This is a moment to rejoice—to double down. You’re a fool if you’re not using it at work. It is time to accelerate.</p><p></p><p>How lucky we are to be alive right now! Yes, things are weird. But what do you expect? You are swimming in the primordial soup of machine cognition. There are bound to be growing pains and collateral damage. To live in such interesting times means contending with <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2025/07/grok-anti-semitic-tweets/683463/">MechaHitler Grok</a> and drinking from a fire hose of <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2024/08/trump-posts-ai-image/679540/">fascist-propaganda slop</a>. It means Grandpa leaving confused Facebook comments under rendered images of Shrimp Jesus or, worse, <a data-event-element="inline link" href="https://www.reuters.com/podcasts/metas-flirty-chatbot-man-who-never-made-it-home-2025-08-18/">falling</a> for a flirty AI chatbot. This future likely requires a new social contract. But also: <a data-event-element="inline link" href="https://www.nytimes.com/2024/04/22/technology/deepfake-ai-nudes-high-school-laws.html">AI revenge porn</a> and <a data-event-element="inline link" href="https://www.404media.co/deepfake-harassment-ohio-undress-clothoff-nudify-apps/">“nudify” apps</a> that use AI to undress women and children, and <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2025/03/libgen-meta-openai/682093/">large language models that have devoured the total creative output of humankind</a>. From this morass, we are told, an “artificial general intelligence” will eventually emerge, turbo-charging the human race or, well, maybe destroying it. But look: Every boob with a T-Mobile plan will soon have more raw intelligence in their pocket than has ever existed in the world. <em>Keep the faith.</em></p><p></p><p>Breathlessness is the modus operandi of those who are building out this technology. The venture capitalist Marc Andreessen is quote-tweeting guys on X bleating out <a data-event-element="inline link" href="https://x.com/pmarca/status/1956065775275663631">statements</a> such as “Everyone I know believes we have a few years max until the value of labor totally collapses and capital accretes to owners on a runaway loop—basically marx’ worst nightmare/fantasy.” How couldn’t you go a bit mad if you took them seriously? Indeed, it seems that one of the many offerings of generative AI is a kind of psychosis-as-a-service. If you are genuinely AGI-pilled—a term for those who believe that machine-born superintelligence is coming, and soon—the rational response probably involves some combination of building a bunker, quitting your job, and joining the cause. As my colleague Matteo Wong <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2025/05/silicon-valley-reacts-to-trump/682799/">wrote</a> after spending time with people in this cohort earlier this year, politics, the economy, and current events are essentially irrelevant to the true believers. It’s hard to care about tariffs or authoritarian encroachment or getting a degree if you believe that the world as we know it is about to change forever.</p><p></p><p>There are maddening effects downstream of this rhetoric. People have been involuntarily <a data-event-element="inline link" href="https://futurism.com/commitment-jail-chatgpt-psychosis">committed</a> or had <a data-event-element="inline link" href="https://gizmodo.com/this-was-trauma-by-simulation-chatgpt-users-file-disturbing-mental-health-complaints-2000636943">delusional</a> breakdowns after developing relationships with chatbots. These <a data-event-element="inline link" href="https://www.rollingstone.com/culture/culture-features/chatgpt-ai-philosophical-psychosis-1235404568/">stories</a> have become a cottage industry in themselves, each one <a data-event-element="inline link" href="https://www.nytimes.com/2025/08/08/technology/ai-chatbots-delusions-chatgpt.html">suggesting</a> that a mix of obsequious models, their presentation of false information as true, and the tools’ ability to mimic human conversation pushes vulnerable users to think they’ve developed a human relationship with a machine. Subreddits such as <a data-event-element="inline link" href="https://www.reddit.com/r/MyBoyfriendIsAI/">r/MyBoyfriendIsAI</a>, in which people describe their relationships with chatbots, may not be representative of most users, but it’s hard to browse through the testimonials and not feel that, just a few years into the generative-AI era, these tools have a powerful hold on people who may not understand what it is they’re engaging with.</p><p></p><p>As all of this happens, young people are experiencing a phenomenon that the writer Kyla Scanlon calls the “<a data-event-element="inline link" href="https://kyla.substack.com/p/gen-z-and-the-end-of-predictable">End of Predictable Progress</a>.” Broadly, the theory argues that the usual pathways to a stable economic existence are no longer reliable. “You’re thinking: <em>These jobs that I rely on to get on the bottom rung of my career ladder are going to be taken away from me</em>” by AI, <a data-event-element="inline link" href="https://www.nytimes.com/2025/07/08/opinion/ezra-klein-podcast-kyla-scanlon.html">she recently told the journalist Ezra Klein</a>. “I think that creates an element of fear.” The feeling of instability she describes is a hallmark of the generative-AI era. It’s not at all clear yet how many entry-level jobs will be claimed by AI, but the messaging from enthusiastic CEOs and corporations certainly sounds dire. In May, Dario Amodei, the CEO of Anthropic, <a data-event-element="inline link" href="https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic">warned</a> that AI could wipe out half of all entry-level white-collar jobs. In June, Salesforce CEO Marc Benioff <a data-event-element="inline link" href="https://www.cnbc.com/2025/06/26/ai-salesforce-benioff.html">suggested</a> that up to 50 percent of the company’s work was being done by AI.</p><p></p><p>The anxiety around job loss illustrates the fuzziness of this moment. Right now, there are competing theories as to whether AI is having a meaningful effect on employment. But real and perceived impact are different things. A recent <a data-event-element="inline link" href="https://poll.qu.edu/poll-release?releaseid=3923">Quinnipiac poll</a> found that, “when it comes to their day-to-day life,” 44 percent of surveyed Americans believe that AI will do more harm than good. The survey found that Americans believe the technology will cause job loss—but many workers appeared confident in the security of their own job. Many people simply don’t know what conclusions to draw about AI, but it is impossible not to be thinking about it.</p><p>O<span class="smallcaps">penAI CEO Sam Altman</span> has demonstrated his own uncertainty. In a blog post titled <a data-event-element="inline link" href="https://blog.samaltman.com/the-gentle-singularity">“The Gentle Singularity”</a> published in June, Altman argued that “we are past the event horizon” and are close to building digital superintelligence, and that “in some big sense, ChatGPT is already more powerful than any human who has ever lived.” He delivered the classic rhetorical flourishes of AI boosters, arguing that “the 2030s are likely going to be wildly different from any time that has come before.” And yet, this post also retreats ever so slightly from the dramatic rhetoric of inevitable <a data-event-element="inline link" href="https://moores.samaltman.com/">“revolution”</a> that he has previously employed. “In the most important ways, the 2030s may not be wildly different,” he wrote. “People will still love their families, express their creativity, play games, and swim in lakes”—a cheeky nod to the endurance of our corporeal form, as a little treat. Altman is a skilled marketer, and the post might simply be a way to signal a friendlier, more palatable future for those who are a little freaked out.</p><p></p><p>But a different way to read the post is to see Altman hedging slightly in the face of potential progress limitations on the technology. Earlier this month, OpenAI released GPT-5, to mixed reviews. Altman had promised “a Ph.D.-level” intelligence on any topic. But early tests of GPT-5 <a data-event-element="inline link" href="https://garymarcus.substack.com/p/gpt-5-overdue-overhyped-and-underwhelming?publication_id=888615&amp;post_id=170534403&amp;isFreemail=true&amp;r=n1p8t&amp;triedRedirect=true">revealed</a> all kinds of <a data-event-element="inline link" href="https://www.bloodinthemachine.com/p/gpt-5-is-a-joke-will-it-matter">anecdotal</a> examples of <a data-event-element="inline link" href="https://www.realtimetechpocalypse.com/p/gpt-5-is-by-far-the-best-ai-system">sloppy</a> answers to queries, including hallucinations, simple-arithmetic errors, and failures in basic reasoning. Some power users who’d become infatuated with previous versions of the software were angry and even bereft by the update. Altman placed particular emphasis on <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2025/08/gpt-5-launch/683791/">the product’s usability and design</a>: Paired with the “Gentle Singularity,” GPT-5 seems like an admission that superintelligence is still just a concept.</p><p><a href="https://www.theatlantic.com/technology/archive/2025/08/gpt-5-launch/683791/">Read: The new ChatGPT resets the AI race</a></p><p>And yet, the philosopher role-play continues. Not long before the launch, Altman appeared on the comedian Theo Von’s popular podcast. The discussion veered into the thoughtful science-fiction territory that Altman tends to inhabit. At one point, the two had <a data-event-element="inline link" href="https://fight.fudgie.org/search/show/tpw/episode/20250723_Wed#line3691">the following exchange</a>:</p><p></p><blockquote><p><strong>Sam Altman: </strong>I do guess that a lot of the world gets covered in data centers over time.</p> <p></p> <p><strong>Theo Von:</strong> Do you really?</p> <p></p> <p><strong>Altman:</strong> But I don’t know, because maybe we put them in space. Like, maybe we build a big Dyson sphere around the solar system and say, “Hey, it actually makes no sense to put these on Earth.”</p> <p></p> <p><strong>Von: </strong>Yeah.</p> <p></p> <p><strong>Altman:</strong> I wish I had, like, more concrete answers for you, but, like, we’re stumbling through this.</p></blockquote><p></p><p>What exactly is a person, listening in their car on the way to the grocery store, to make of conversations like this? Surely, there’s a cohort that finds covering the Earth or atmosphere with data centers very exciting. But what about those of us who don’t? Altman and lesser personalities in the AI space often talk this way, making extreme, matter-of-fact proclamations about the future and sounding like kids playing a strategy game. This isn’t a business plan; it’s an idle daydream.</p><p></p><p>Similarly disorienting is the fact that these visions and pontifications are driving change in the real world. Even if you personally don’t believe in the hype, you are living in an economy that has reoriented itself around AI. A recent <a data-event-element="inline link" href="https://www.wsj.com/tech/ai/silicon-valley-ai-infrastructure-capex-cffe0431?mod=author_content_page_1_pos_1">report</a> from <em>The</em> <em>Wall Street Journal</em> estimates that Big Tech’s spending on IT infrastructure in 2025 is “acting as a sort of private-sector stimulus program,” with the “Magnificent Seven” tech companies—Meta, Alphabet, Microsoft, Amazon, Apple, Nvidia, and Tesla—spending more than $100 billion on capital expenditures in the recent months. The flip side of such consolidated investment in one tech sector is a giant economic vulnerability that could lead to a <a data-event-element="inline link" href="https://www.noahpinion.blog/p/will-data-centers-crash-the-economy">financial crisis</a>.</p><p></p><p>This is the AI era in a nutshell. Squint one way, and you can portray it as the saving grace of the world economy. Look at it more closely, and it’s a ticking time bomb lodged in the global financial system. The conversation is always polarized. <em>Keep the faith.</em></p><p>I<span class="smallcaps">t’s difficult to deny</span> that generative-AI tools are transformative, insomuch as their adoption has radically altered the economy and the digital world. Social networks and the internet at large have been flooded with AI slop and synthetic text. Spotify and YouTube are filling up with <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2025/07/velvet-sundown-ai-band-spotify/683410/">AI-generated songs</a> and videos, some of which get millions of streams.</p><p></p><p>Bots are everywhere, and they have produced profoundly strange and meaningful effects on digital life. <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2025/07/new-grok-racism-elon-musk/683515/">Sometimes they’re racist</a>. <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2025/05/sycophantic-ai/682743/">Many are sycophants</a>. Other times, they <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2025/07/chatgpt-ai-self-mutilation-satanism/683649/">summon demons</a>. Google’s AI summaries are <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2025/06/generative-ai-pirated-articles-books/683009/">cratering traffic and rewiring the web</a>. In <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2025/08/ai-takeover-education-chatgpt/683840/">schools</a>, ChatGPT hasn’t just <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2022/12/chatgpt-ai-writing-college-student-essays/672371/">killed</a> the student essay; it seems to be threatening some of the basic building blocks of human <a data-event-element="inline link" href="https://www.forkingpaths.co/p/the-death-of-the-student-essayand">cognition</a>. Some research has argued that chatbots are <a data-event-element="inline link" href="https://www.theverge.com/openai/686748/chatgpt-linguistic-impact-common-word-usage">homogenizing</a> the way people speak. In any case, they appear to have <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2023/05/microsoft-bing-chatbot-search-information-consolidation/673958/">inverted the promise</a> of the internet as an endless archive of information one can navigate for themselves. <em>Do your own research</em> has, in short order, become <em>Get one canonical answer</em>.</p><p></p><p>Sometimes this is helpful: A bot artfully summarizes a complex PDF. They are, by most accounts, truly helpful coding tools. Kids use them to <a data-event-element="inline link" href="https://www.wired.com/story/what-kids-think-about-ai-schools/">build</a> helpful study guides. They’re good at saving you time by churning out anemic emails. Also, a <a data-event-element="inline link" href="https://www.theverge.com/health/718049/google-med-gemini-basilar-ganglia-paper-typo-hallucination">health-care chatbot</a> made up fake body parts. The FDA has introduced a generative-AI tool to help fast-track drug and medical-device <a data-event-element="inline link" href="https://www.cnn.com/2025/07/23/politics/fda-ai-elsa-drug-regulation-makary">approvals</a>—but the tool keeps making up fake studies. To scan the AI headlines is a daily exercise in trying to determine the cost that society is paying for these perceived productivity benefits. For example, with a new Google Gemini–enabled smartwatch, you can <a data-event-element="inline link" href="https://www.theverge.com/analysis/718390/gemini-wear-os-smartwatches-ai">ask the bot</a> to “tell my spouse I’m 15 minutes late and send it in a jokey tone” instead of communicating yourself. This is followed by news of a study suggesting that ChatGPT power users might be <a data-event-element="inline link" href="https://www.media.mit.edu/publications/your-brain-on-chatgpt/">accumulating</a> a “cognitive debt” from using the tool.</p><p></p><p>In recent months, I’ve felt unmoored by all of this: by a technology that I find useful in certain contexts being treated as a portal to sentience; by a <a data-event-element="inline link" href="https://gizmodo.com/billionaires-convince-themselves-ai-is-close-to-making-new-scientific-discoveries-2000629060">billionaire confidently declaring</a> that he is close to making breakthroughs in physics by conversing with a chatbot; by a “get that bag” culture that seems to have accepted these tools without much consideration as to the repercussions; by <em>the discourse</em>. I hear the chatter everywhere—a guy selling produce at the farmers’ market makes a half-hearted joke that AI can’t grow blueberries; a woman at the airport tells her friend that she asked ChatGPT for makeup recommendations. Most of these conversations are poorly informed, conducted by people who have been bombarded for years now by hype but who have also watched as some of these tools have become ingrained in their life or in the life of people they know. They’re not quite excited or jaded, but almost all of them seem resigned to dealing with the tools as part of their future. Remember—this is just the beginning … right?</p><p></p><p>This is the language that the technology’s builders and backers have given us, which means that discussions that situate the technology in the future are being had on their terms. This is a mistake, and it is perhaps the reason so many people feel adrift. Lately, I’ve been preoccupied with a different question: What if generative AI isn’t God in the machine <em>or</em> vaporware? What if it’s just good enough, useful to many without being revolutionary? Right now, the models don’t think—they predict and arrange tokens of language to provide plausible responses to queries. There is little compelling evidence that they will evolve without some kind of quantum research leap. What if they never stop hallucinating and never develop the kind of creative ingenuity that powers actual human intelligence?</p><p></p><p>The models being good enough doesn’t mean that the industry collapses overnight or that the technology is useless (though it could). The technology may still do an excellent job of making our educational system irrelevant, leaving a generation reliant on getting answers from a chatbot instead of thinking for themselves, without the promised advantage of a sentient bot that invents cancer cures.</p><p><a href="https://www.theatlantic.com/technology/archive/2025/04/how-ai-will-actually-contribute-cancer-cure/682607/">Read: AI executives promise cancer cures. Here’s the reality</a></p><p><em>Good enough</em> has been keeping me up at night. Because good enough would likely mean that not enough people recognize what’s really being built—and what’s being sacrificed—until it’s too late. What if the real doomer scenario is that we pollute the internet and the planet, reorient our economy and leverage ourselves, outsource big chunks of our minds, realign our geopolitics and culture, and fight endlessly over a technology that never comes close to delivering on its grandest promises? What if we spend so much time waiting and arguing that we fail to marshal our energy toward addressing the problems that exist here and now? That would be a tragedy—the product of a mass delusion. What scares me the most about this scenario is that it’s the only one that doesn’t sound all that insane.</p></body></html>
