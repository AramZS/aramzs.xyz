---
author: Ananya
cover_image: >-
  https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?resize=1200,600
date: '2025-09-23T13:05:28.911Z'
dateFolder: 2025/09/23
description: Some companies are working to remedy the issue.
isBasedOn: >-
  https://www.technologyreview.com/2025/09/23/1123897/ai-models-are-using-material-from-retracted-scientific-papers/
link: >-
  https://www.technologyreview.com/2025/09/23/1123897/ai-models-are-using-material-from-retracted-scientific-papers/
slug: >-
  2025-09-23-httpswwwtechnologyreviewcom202509231123897ai-models-are-using-material-from-retracted-scientific-papers
tags:
  - ai
  - science
title: AI models are using material from retracted scientific papers
---
<p>Some companies are working to remedy the issue.</p>
<figure><img alt='""' data-smartcrop-focus="50,50" data-wpsmartcrop-natural-dims="807,454" sizes="(max-width: 32rem) 360px,(max-width: 48rem) 728px,(max-width: 64rem) 808px,(max-width: 80rem) 1064px,(max-width: 90rem) 1126px,1080px" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?fit=2252,1266" srcset="https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?fit=720,480 720w,https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?fit=360,240 360w,https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?fit=1456,818 1456w,https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?fit=728,409 728w,https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?fit=1616,908 1616w,https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?fit=808,454 808w,https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?fit=2128,1196 2128w,https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?fit=1064,598 1064w,https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?fit=2252,1266 2252w,https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?fit=1126,633 1126w,https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?fit=2160,1214 2160w,https://wp.technologyreview.com/wp-content/uploads/2025/09/retracted-papers2a.jpg?fit=1080,607 1080w"/></figure>
<p>Stephanie Arnett/MIT Technology Review | Adobe Stock, Getty Images</p>
<p>Some AI chatbots rely on flawed research from retracted scientific papers to answer questions, according to recent studies. The findings, confirmed by <em>MIT Technology Review</em>, raise questions about how reliable AI tools are at evaluating scientific research and could complicate efforts by countries and industries seeking to invest in AI tools for scientists.</p>
<p>AI search tools and chatbots are already known to <a href="https://www.cjr.org/tow_center/we-compared-eight-ai-search-engines-theyre-all-bad-at-citing-news.php">fabricate links</a> and references. But answers based on the material from actual papers can mislead as well if those papers have been retracted. The chatbot is “using a real paper, real material, to tell you something,” says Weikuan Gu, a medical researcher at the University of Tennessee in Memphis and an author of <a href="https://www.sciencedirect.com/science/article/pii/S2090123225001808">one of the recent studies</a>. But, he says, if people only look at the content of the answer and do not click through to the paper and see that it’s been retracted, that’s really a problem.</p>
<p>Gu and his team asked OpenAI’s ChatGPT, running on the GPT-4o model, questions based on information from 21 retracted papers on medical imaging. The chatbot’s answers referenced retracted papers in five cases but advised caution in only three. While it cited non-retracted papers for other questions, the authors note it may not have recognized the retraction status of the articles. In a <a href="https://onlinelibrary.wiley.com/doi/10.1002/leap.2018">study from August</a>, a different group of researchers used ChatGPT-4o mini to evaluate the quality of 217 retracted and low-quality papers from different scientific fields; they found that none of the chatbot’s responses mentioned retractions or other concerns. (No similar studies have been released on GPT-5, which came out this August.)</p>
<p>The public uses AI chatbots to ask <a href="https://theconversation.com/more-people-are-asking-generative-ai-questions-about-their-health-but-the-wrong-answer-can-be-risky-249383">for medical advice</a> and <a href="https://www.dw.com/en/can-you-trust-ai-medical-advice-from-chatgpt/a-71701818">diagnose health conditions</a>. Students and scientists <a href="https://www.nature.com/articles/d41586-025-00343-5">increasingly use</a> <a href="https://www.nature.com/articles/d41586-025-01069-0">science-focused AI tools</a> to review existing scientific literature and summarize papers. That kind of usage is likely to increase. The US National Science Foundation, for instance, invested $75 million in building AI models for science research this August.</p>
<p>“If [a tool is] facing the general public, then using retraction as a kind of quality indicator is very important,” says Yuanxi Fu, an information science researcher at the University of Illinois Urbana-Champaign. There’s “kind of an agreement that retracted papers have been struck off the record of science,” she says, “and the people who are outside of science—they should be warned that these are retracted papers.” OpenAI did not provide a response to a request for comment about the paper results.</p>
<p>The problem is not limited to ChatGPT. In June, <em>MIT Technology Review</em> tested AI tools specifically advertised for research work, such as Elicit, Ai2 ScholarQA (now part of the Allen Institute for Artificial Intelligence’s Asta tool), Perplexity, and Consensus, using questions based on the 21 retracted papers in Gu’s study. Elicit referenced five of the retracted papers in its answers, while Ai2 ScholarQA referenced 17, Perplexity 11, and Consensus 18—all without noting the retractions.</p>
<p>Some companies have since made moves to correct the issue. “Until recently, we didn’t have great retraction data in our search engine,” says Christian Salem, cofounder of Consensus. His company has now started using retraction data from a combination of sources, including publishers and data aggregators, independent web crawling, and <a href="https://retractionwatch.com/">Retraction Watch</a>, which manually curates and maintains <a href="https://retractiondatabase.org/RetractionSearch.aspx">a database</a> of retractions. In a test of the same papers in August, Consensus cited only five retracted papers.</p>
<p>Elicit told <em>MIT Technology Review</em> that it removes retracted papers flagged by the scholarly research catalogue OpenAlex from its database and is “still working on aggregating sources of retractions.” Ai2 told us that its tool does not automatically detect or remove retracted papers currently. Perplexity said that it “[does] not ever claim to be 100% accurate.”</p>
<p>However, relying on retraction databases may not be enough. Ivan Oransky, the cofounder of Retraction Watch, is careful not to describe it as a comprehensive database, saying that creating one would require more resources than anyone has: “The reason it’s resource intensive is because someone has to do it all by hand if you want it to be accurate.”</p>
<p>Further complicating the matter is that publishers don’t share a uniform approach to retraction notices. “Where things are retracted, they can be marked as such in very different ways,” says Caitlin Bakker from University of Regina, Canada, an expert in research and discovery tools. “Correction,” “expression of concern,” “erratum,” and “retracted” are among some labels publishers may add to research papers—and these labels can be added for many reasons, including concerns about the content, methodology, and data or the presence of conflicts of interest.</p>
<p>Some researchers distribute their papers on preprint servers, paper repositories, and other websites, causing copies to be scattered around the web. Moreover, the data used to train AI models may not be up to date. If a paper is retracted after the model’s training cutoff date, its responses might not instantaneously reflect what's going on, says Fu. Most academic search engines don’t do a real-time check against retraction data, so you are at the mercy of how accurate their corpus is, says Aaron Tay, a librarian at Singapore Management University.</p>
<p>Oransky and other experts advocate making more context available for models to use when creating a response. This could mean publishing information that already exists, like peer reviews commissioned by journals and critiques from the review site PubPeer, alongside the published paper.</p>
<p>Many publishers, such as <em>Nature</em> and the <em>BMJ</em>, publish retraction notices as separate articles linked to the paper, outside paywalls. Fu says companies need to effectively make use of such information, as well as any news articles in a model’s training data that mention a paper’s retraction.</p>
<p>The users and creators of AI tools need to do their due diligence. “We are at the very, very early stages, and essentially you have to be skeptical,” says Tay.</p>
<p><a href="https://storiesbyananya.wordpress.com"><em>Ananya</em></a><em> is a freelance science and technology journalist based in Bengaluru, India.</em></p>
<figure></figure>
