---
author: Brian Merchant
cover_image: >-
  https://substackcdn.com/image/fetch/$s_!XVbm!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1d0e73-1523-46e4-9d13-f9fab3eae627_1328x846.png
date: '2025-09-09T23:25:08.813Z'
dateFolder: 2025/09/09
description: >-
  A new paper calls on academia to repel rampant AI in university departments
  and classrooms.
isBasedOn: 'https://www.bloodinthemachine.com/p/cognitive-scientists-and-ai-researchers'
link: 'https://www.bloodinthemachine.com/p/cognitive-scientists-and-ai-researchers'
slug: >-
  2025-09-09-httpswwwbloodinthemachinecompcognitive-scientists-and-ai-researchers
tags:
  - ai
  - academia
title: >-
  Cognitive scientists and AI researchers make a forceful call to reject
  “uncritical adoption" of AI in academia
---
<p><a href="https://www.bloodinthemachine.com/"><figure><picture><figure><img alt="Blood in the Machine" sizes="100vw" src="https://substackcdn.com/image/fetch/$s_!irLg!,w_80,h_80,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe21f9bf3-26aa-47e8-b3df-cfb2404bdf37_256x256.png"/></figure></picture></figure></a></p>
<h3>A new paper calls on academia to repel rampant AI in university departments and classrooms.</h3>
<p>Greetings friends,</p>
<p>I know there’s been a lot of coverage in these pages of the dark side of commercial AI systems lately: Of <a href="https://www.bloodinthemachine.com/p/ai-killed-my-job-translators">how management is using AI software to drive down wages</a> and deskill work, <a href="https://www.bloodinthemachine.com/p/a-500-billion-tech-companys-core">the psychological crises</a> that AI chatbots are inflicting on vulnerable users, and, <a href="https://www.bloodinthemachine.com/p/one-of-the-last-best-hopes-for-saving">the failure of the courts</a> to confront the monopoly power of Google, the biggest AI content distributor on the planet. To name a few.</p>
<p>But there are so many folks out there—scientists, workers, students, you name it—who are not content to let the future be determined by a handful of Silicon Valley giants alone, and who are pushing back in ways large and small. To wit: A new, just-published paper calls on academia to repel rampant AI adoption in their departments and classrooms.</p>
<p>A group lead by cognitive scientists and AI researchers hailing from universities in the Netherlands, Denmark, Germany, and the US, has published a searing position paper urging educators and administrations to reject corporate AI products. The paper is called, fittingly, <a href="https://zenodo.org/records/17065099">“Against the Uncritical Adoption of 'AI' Technologies in Academia,”</a> and it makes an urgent and exhaustive case that universities should be doing a lot more to dispel tech industry hype and keep commercial AI tools out of the academy.</p>
<p>“It's the start of the academic year, so it's now or never,” Olivia Guest, an assistant professor of cognitive computational science at Radboud University, and the lead author of the paper, tells me. “We're already seeing students who are deskilled on some of the most basic academic skills, even in their final years.”</p>
<p>Indeed, <a href="https://www.mdpi.com/2075-4698/15/1/6">preliminary research</a> indicates that AI encourages cognitive offloading among students, and weakens retention and critical thinking skills.</p>
<p>The paper follows the publication in late June of <a href="https://openletter.earth/open-letter-stop-the-uncritical-adoption-of-ai-technologies-in-academia-b65bba1e?limit=0">an open letter</a> to universities in the Netherlands, written by some of the same authors, and signed by over 1,100 academics, that took a “principled stand against the proliferation of so-called 'AI' technologies in universities.” The letter proclaimed that “we cannot condone the uncritical use of AI by students, faculty, or leadership.” It called for a reconsideration of the financial relationships between universities and AI companies, among other remedies.</p>
<p>The position paper, published September 5th, expands the argument and supports it with historical and academic research. It implores universities to cut through the hype, keep Silicon Valley AI products at a distance, and ensure students’ educational needs are foregrounded. Despite being an academic paper, it pulls few punches.</p>
<p>“When it comes to the AI technology industry, we refuse their frames, reject their addictive and brittle technology, and demand that the sanctity of the university both as an institution and a set of values be restored,” the authors write. “If we cannot even in principle be free from external manipulation and anti-scientific claims—and instead remain passive by default and welcome corrosive industry frames into our computer systems, our scientific literature, and our classrooms—then we have failed as scientists and as educators.”</p>
<p>See? It goes pretty hard.</p>
<p>“The position piece has the goal of shifting the discussion from the two stale positions of AI compatibilism, those who roll over and allow AI products to ruin our universities because they claim to know no other way, and AI enthusiasm, those who have drunk the the Kool-Aid, swallowed all technopositive rhetoric hook line and sinker, and behave outrageously and unreasonably towards any critical thought,” Guest tells me.</p>
<figure><a data-component-name="Image2ToDOM" href="https://substackcdn.com/image/fetch/$s_!XVbm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1d0e73-1523-46e4-9d13-f9fab3eae627_1328x846.png"><picture><img alt="" data-attrs='{"src":"https://substack-post-media.s3.amazonaws.com/public/images/1f1d0e73-1523-46e4-9d13-f9fab3eae627_1328x846.png","srcNoWatermark":null,"fullscreen":null,"imageSize":null,"height":846,"width":1328,"resizeWidth":null,"bytes":231936,"alt":null,"title":null,"type":"image/png","href":null,"belowTheFold":true,"topImage":false,"internalRedirect":"https://www.bloodinthemachine.com/i/172985467?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1d0e73-1523-46e4-9d13-f9fab3eae627_1328x846.png","isProcessing":false,"align":null,"offset":false}' sizes="100vw" src="https://substackcdn.com/image/fetch/$s_!XVbm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1d0e73-1523-46e4-9d13-f9fab3eae627_1328x846.png" srcset="https://substackcdn.com/image/fetch/$s_!XVbm!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1d0e73-1523-46e4-9d13-f9fab3eae627_1328x846.png 424w, https://substackcdn.com/image/fetch/$s_!XVbm!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1d0e73-1523-46e4-9d13-f9fab3eae627_1328x846.png 848w, https://substackcdn.com/image/fetch/$s_!XVbm!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1d0e73-1523-46e4-9d13-f9fab3eae627_1328x846.png 1272w, https://substackcdn.com/image/fetch/$s_!XVbm!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1d0e73-1523-46e4-9d13-f9fab3eae627_1328x846.png 1456w"/></picture></a><figcaption>From Figure 1 in the paper. Figure 1. A cartoon set theoretic view on various terms used when discussing the superset AI: LLMs are in orange; ANNs are in magenta; generative models are in blue; and finally, chatbots are in green. Where these intersect, the colors reflect that, e.g. generative adversarial network (GAN) and Boltzmann machine (BM) models are in the purple subset because they are both generative and ANNs. In the case of proprietary closed source models, e.g. OpenAI’s ChatGPT and Apple’s Siri, we cannot verify their implementation and so academics can only make educated guesses.</figcaption></figure>
<p>“To achieve this we perform a few discursive maneuvers,” she adds. “First, we unpick the technology industry’s marketing, hype, and harm. Second, we argue for safeguarding higher education, critical thinking, expertise, academic freedom, and scientific integrity. Finally, we also provide extensive further reading.”</p>
<p>Here’s the abstract for more detail:</p>
<blockquote><p>Under the banner of progress, products have been uncritically adopted or even imposed on users—in past centuries with tobacco and combustion engines, and in the 21st with social media. For these collective blunders, we now regret our involvement or apathy as scientists, and society struggles to put the genie back in the bottle. Currently, we are similarly entangled with artificial intelligence (AI) technology. </p><p>For example, software updates are rolled out seamlessly and non-consensually, Microsoft Office is bundled with chatbots, and we, our students, and our employers have had no say, as it is not considered a valid position to reject AI technologies in our teaching and research… universities must take their role seriously to a) counter the technology industry’s marketing, hype, and harm; and to b) safeguard higher education, critical thinking, expertise, academic freedom, and scientific integrity. </p></blockquote>
<p>It’s very much worth spending some time with, and not just because it cites yours truly (though I am honored to have Blood in the Machine: The book referenced a few times throughout). It’s an excellent resource for educators, administrators, and anyone concerned about AI in the classroom, really. And it’s a fine arrow in the quiver for those educators already eager to stand up to AI-happy administrations or department heads.</p>
<p>It also helps that these are scientists *working in AI labs and computer science departments*. Nothing against the comp lit and art history professors out there, whose views on the matter are just as valid, but the argument stands to carry more weight among administrations or departments navigating the question of whether or how to integrate AI into their schools this way. It might inspire AI researchers and cognitive scientists skeptical of the enormous industry presence in their field to speak out, too.</p>
<p>And it does feel like these calls are gaining in resonance and momentum—it follows the publication of <a href="https://refusinggenai.wordpress.com/">“Refusing GenAI in Writing Studies: A Quickstart Guide”</a> by three university professors in the US, <a href="https://themindfile.substack.com/p/against-ai-literacy-have-we-actually">“Against AI Literacy,”</a> by the learning designer Miriam Reynoldson, and <a href="https://lareviewofbooks.org/article/inspiration-from-the-luddites-on-brian-merchants-blood-in-the-machine/">lengthy cases for fighting automation in the classroom</a> by educators. After Silicon Valley’s drive to capture the classroom—and success in <a href="https://laist.com/news/education/csu-artificial-intelligence-chatgpt-budget-gap-administrators">scoring some lucrative deals</a>—perhaps the tide is beginning to turn.</p>
<h2>Silicon Valley goes to Washington</h2>
<p>This, of course, is what those educators are up against. The leading lights of Silicon Valley all sitting down with the same president who has effectively dismantled the Department of Education, to kiss his ring, and to do, well, whatever this is:</p>
<article class="rw-embedded-tweet"><header class="rw-embedded-tweet-header"><div><img src="https://cdn.bsky.app/img/avatar/plain/did:plc:66lbtw2porscqpmair6mir37/bafkreihwiie3v5p5zxedev2tunz5cgnjgsn7gjza3ceada2a2nwawehgge@jpeg"/></div><div><span><a href="https://bsky.app/profile/ketanjoshi.co">@ketanjoshi.co</a></span><span><a href="https://bsky.app/profile/ketanjoshi.co">Ketan Joshi</a></span></div><div><a href="https://bsky.app/profile/ketanjoshi.co/post/3ly6tyokzfk2x"><svg fill="none" style="width: 20px; height: 17.8125px;" viewbox="0 0 64 57" width="20"><path d="M13.873 3.805C21.21 9.332 29.103 20.537 32 26.55v15.882c0-.338-.13.044-.41.867-1.512 4.456-7.418 21.847-20.923 7.944-7.111-7.32-3.819-14.64 9.125-16.85-7.405 1.264-15.73-.825-18.014-9.015C1.12 23.022 0 8.51 0 6.55 0-3.268 8.579-.182 13.873 3.805ZM50.127 3.805C42.79 9.332 34.897 20.537 32 26.55v15.882c0-.338.13.044.41.867 1.512 4.456 7.418 21.847 20.923 7.944 7.111-7.32 3.819-14.64-9.125-16.85 7.405 1.264 15.73-.825 18.014-9.015C62.88 23.022 64 8.51 64 6.55c0-9.818-8.578-6.732-13.873-2.745Z" fill="#0085ff"></path></svg></a></div></header><main><p>Incredible clip of tech CEOs fawning over Donald Trump. Someone store this clip in the underground archive vault<article class="rw-embedded-tweet"><header class="rw-embedded-tweet-header"><div>We cannot display the video. <a href="https://bsky.app/profile/ketanjoshi.co/post/3ly6tyokzfk2x" rel="nofollow" target="_blank">Check the original post.</a></div></header><div><a href="https://bsky.app/profile/ketanjoshi.co/post/3ly6tyokzfk2x" rel="nofollow" target="_blank"><img src="https://video.bsky.app/watch/did%3Aplc%3A66lbtw2porscqpmair6mir37/bafkreiadoug5332ewpp2w46s4q4oa75tukvn34kcb6hmnhwa6ovhyr457i/thumbnail.jpg"/></a></div><div>a clip from tiktok </div></article></p></main><footer class="rw-embedded-tweet-footer" data-rw-created-timestamp="1757184891846"><span><a href="https://bsky.app/profile/ketanjoshi.co/post/3ly6tyokzfk2x">Posted Sep 6, 2025 at 6:54PM</a></span></footer></article>
<p>Pretty embarrassing!</p>
<p>Okay, that’s it for today. Thanks as always for reading. Remember, Blood in the Machine is a precarious, 100% reader supported publication. I can only do this work if readers like you chip in a few bucks each month, or $60 a year, and I appreciate each and every one of you. If you can, please consider helping me keep Silicon Valley accountable. Until next time.</p>

<p></p>
