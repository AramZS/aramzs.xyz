---
author: Robert Booth
cover_image: >-
  https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a898840ac81c0db6a3d82e6c95d87646
date: '2025-12-09T14:03:36.661Z'
dateFolder: 2025/12/09
description: >-
  Experts warn of dangers as England and Wales study shows 13- to 17-year-olds
  consulting AI amid long waiting lists for services
isBasedOn: >-
  https://www.theguardian.com/technology/2025/dec/09/teenagers-ai-chatbots-mental-health-support?CMP=share_btn_url
link: >-
  https://www.theguardian.com/technology/2025/dec/09/teenagers-ai-chatbots-mental-health-support?CMP=share_btn_url
slug: >-
  2025-12-09-httpswwwtheguardiancomtechnology2025dec09teenagers-ai-chatbots-mental-health-supportcmpsharebtnurl
tags:
  - ai
  - tech
  - youth
title: >-
  ‘I feel it’s a friend’: quarter of teenagers turn to AI chatbots for mental
  health support
---
<figure><picture><source media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 980px)" srcset="https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 740px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 740px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=700&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 740px)" srcset="https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=700&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 660px)" srcset="https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=645&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 480px)" srcset="https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=645&amp;dpr=1&amp;s=none&amp;crop=none"/><source media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)" srcset="https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=465&amp;dpr=2&amp;s=none&amp;crop=none"/><source media="(min-width: 320px)" srcset="https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none"/><img alt="A sad girl looks at her phone in the dark." src="https://i.guim.co.uk/img/media/9c56f5fc8042537534d9603f19981242fa85bff4/0_0_4800_3840/master/4800.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none"/></picture><figcaption data-spacefinder-role="inline">About 40% of 13- to 17-year-olds in England and Wales affected by youth violence are turning to AI chatbots for mental health support. Photograph: Antonio Guillem/Shutterstock</figcaption></figure>
<h2 data-gu-name="standfirst">Experts warn of dangers as England and Wales study shows 13- to 17-year-olds consulting AI amid long waiting lists for services</h2>
<p>It was after one friend was shot and another stabbed, both fatally, that Shan asked <a data-component="auto-linked-tag" data-link-name="in body link" href="https://www.theguardian.com/technology/chatgpt">ChatGPT</a> for help. She had tried conventional mental health services but “chat”, as she came to know her AI “friend”, felt safer, less intimidating and, crucially, more available when it came to handling the trauma from the deaths of her young friends.</p>
<p>As she started consulting the AI model, the Tottenham teenager joined about 40% of 13- to 17-year-olds in <a data-component="auto-linked-tag" data-link-name="in body link" href="https://www.theguardian.com/uk-news/england">England</a> and Wales affected by youth violence who are turning to AI chatbots for mental health support, according to research among more than 11,000 young people.</p>
<p>It found that both victims and perpetrators of violence were markedly more likely to be using AI for such support than other teenagers. The findings, from the Youth Endowment Fund, have sparked warnings from youth leaders that children at risk “need a human not a bot”.</p>
<p>The results suggest chatbots are fulfilling demand unmet by conventional mental health services, which have long waiting lists and which some young users find lacking in empathy. The supposed privacy of the chatbot is another key factor in driving use by victims or perpetrators of crimes.</p>
<p>After her friends were killed Shan, 18, not her real name, started using Snapchat’s AI before switching to ChatGPT, which she can talk to at any time of day or night with two clicks on her smartphone.</p>
<p>“I feel like it definitely is a friend,” she said, adding that it was less intimidating, more private and less judgmental than her experience with conventional <a data-component="auto-linked-tag" data-link-name="in body link" href="https://www.theguardian.com/society/nhs">NHS</a> and charity mental health support.</p>
<p>“The more you talk to it like a friend it will be talking to you like a friend back. If I say to chat ‘Hey bestie, I need some advice’. Chat will talk back to me like it’s my best friend, she’ll say, ‘Hey bestie, I got you girl’.”</p>
<p>One in four of 13- to 17-year-olds have used an AI chatbot for mental health support in the past year, with black children twice as likely as white children to have done so, the study found. Teenagers were more likely to go online for support, including using AI, if they were on a waiting list for treatment or diagnosis or had been denied, than if they were already receiving in-person support.</p>
<p>Crucially, Shan said, the AI was “accessible 24/7” and would not tell teachers or parents about what she had disclosed. She felt this was a considerable advantage over telling a school therapist, after her own experience of what she thought were confidences being shared with teachers and her mother.</p>
<p>Boys who were involved in gang activities felt safer asking chatbots for advice about other safer ways to make money than a teacher or parent who might leak the information to police or other gang members, putting them in danger, she said.</p>
<p>Another young person, who has been using AI for mental health support but asked not to be named, told the Guardian: “The current system is so broken for offering help for young people. <a data-component="auto-linked-tag" data-link-name="in body link" href="https://www.theguardian.com/technology/chatbots">Chatbots</a> provide immediate answers. If you’re going to be on the waiting list for one to two years to get anything, or you can have an immediate answer within a few minutes … that’s where the desire to use AI comes from.”</p>
<p>Jon Yates, the chief executive of the Youth Endowment Fund, which commissioned the research, said: “Too many young people are struggling with their mental health and can’t get the support they need. It’s no surprise that some are turning to technology for help. We have to do better for our children, especially those most at risk. They need a human not a bot.”</p>
<p>There have been growing concerns about the dangers of chatbots when children engage with them at length. OpenAI, the US company behind ChatGPT, is facing <a data-link-name="in body link" href="https://www.theguardian.com/technology/2025/nov/07/chatgpt-lawsuit-suicide-coach">several lawsuits</a> including from families of young people who have killed themselves after long engagements.</p>
<p>In the <a data-link-name="in body link" href="https://www.theguardian.com/us-news/2025/aug/29/chatgpt-suicide-openai-sam-altman-adam-raine">case of the Californian 16-year-old Adam Raine</a>, who took his life in April, OpenAI has <a data-link-name="in body link" href="https://www.theguardian.com/technology/2025/nov/26/chatgpt-openai-blame-technology-misuse-california-boy-suicide">denied</a> it was caused by the chatbot. It has said it has been improving its technology “to recognise and respond to signs of mental or emotional distress, de-escalate conversations, and guide people toward real-world support.”. The startup <a data-link-name="in body link" href="https://www.theguardian.com/technology/2025/sep/11/chatgpt-may-start-alerting-authorities-about-youngsters-considering-suicide-says-ceo-sam-altman">said</a> in September it could start contacting authorities in cases where users start talking seriously about suicide.</p>
<p>Hanna Jones, a youth violence and mental health researcher in London, said: “To have this tool that could tell you technically anything – it’s almost like a fairytale. You’ve got this magic book that can solve all your problems. That sounds incredible.”</p>
<p>But she is worried about the lack of regulation.</p>
<p>“People are using ChatGPT for mental health support, when it’s not designed for that,” she said. “What we need now is to increase regulations that are evidence-backed but also youth-led. This is not going to be solved by adults making decisions for young people. <a data-component="auto-linked-tag" data-link-name="in body link" href="https://www.theguardian.com/society/youngpeople">Young people</a> need to be in the driving seat to make decisions around ChatGPT and mental health support that uses AI, because it’s so different to our world. We didn’t grow up with this. We can’t even imagine what it is to be a young person today.”</p>
<p><em> In the UK, the youth suicide charity <a data-link-name="in body link" href="https://www.papyrus-uk.org/">Papyrus</a> can be contacted on 0800 068 4141 or email <a data-link-name="in body link | mailto:pat@papyrus-uk.org" href="mailto:pat@papyrus-uk.org">pat@papyrus-uk.org</a>, and in the UK and Ireland <a data-link-name="in body link" href="https://www.samaritans.org/">Samaritans</a> can be contacted on freephone 116 123, or email <a data-link-name="in body link | mailto:jo@samaritans.org" href="mailto:jo@samaritans.org">jo@samaritans.org</a> or <a data-link-name="in body link | mailto:jo@samaritans.ie" href="mailto:jo@samaritans.ie">jo@samaritans.ie</a>. In the US, the <a data-link-name="in body link" href="https://suicidepreventionlifeline.org/">988 Suicide &amp; Crisis Lifeline</a> is at 988 or chat for support. In Australia, the crisis support service <a data-link-name="in body link" href="https://www.lifeline.org.au/">Lifeline</a> is 13 11 14. Other international helplines can be found at <a data-link-name="in body link" href="http://www.befrienders.org/">befrienders.org</a></em></p>
