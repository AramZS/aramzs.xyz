---
author: 'Sonja Drimmer, Christopher J. Nygren'
cover_image: >-
  https://www.publicbooks.org/wp-content/uploads/2025/12/Stanford_Photo-scaled.jpg
date: '2025-12-26T06:13:35.435Z'
dateFolder: 2025/12/26
description: >-
  We are calling for resistance to the AI industry’s ongoing capture of higher
  education.
isBasedOn: 'https://www.publicbooks.org/four-frictions-or-how-to-resist-ai-in-education/'
link: 'https://www.publicbooks.org/four-frictions-or-how-to-resist-ai-in-education/'
slug: >-
  2025-12-26-httpswwwpublicbooksorgfour-frictions-or-how-to-resist-ai-in-education
tags:
  - ai
  - education
title: 'Four Frictions: or, How to Resist AI in Education'
---
<figure><img alt="" sizes="(max-width: 810px) 100vw, 810px" src="https://www.publicbooks.org/wp-content/uploads/2025/12/Stanford_Photo-2048x1664.jpg" srcset="https://www.publicbooks.org/wp-content/uploads/2025/12/Stanford_Photo-810x658.jpg 810w, https://www.publicbooks.org/wp-content/uploads/2025/12/Stanford_Photo-1024x832.jpg 1024w, https://www.publicbooks.org/wp-content/uploads/2025/12/Stanford_Photo-768x624.jpg 768w, https://www.publicbooks.org/wp-content/uploads/2025/12/Stanford_Photo-1536x1248.jpg 1536w, https://www.publicbooks.org/wp-content/uploads/2025/12/Stanford_Photo-2048x1664.jpg 2048w, https://www.publicbooks.org/wp-content/uploads/2025/12/Stanford_Photo-1140x926.jpg 1140w"/><figcaption>By <a data-action="click" data-category="author-name" href="https://www.publicbooks.org/author/sonja-drimmer/">Sonja Drimmer</a> &amp; <a data-action="click" data-category="author-name" href="https://www.publicbooks.org/author/christopher-j-nygren/">Christopher J. Nygren</a> </figcaption></figure>
<p>Arms, open hands, and fists surge above a cluster of heads. We are standing among them, addressed by the bullseye of a megaphone held by a woman facing the crowd. Behind her, plate glass reflects an apparition of leaves and trees over the faces of men looking out. A police officer looms in the corner.</p>
<p>The scene captured in <a href="https://exhibits.stanford.edu/activism/catalog/fc158sg4582">this photo </a>is from over 50 years ago, documenting the 1971 Computation Center Demonstration at Stanford. It was a moment of campus activism, a modest but momentous stand against researchers being allowed by the university to continue diverting computational resources for America’s war machine in Vietnam. This was a signal moment of refusal (as James Dobson describes in detail in <a href="https://www.upress.umn.edu/9781517914219/the-birth-of-computer-vision/"><em>The Birth of Computer Vision</em></a>) against Stanford developing artificial intelligence technologies under the direction of the Department of Defense. The photograph documents students and faculty refusing to permit the exploitation of university resources by the country’s military-industrial complex.</p>
<p>Though half a century ago, still, the demonstration resonates now. Today, it may seem to many that the cluster of technologies marketed as “AI” is entirely new, and, logically, that objection to it must likewise be unheard-of. But, as the demonstration shows, not only is “AI” not especially new; protesting it has a long history. Inspired by the collective objection represented in <a href="https://purl.stanford.edu/fc158sg4582">this photo</a>, we are calling for resistance to the AI industry’s ongoing capture of higher education.</p>
<p>We envision a resistance that is, by its very nature, a repudiation of the efficiencies that automated algorithmic education falsely promises: a resistance comprising the collective force of small acts of friction.</p>
<p><a data-action="image" data-category="bc_explore" href="https://www.publicbooks.org/?post_type=post&amp;p=60869"><figure><img alt="" sizes="(max-width: 460px) 100vw, 460px" src="https://www.publicbooks.org/wp-content/uploads/2025/10/mitchell-luo-gQtUcKahZoQ-unsplash-2048x1365.jpg" srcset="https://www.publicbooks.org/wp-content/uploads/2025/10/mitchell-luo-gQtUcKahZoQ-unsplash-460x306.jpg 460w, https://www.publicbooks.org/wp-content/uploads/2025/10/mitchell-luo-gQtUcKahZoQ-unsplash-300x200.jpg 300w, https://www.publicbooks.org/wp-content/uploads/2025/10/mitchell-luo-gQtUcKahZoQ-unsplash-1024x683.jpg 1024w, https://www.publicbooks.org/wp-content/uploads/2025/10/mitchell-luo-gQtUcKahZoQ-unsplash-768x512.jpg 768w, https://www.publicbooks.org/wp-content/uploads/2025/10/mitchell-luo-gQtUcKahZoQ-unsplash-1536x1024.jpg 1536w, https://www.publicbooks.org/wp-content/uploads/2025/10/mitchell-luo-gQtUcKahZoQ-unsplash-2048x1365.jpg 2048w, https://www.publicbooks.org/wp-content/uploads/2025/10/mitchell-luo-gQtUcKahZoQ-unsplash-810x540.jpg 810w, https://www.publicbooks.org/wp-content/uploads/2025/10/mitchell-luo-gQtUcKahZoQ-unsplash-1140x760.jpg 1140w"/></figure></a></p>
<p>There are key differences between the 1971 protest and the growing resistance to AI today. Back then, advanced computational development was directed explicitly toward military purposes. When this research had to pass through university infrastructures, the violence of its purpose was easy to see. And this, in turn, made the potential targets of resistance clear; indeed, it was relatively easy to organize protests in front of large mainframe computers, located in very specific facilities and locations. Now, however, computation is distributed. And this makes the targets to resist so diffuse that the shape of direct action becomes difficult even to conceptualize.</p>
<p>Another difference is who is directing the violence. Once, universities saw their computational power exploited by researchers working for the Department of Defense. Today, universities are being infiltrated by a commercial industry (albeit one that receives a staggering amount of money from defense contracts) that exploits students and faculty as data mines, test subjects, and a perpetual supply depot of future users, all for their own profit.</p>
<p>Universities have accepted the overtures from this industry in a FOMO-driven frenzy without consulting their faculty, collecting empirical data on whether generative AI is pedagogically useful, or pausing to inquire about the long-term impact of AI on the students who have been entrusted to their care. Faculty are at best being coerced—and at worst being forced—to employ generative AI in their teaching, assessment, or advising. Moreover, with the educational mission that they thought they were signing up for undermined, students have no option to resist.</p>
<p>In other words, we have all been left on our own to jury rig workable pedagogical scaffolds while the educational edifice is being bulldozed around us. Individual responses will not suffice; collective action is necessary.</p>
<p>The photograph shows us a moment when students and some faculty resisted the co-optation of university resources in the service of the Department of Defense’s war machine operating thousands of miles away. It was a moment in which human bodies and minds came into conflict: chants were yelled, rocks were thrown, the son of one faculty member was shot, twelve individuals were arrested, and a tenured faculty member fired.</p>
<p>Resistance in 2025, however, demands collective action across a much broader spectrum. The AAUP has released <a href="https://www.aaup.org/reports-publications/aaup-policies-reports/topical-reports/artificial-intelligence-and-academic">a report</a> with a set of excellent recommendations, which we commend. Others have begun making <a href="https://openletter.earth/an-open-letter-from-educators-who-refuse-the-call-to-adopt-genai-in-education-cb4aee75">public pledges</a> disavowing the use of AI in their classrooms, and we support such endeavors as well.</p>
<p>To these measures, however, we call for even more.</p>
<h4>A Brief History of Technosolutionism in Teaching</h4>
<p>Grandiose promises that technology will improve education are nothing new. Such promises have been a refrain for decades. It is remarkable how little they have changed and how consistently they have failed to deliver. A recent interview with Sal Khan <a href="https://www.yahoo.com/news/khan-academy-ceo-predicts-ai-095501931.html">quotes the founder </a>and CEO of Khan Academy as imagining the use of “AI teaching assistants … able to help children when needed and ‘report back to the teacher.’” For someone allegedly so invested in the future, Khan sounds uncannily like the past. In 1954, the behaviorist B. F. Skinner was promoting his “teaching machines,” <a href="https://archive.org/details/technologyofteac0000skin/page/22">writing</a>, “If the teacher is to take advantage of recent advances in the study of learning, she must have the help of mechanical devices.” As Audrey Watters has written in <a href="https://mitpress.mit.edu/9780262546065/teaching-machines/"><em>Teaching Machines</em></a>, “What today’s technology-oriented education reformers claim is a new idea—‘personalized learning’—that was unattainable if not unimaginable until recent advances in computing and data analysis has actually been the goal of technology-oriented education reformers for almost a century.” And, as Watters shows, similar to the protesters at Stanford, students at the Ohio State University in the 1930s rejected—derided, really—such proposals. Langdon Winner <a href="https://journals.sagepub.com/doi/10.2304/pfie.2009.7.6.587">accuses</a> educators who fall prey to the blandishments of ed-tech boosters of a “willingness to forget” that “there is scant evidence during the decades from Edison to the present day that any of the heavily touted varieties of equipment introduced into schools and colleges over the years has done much to improve education at all.”</p>
<p>In the techno-utopian scenario, generative AI can essentially teach undergraduates many foundational skills. Even elite institutions like the University of Chicago are seriously entertaining the idea that their students will be “<a href="https://www.compactmag.com/article/the-crisis-of-the-university-started-long-before-trump">taught” foreign languages by ChatGPT</a>. And by now there is a <a href="https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web">cottage industry</a> of <a href="https://nymag.com/intelligencer/article/openai-chatgpt-ai-cheating-education-college-students-school.html">essays</a> on how teaching <a href="https://www.newyorker.com/magazine/2025/07/07/the-end-of-the-english-paper">college writing</a> has been rendered superfluous in the wake of generative AI. Some of these essays betray an exhausted resignation, while others seek to find promise in the incorporation of AI into the college classroom. In different ways, though, both resignation and optimism suggest that the co-optation of education by this technology is inevitable. It is, in some ways, writing as therapy: an effort to maintain contact with the terrain that is shifting under the author’s feet. There’s value in that, but we are not writing for therapy; we are writing for change.</p>
<p>We write from the perspective of 2025. But we also write as historians looking back at a lineage of educators and students who have resisted the incursions of technosolutionism, technocapitalism, and technofascism in higher education. As such, we warn of the possible consequences of inaction; and we hope that action will shape a future for higher education that defends students and faculty’s humanity.</p>
<h4>A Crisis in Teaching, Or a Crisis in Learning?</h4>
<p>Time and again we have been told that a dire educational crisis demands technological solutions that will improve learning outcomes. So, our question is: Why are we doing this again? What is the crisis? Where is it located? Teaching? Learning? Or society more broadly?</p>
<p>This short essay is not the place for a full diagnosis. Still, we cannot hold this conversation without recognizing that, since the 1980s, state and federal governments have divested from education. Efforts have been made to plug these funding holes with public-private partnerships, bringing into schools technology firms, other industries, and private philanthropy. Yet all these investments have been accompanied, crucially, by a corrosive cultural argument: that public expenditure on education was a wasteful extravagance, anyway, one that can be cleaned up by a new model of technologically led pedagogy.</p>
<p>It is in this context that we must consider the newfound praise of AI in education. AI boosters promise that the technology will find greater efficiencies in education; but this is less about the functionalities of AI itself, and far more about eviscerating the public nature of public education. As the ceaseless ed-tech boom-and-bust cycle of the last century has repeatedly shown, efficiencies are easy to promise, but difficult to realize in the stubbornly human-centered endeavor of education. And that is because education is, by necessity, inefficient.</p>
<h2>learning is the result of human grappling with the parts of the world that resist us and our capacity to understand.</h2>
<p>Trump’s federal budget, passed on July 4, 2025, transfers the largest amount of wealth upward from poor to rich ever in the country’s history. In addition, the budget continues in the trend of defunding education in favor of massive tax cuts for the rich and budget infusions for a national anti-immigrant police force. Clearly, in the near term, we cannot rely on a simple reinvestment in public education.</p>
<p>Within this context, professors and administrators may be tempted to see technology companies as a life raft. Adopting AI, this argument goes, might save professors some time or energy.</p>
<p>Such a temptation must be rejected. Higher ed must, instead, ask the same question Marc Watkins has proposed for secondary education: <a href="https://marcwatkins.substack.com/p/who-owns-the-ai-dividend">Who owns the A.I. dividend</a>? Technology firms see the university as a gigantic data farm; they are not invested in our students or the learning process, only in harvesting the attention of an entire generation of users, who will be addicted to their product for the rest of their adult lives.</p>
<p>Even worse, these students will be subjected to brutal calculations—based on the data stolen from them in college—to determine their worthiness for job interviews, the validity of insurance claims, or eligibility for parole.</p>
<p>Why, after all, has a consensus so quickly emerged that we have a crisis in <em>teaching</em>? Is this not more rightly described as a crisis in <em>learning</em>? Or, more aptly, as an <em>attack </em>on learning?</p>
<h4>AI ISN’T EDUCATION</h4>
<p>Most fundamentally, we believe that learning is the result of human grappling with the parts of the world that resist us and our capacity to understand. This conception of education is antithetical to the transactional and antihuman program of “optimized” and “efficient” delivery of learning outcomes, promised by proponents of AI’s incursion into the space of education.</p>
<p>The most thrilling moments for us as educators come when we see the glint and sparkle of a student having an illumination: anything from finding the best articulation of an idea or making connections between seemingly disparate bodies of knowledge. Those moments underline for us that learning is ultimately a process, and one that is predicated on friction and struggle. Anyone who has taught will have had the experience of watching a student struggle with a complex concept or piece of evidence. Ideas are slippery things, and grasping them more than fleetingly is a challenge. This is the result of epistemological friction, of rubbing our ideas against a world that is recalcitrant and full of other agents who see it differently. At its best, education is similar to C. S. Peirce’s definition, in “<a href="https://archive.org/details/1877-peirce-fixation-of-belief">The Fixation of Belief</a>,” of inquiry as the “irritation of doubt [which] causes a struggle to attain a state of belief.” That is, we believe, a pretty concise summation of the purpose of higher education: to lead students from doubt into knowledge.</p>
<p>Learning is not a problem to be solved; it’s a process to be undertaken. There are students who feel that they are <a href="https://www.chronicle.com/special-projects/the-different-voices-of-student-success/ai-to-the-rescue">being robbed</a> of an educational experience, because AI has fundamentally shifted the culture of education. Not only do their fellow students seem more apt to use ChatGPT as a “study buddy,” they also worry that the faculty are using AI to offer perfunctory assessments of their work. To those students, we say: we see you and we validate your sense of frustration. We teach to you, and we hope that you will learn with us.</p>
<h4>Centering Humanity through Small Acts of Friction</h4>
<p>And so, we write here as a call to action. We hope that other educators will join us in helping students and professors to pave an exit ramp off the alienating highway of automated education, and we aspire to achieve this in community, rather than as solitary prompt engineers.</p>
<p>Resistance must entail what Emily Bender and Alex Hanna call in <a href="https://www.harpercollins.com/products/the-ai-con-emily-m-benderalex-hanna"><em>The AI Con</em></a> “strategic refusal.”</p>
<p><em>The strategic refusal for which we call takes the form of “acts of friction.”</em></p>
<p><strong>Friction One:</strong> Resolutely center students in our teaching. Maintaining students at the center of our focus means not only refusing to use AI in teaching. Paradoxically, it also means refusing to devise assignments that deflect AI, and, thus, making AI the main focus again. Students, not LLMs, are the protagonists of education and should be treated as such. The friction here means accepting that it is a waste of our and our students’ time to redefine education for the purposes of ChatGPT-proofing our classrooms. Defensive maneuvers, like in-class essay writing exclusively, are acts of deprivation. They deprive students of the opportunity to reflect and refine away from the pressures of the classroom clock. Don’t fulfill the prophecy that “the college essay is dead” because <em>The Atlantic </em>told you so. Keep the essay; but don’t be a cop. Meet thoughtless text extrusion with desultory feedback. Reserve your energy instead for crafting assignments that compel care from students who care enough to think, offering thoughtful feedback on the papers that exhibit their own thoughtfulness.</p>
<p><strong>Friction Two:</strong> Cultivate the moments between graded reckonings; slow down the momentum of “optimizing.” What we mean here are small acts of extracurricular and uncredited communion. Reading groups, lightning round presentations, unambitious programs of being in simple, un-CV-able conversations. These pauses alone will insist on humanity’s place in learning. And while these pauses themselves insist on the vitality of getting to think with one another without being subject to metrics and rubrics or succumbing to the thrall of their being against AI, we <em>can</em> also talk to our colleagues and students about our stance on it to show them that there are those who are skeptical.</p>
<p><strong>Friction Three:</strong> Interrupt the digital landscape. Erect small speed bumps that jostle and slow our course, drawing attention back to our control over the direction we are taking. This can take the form of sharing print-outs of reading in hallways, leaflets in folders tacked to office doors, pamphlets on tables in common spaces. It also means rejecting the online-ification of education and opting out of Learning Management Systems, while also distributing resources such as those being compiled on the website <a href="https://against-a-i.com/">Against AI</a>.</p>
<p><strong>Friction Four:</strong> Ask questions. Rather than accepting the premise that education needs reforming—that the sight of a graph or bar chart proves that a problem exists and that products offer solutions—ask questions of your administration. But this resistance must happen person-to-person. Only once we have created this kind of community will we be comfortable and secure in asking these questions.</p>
<p>In the end, friction means being sand in the gears. It means being the squeaky wheel and the pebble in the shoe, and even the thorn in the side. What this will look like will differ from person to person, and from institution to institution: to propose a single solution would only resemble the disregard for context on which the AI industry thrives.</p>
<p>Whatever small acts of friction one takes, let them make it hard for universities to charge ahead, pouring resources into a technology that none of us asked for. It’s only friction that can bring this momentum to a halt.</p>
