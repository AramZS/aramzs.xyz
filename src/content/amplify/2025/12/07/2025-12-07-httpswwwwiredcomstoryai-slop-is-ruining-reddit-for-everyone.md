---
author: Kat Tenbarge
cover_image: >-
  https://media.wired.com/photos/692f329c56ed04538b1ea189/191:100/w_1280,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg
date: '2025-12-07T05:31:25.384Z'
dateFolder: 2025/12/07
description: >-
  Reddit is considered one of the most human spaces left on the internet, but
  mods and users are overwhelmed with slop posts in the most popular subreddits.
isBasedOn: 'https://www.wired.com/story/ai-slop-is-ruining-reddit-for-everyone/'
link: 'https://www.wired.com/story/ai-slop-is-ruining-reddit-for-everyone/'
slug: 2025-12-07-httpswwwwiredcomstoryai-slop-is-ruining-reddit-for-everyone
tags:
  - ai
  - social media
title: AI Slop Is Ruining Reddit for Everyone
---
<p>Reddit is considered one of the most human spaces left on the internet, but mods and users are overwhelmed with slop posts in the most popular subreddits.</p>
<figure><picture><source media="(max-width: 767px)" sizes="100vw" srcset="https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_120,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 120w, https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_240,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 240w, https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_320,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 320w, https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_640,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 640w, https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_960,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 960w"/><source media="(min-width: 768px)" sizes="100vw" srcset="https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_120,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 120w, https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_240,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 240w, https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_320,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 320w, https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_640,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 640w, https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_960,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 960w, https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_1280,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 1280w, https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_1600,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 1600w, https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_1920,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 1920w, https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_2240,c_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg 2240w"/><figure><img alt="Image may contain Person Face and Head" data-src="https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_2560%2Cc_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg" src="https://media.wired.com/photos/692f329c56ed04538b1ea189/1:1/w_2560%2Cc_limit/Die-Hard-Redditors-Feeling-Pushed-out-by-AI-Culture-.jpg"/></figure></picture></figure>
<p>Photo-Illustration: WIRED Staff; Getty Images</p>
<p>A Reddit post about a bride who demands a wedding guest wear a specific, unflattering shade is sure to provoke rage, let alone one about a bridesmaid or mother of the groom who wants to wear white. A scenario where a parent asks someone on an airplane to switch seats so they can sit next to their young child is likely to invoke the same rush of anger. But those posts may trigger a <a href="https://www.wired.com/tag/reddit/">Reddit</a> moderator’s annoyance for a different reason—they are common themes within a growing genre of <a href="https://www.wired.com/tag/artificial-intelligence/">AI</a>-generated, fake posts.</p>
<p>These are examples that spring to mind for Cassie, one of dozens of moderators for <a href="https://www.wired.com/story/reddit-am-i-the-asshole-relationship-advice/">r/AmItheAsshole</a>. With over 24 million members, it's one of the biggest subreddits, and it explicitly bans AI-generated content and other made-up stories. Since late 2022, when ChatGPT first launched to the public, Cassie (who wanted to be referred to by first name only) and other people who volunteer their time to moderate Reddit posts have been struggling with an influx of AI content. Some of it is entirely AI-generated, while other users have taken to editing their posts and comments with AI programs like Grammarly.</p>
<p>“It’s probably more prevalent than anybody wants to really admit, because it’s just so easy to shove your post into ChatGPT and say ‘Hey, make this more exciting,’” says Cassie, who thinks as much as half of all content being posted to Reddit may have been created or reworked with AI in some way.</p>
<p>r/AmItheAsshole is a pillar of Reddit culture, a format that has inspired dozens if not hundreds of derivatives like r/AmIOverreacting, r/AmITheDevil, and r/AmItheKameena, a subreddit with over 100,000 members described as “Am I the asshole, but the Indian version.” Posts tend to feature stories about interpersonal conflicts, where Redditors can weigh in on who is wrong (“YTA” means “You’re the asshole,” while “ESH” means “Everyone sucks here”), who is right, and what the best course of action to take is moving forward. Users and moderators across these r/AmItheAsshole variants have reported seeing more content they suspect is AI-generated, and others say it's a sitewide issue happening in all kinds of subreddits.</p>
<p>“If you have a general wedding sub or AITA, relationships, or something like that, you will get hit hard,” says a moderator of r/AITAH, a variant of r/AmItheAsshole that has almost 7 million members. This moderator, a retiree who spoke on the condition of anonymity, has been active on Reddit for 18 years—most of its existence—and also had decades of experience in the web business before that. She views AI as a potential existential threat to the platform.</p>
<p>“Reddit itself is either going to have to do something, or the snake is going to swallow its own tail,” she says. “It’s getting to the point where the AI is feeding the AI.”</p>
<p>In a response to a request for comment, a Reddit spokesperson said: “Reddit is the most human place on the Internet, and we want it to stay that way. We prohibit manipulated content and inauthentic behavior, including misleading AI bot accounts posing as people and foreign influence campaigns. Clearly labeled AI-generated content is generally allowed as long as it’s within a community’s rules and our sitewide rules.” The spokesperson added that there were over 40 million “spam and manipulated content removals” in the first half of 2025.</p>
<h2>Vibe Shift for the Worse</h2>
<p>Ally, a 26-year-old who tutors at a community college in Florida and spoke using her first name only for her privacy, has noticed Reddit “really going downhill” in the past year because of AI. Her feelings are shared by other users in subreddits like r/EntitledPeople, r/simpleliving, and r/self, where posts in the last year have bemoaned the rise of suspected AI. The mere possibility that something could be AI-generated has already eroded trust between users. “AI is turning Reddit into a heap of garbage,” one account wrote in r/AmITheJerk. “Even if a post suspected of being AI isn’t, just the existence of AI is like having a spy in the room. Suspicion itself is an enemy.” Ally used to enjoy reading subreddits like r/AmIOverreacting. But now she doesn’t know if her interactions are real anymore, and she’s spending less time on the platform than in years past.</p>
<p>“AI burns everybody out,” says the r/AITAH moderator. “I see people put an immense amount of effort into finding resources for people, only to get answered back with ‘Ha, you fell for it, this is all a lie.’”</p>
<h2>Detecting AI</h2>
<p>There are few foolproof ways to prove that something is AI or not, and most everyday people are relying on their own intuition. Text can be even harder to evaluate than photos and videos, which often have pretty definitive tells. Five Redditors who spoke to WIRED all had different strategies for identifying AI-generated text. Cassie notices when posts restate their title verbatim in the body or use <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://www.nytimes.com/2025/09/18/magazine/chatgpt-dash-hyphen-writing-communication.html"}' data-offer-url="https://www.nytimes.com/2025/09/18/magazine/chatgpt-dash-hyphen-writing-communication.html" href="https://www.nytimes.com/2025/09/18/magazine/chatgpt-dash-hyphen-writing-communication.html">em dashes</a>, as well as when a poster has terrible spelling and punctuation in their comment history but posts something with perfect grammar. Ally is thrown off by newly created Reddit accounts and posts with emojis in the title. The r/AITAH mod gets an “uncanny valley” feeling from certain posts. But these “tells” could also be present in a post that isn’t using AI at all.</p>
<p>“At this point, it’s a bit of a you-know-it-when-you-see-it kind of vibe,” says Travis Lloyd, a PhD student at Cornell Tech who has <a href="https://news.cornell.edu/stories/2025/10/ai-generated-content-triple-threat-reddit-moderators">published research</a> into new AI-driven challenges that Reddit moderators face. “Right now, there are no reliable tools to detect it 100 percent of the time. So people have their strategies, but they’re not necessarily foolproof.”</p>
<p>Plus, as more AI text appears in the wild, people start mimicking the commonalities of AI-generated language whether they use AI or not. On Reddit, the AI feedback loop may be even more incestuous, since the platform has sued AI companies like <a href="https://apnews.com/article/reddit-sues-ai-company-anthropic-claude-chatbot-f5ea042beb253a3f05a091e70531692d">Anthropic</a> and <a href="https://apnews.com/article/reddit-perplexity-ai-copyright-scraping-lawsuit-3ad8968550dd7e11bcd285a74fb6e2ff">Perplexity</a> for allegedly scraping Reddit content without consent to train chatbots. Google’s AI summary results have infamously pulled from Reddit comments that are actually sarcastic jokes, like a user who <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://www.404media.co/google-is-paying-reddit-60-million-for-fucksmith-to-tell-its-users-to-eat-glue/"}' data-offer-url="https://www.404media.co/google-is-paying-reddit-60-million-for-fucksmith-to-tell-its-users-to-eat-glue/" href="https://www.404media.co/google-is-paying-reddit-60-million-for-fucksmith-to-tell-its-users-to-eat-glue/">suggested using glue</a> to make cheese stick to pizza crust better.</p>
<p>“AI is trained off people, and people copy what they see other people doing,” Cassie says. “People become more like AI, and AI becomes more like people.”</p>
<h2>Rage-Bait Targeting Minorities</h2>
<p>Both AITA moderators say they’ve observed a trend of rage-bait posts that could be written with AI and seem to exist just to malign trans people and other vulnerable populations. The r/AITAH moderator says the subreddit received a deluge of anti-trans content during Pride Month, while Cassie says it pops up in the moderation queue intermittently.</p>
<p>“Stuff like ‘My parents didn’t use my chosen name and I’m trans and I blew up on them because how dare they’ or ‘Somebody assumed my gender and I’m cis but how dare they assume my gender,’” Cassie says. “They’re just meant to make you mad at trans people, at gay people, at Black people, at women.”</p>
<p>In subreddits that revolve around news and politics, AI has enabled new ways of spreading disinformation. It’s something that Tom, a Redditor who helped moderate r/Ukraine for three years and spoke using only his first name for privacy, encountered alongside social manipulation techniques like astroturfing that predated programs like ChatGPT. But now, AI can automate those tactics, making it even harder for human moderators to keep up.</p>
<p>“It was like one guy standing in a field against a tidal wave,” Tom says. “You can create so much noise with such little effort.”</p>
<p>On r/Ukraine, which has close to a million members, Tom remembers getting training from other mods to try and mitigate the spread of Russian propaganda and even receiving specialized support from Reddit admins, who are a step above the volunteers and actually work for and get paid by Reddit.</p>
<h2>Monetizing Karma</h2>
<p>In addition to ideological motivations, there are also little-known ways to monetize Reddit content. Some are more obvious, like the <a data-event-click='{"element":"ExternalLink","outgoingURL":"https://support.reddithelp.com/hc/en-us/articles/17331620007572-What-is-the-Contributor-Program-and-how-can-I-participate"}' data-offer-url="https://support.reddithelp.com/hc/en-us/articles/17331620007572-What-is-the-Contributor-Program-and-how-can-I-participate" href="https://support.reddithelp.com/hc/en-us/articles/17331620007572-What-is-the-Contributor-Program-and-how-can-I-participate">Reddit Contributor Program</a>, which lets posters make money from getting upvotes (referred to as “karma”) and awards that other users can purchase for them. Reddit hustlers can theoretically use AI-generated content to rack up karma, profit from it, and even sell their accounts.</p>
<p>“My Reddit account is worth a lot of money, and I know because people keep trying to buy it,” Tom says. “It could also be used for nefarious purposes, but I suspect a lot of it is people who are bored and have time, they’re like ‘Well, I could make a hundred bucks in a month on the side by doing almost nothing.’”</p>
<p>Other accounts need the karma to get access to post in NSFW subreddits that have karma requirements to do so, where they can then promote things like OnlyFans links. Both Cassie and the r/AITAH moderator have noticed accounts posting in their larger subreddits to rack up karma before moving on to posting adult content. Some of them are scammers. Others may just be trying to make a living.</p>
<p>“Sometimes it’s real, sometimes it’s an actual conflict they have actually had, sometimes it’s fake, sometimes either way it’s AI-generated,” Cassie says. “I almost want to call it gamification, where they’re just trying to use the system the way that it’s been set up.”</p>
<p>The extra time it takes for Reddit moderators to sift through potential AI material is a reflection of how AI content in general has created new roadblocks, which extends well beyond the realm of social media moderation.</p>
<p>“What Reddit moderators are dealing with is what people all over the place are dealing with right now, which is adjusting to a world where it takes incredibly little effort to create AI-generated content that looks plausible, and it takes way more effort to evaluate it,” Lloyd says. “That’s a real burden on them, like it is for teachers and whoever else.”</p>
