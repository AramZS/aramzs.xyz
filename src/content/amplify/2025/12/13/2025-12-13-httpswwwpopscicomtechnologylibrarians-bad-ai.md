---
author: Andrew Paul
cover_image: >-
  https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?quality=85&w=1200
date: '2025-12-13T17:17:00.972Z'
dateFolder: 2025/12/13
description: 'From false sources to hallucinations, it’s become a major problem.'
isBasedOn: 'https://www.popsci.com/technology/librarians-bad-ai/'
link: 'https://www.popsci.com/technology/librarians-bad-ai/'
slug: 2025-12-13-httpswwwpopscicomtechnologylibrarians-bad-ai
tags:
  - ai
title: Librarians can’t keep up with bad AI
---
<figure><img alt="Library aisle showing rows of books" sizes="(max-width: 2000px) 100vw, 2000px" src="https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg" srcset="https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=50&amp;h=28 50w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=280&amp;h=158 280w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=289&amp;h=163 289w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=308&amp;h=173 308w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=370&amp;h=208 370w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=384&amp;h=216 384w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=580&amp;h=326 580w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=660&amp;h=371 660w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=704&amp;h=396 704w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=711&amp;h=400 711w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=768&amp;h=432 768w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=1024&amp;h=576 1024w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=1152&amp;h=648 1152w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=1234&amp;h=694 1234w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=1250&amp;h=703 1250w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=1337&amp;h=752 1337w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=1440&amp;h=810 1440w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=1486&amp;h=836 1486w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=1536&amp;h=864 1536w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg?w=1819&amp;h=1023 1819w, https://www.popsci.com/wp-content/uploads/2025/12/Library-Aisle.jpg 2000w"/><figcaption>One librarian estimated as much as 15 percent of their reference requests are AI-generated. <strong>Credit: <a href="https://depositphotos.com/photos/public-library.html?offset=60&amp;filter=all&amp;qview=173862594">Deposit Photos</a></strong></figcaption></figure>
<p>Generative <a href="https://www.popsci.com/category/ai/">artificial intelligence</a> continues to have a problem with <a href="https://www.popsci.com/technology/chatgpt-conspiracy-theory-misinfo/">hallucinations</a>. Although many responses to user queries are largely accurate, programs like ChatGPT, <a href="https://www.popsci.com/diy/how-to-erase-google-gemini-memory/">Google Gemini</a>, and Microsoft Copilot are still prone to offering <a href="https://gizmodo.com/librarians-arent-hiding-secret-books-from-you-that-only-ai-knows-about-2000698176">made-up information and facts</a>. As bad as that is on its own, the issue is further complicated by a tendency for these AI programs to produce seemingly reputable, yet wholly imaginary, sources. But as annoying as that is for millions of users, it’s becoming a major issue for the people trusted to provide reliable, real information: librarians.</p>
<p>“For our staff, it is much harder to prove that a unique record doesn’t exist,” Sarah Falls, a research engagement librarian at the Library of Virginia, told <a href="https://www.scientificamerican.com/article/ai-slop-is-spurring-record-requests-for-imaginary-journals/"><em>Scientific American</em></a>.</p>
<p>Falls estimated that around 15 percent of all the reference questions received by her staff are written by generative AI, some of which include imaginary citations and sources. This increased burden placed on librarians and institutions is so bad that even organizations like the International Committee of the Red Cross are putting people on notice about the problem.</p>
<p>“A specific risk is that generative AI tools always produce an answer, even when the historical sources are incomplete or silent,” the <a href="https://www.icrc.org/en/article/important-notice-ai-generated-archival-references?afd_azwaf_tok=eyJraWQiOiIzOTI3RjFFNDBGODczRjIyNkVCRTc4QjY5MkM1OUU1NDA2QzUyMzgxN0MxQkY4QTA4OEZBQzQ0MTQ0NUFEQzgyIiwiYWxnIjoiUlMyNTYifQ.eyJhdWQiOiJ3d3cuaWNyYy5vcmciLCJleHAiOjE3NjU1NjU0MTQsImlhdCI6MTc2NTU2NTQwNCwiaXNzIjoidGllcjEtOWM0ZDk4NjU4LThyN25zIiwic3ViIjoiNzkuMTI3LjEzNi42NyIsImRhdGEiOnsidHlwZSI6Imlzc3VlZCIsInJlZiI6IjIwMjUxMjEyVDE4NTAwNFotcjE5YzRkOTg2NTg4cjduc2hDMUNISXloOTQwMDAwMDAwODEwMDAwMDAwMDBjY2RnIiwiYiI6ImZvU2loSEtBLW5ISUJJRjVfZHdZY2FET1kxZjdnYVhpQXFRaE92X1c0c00iLCJoIjoiMTRCQVJSVnNYX01HNDJreEgydVQtLW5aWGMybmJJTXNqT3N2VVZ0RTBNbyJ9fQ.W9HATylklT4PKhH8t5CKX9gt0VEZObgUu-cKfgBSmcFbwHmJAGKUWqGiEJKMGikyZcfxHBRsjd-xmdce2tEtozM3q6Mrmg0OlhAwEEjkfiKsRymrCIy7flnm70rpSG_VJt9kqhcddk-8qj4a-0DrqeRkvPx9Z0kE4cl-yAtVFBwFm6zSqTPWHzzkFrcN0ERjBgK8z4bQXYfBKL1XB-V-rWszKbgR1U9TRKIeQZcwRl7UDh73Trsrr7B9hMEBuBmNPK8zBrRgsGZe4s3kR9Hcx2bJj45m1cKg9sV6dAMWCLPpKrtWjLAhfSnNeZ_JhNrVCEaaaHL6PgtGV-Typ3mDEg.WF3obl2IDtqgvMFRqVdYkD5s">ICRC cautioned in a public notice</a> earlier this month. “Because their purpose is to generate content, they cannot indicate that no information exists; instead, they will invent details that appear plausible but have no basis in the archival record.”</p>
<p>Instead of asking a program like ChatGPT for a list of ICRC reports, the organization suggests you engage directly with their <a href="https://archives.icrc.org/search/advanced">publicly available information catalogue</a> and <a href="https://library.icrc.org/library/">scholarly archives</a>. The same strategy should be extended to any institution. Unfortunately, until more people understand the fallibility of generative AI, the burden will remain on human archivists.</p>
<p>“We’ll likely also be letting our users know that we must limit how much time we spend verifying information,” Falls warned.</p>
<p>There’s a good reason why librarians remained an integral component in societies for thousands of years. Unlike generative AI, they’re trained to think critically, search for answers, and most importantly, admit when they’re wrong.</p>
