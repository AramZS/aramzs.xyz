---
author: Anil Dash
cover_image: 'https://www.anildash.com/images/keycaps.jpg'
date: '2025-12-03T18:58:02.494Z'
dateFolder: 2025/12/03
description: A blog about making culture. Since 1999.
isBasedOn: 'https://www.anildash.com/2025/12/02/vibe-coding-empowering-and-imprisoning/'
link: 'https://www.anildash.com/2025/12/02/vibe-coding-empowering-and-imprisoning/'
slug: 2025-12-03-httpswwwanildashcom20251202vibe-coding-empowering-and-imprisoning
tags:
  - ai
  - tech
title: 'Vibe Coding: Empowering and Imprisoning'
---
<figure><picture><source sizes="(min-width: 1024px) 1200px, 100vw" srcset="https://www.anildash.com/img/BMvev3l4kz-600.webp%20600w,%20/img/BMvev3l4kz-900.webp%20900w,%20/img/BMvev3l4kz-1200.webp%201200w,%20/img/BMvev3l4kz-1600.webp%201600w" type="image/webp"/><img alt="Vibe Coding: Empowering and Imprisoning" sizes="(min-width: 1024px) 1200px, 100vw" src="https://www.anildash.com/img/BMvev3l4kz-600.jpeg" srcset="https://www.anildash.com/img/BMvev3l4kz-600.jpeg%20600w,%20/img/BMvev3l4kz-900.jpeg%20900w,%20/img/BMvev3l4kz-1200.jpeg%201200w,%20/img/BMvev3l4kz-1600.jpeg%201600w"/></picture></figure>
<p>In case you haven’t been following the world of software development closely, it’s good to know that vibe coding — using LLM tools to assist with writing code — can help enable many people to create apps or software that they wouldn’t otherwise be able to make. This has led to an extraordinary rapid adoption curve amongst even experienced coders in many different disciplines within the world of coding. But there’s a very important threat posed by vibe coding that almost no one has been talking about, one that’s far more insidious and specific than just the risks and threats posted by AI or LLMs in general.</p>
<p>Here’s a quick summary:</p>
<ul> <li>One of the most effective uses of LLMs is in helping programmers write code</li> <li>A huge reason VCs and tech tycoons put billions into funding LLMs was so they could undermine coders and depress wages</li> <li>Vibe coding might limit us to making simpler apps instead of the radical innovation we need to challenge Big Tech</li> </ul>
<h2>Start vibing</h2>
<p>It may be useful to start by explaining how people use LLMs to assist with writing software. My background is that I’ve helped build multiple companies focused on enabling millions of people to create with code. And I’m personally an example of one common scenario with vibe coding. Since I don’t code regularly anymore, I’ve become much slower and less efficient at even the web development tasks that I used to do professionally, which I used to be fairly competent at performing. In software development, there are usually a nearly-continuous stream of new technologies being released (like when you upgrade your phone, or your computer downloads an update to your web browser), and when those things change, developers have to update <em>their</em> skills and knowledge to stay current with the latest tools and techniques. If you’re not staying on top of things, your skillset can rapidly decay into irrelevance, and it can be hard to get back up to speed, even though you understand the fundamentals completely, and the underlying logic of <em>how</em> to write code hasn’t changed at all. It’s like knowing how to be an electrician but suddenly you have to do all your work in French, and you don’t speak French.</p>
<p>This is the kind of problem that LLMs are really good at helping with. Before I had this kind of coding assistant, I couldn’t do any meaningful projects within the limited amount of free time that I have available on nights and weekends to build things. Now, with the assistance of contemporary tools, I can get help with things like routine boilerplate code and obscure syntax, speeding up my work enough to focus on the fun, creative parts of coding that I love.</p>
<p>Even professional coders who <em>are</em> up to date on the latest technologies use these LLM tools to do things like creating scripts, which are essentially small bits of code used to automate or process common tasks. This kind of code is disposable, meaning it may only ever be run once, and it’s not exposed to the internet, so security or privacy concerns aren’t usually much of an issue. In that context, having the LLM create a utility for you can feel like being truly liberated from grunt work, something like having a robot vacuum around to sweep up the floor.</p>
<h2>Surfing towards serfdom</h2>
<p>This all sounds pretty good, right? It certainly helps explain why so many in the tech world tend to see AI much more positively than almost everyone else does; there’s a clear-cut example of people finding value from these tools in a way that feels empowering or even freeing.</p>
<p>But there are far darker sides to this use of AI. Let me put aside the threats and risks of AI that are true of <em>all</em> uses of the Big AI platforms, like the environmental impact, the training on content without consent, the psychological manipulation of users, the undermining of legal regulations, and other significant harms. These are all real, and profound, but I want to focus on what’s specific to using AI to help write code here, because there are negative externalities that are unique to <em>this</em> context that people haven’t discussed enough. (For more on the larger AI discussion, see "<a href="https://www.anildash.com/2025/05/01/what-would-good-ai-look-like/">What would good AI look like?</a>")</p>
<p>The first problem raised by vibe coding is an obvious one: the major tech investors focused on making AI good at writing code because they wanted to make coders less powerful and reduce their pay. If you go back a decade ago, nearly everyone in the world was saying “teach your kids to code” and being a software engineer was one of the highest paying, most powerful individual jobs in the history of labor. Pretty soon, coders were acting like it — using their power to improve workplace conditions for those around them at the major tech companies, and pushing their employers to be more socially responsible. Once workers began organizing in this way, the tech tycoons who founded the big tech companies, and the board members and venture capitalists who backed them, immediately began investing billions of dollars in building these technologies that would devalue the labor of millions of coders around the world.</p>
<p>It worked. More than <em>half a million</em> tech workers have been laid off in America since ChatGPT was released in November 2022.</p>
<p>That’s <em>just</em> in the private sector, and <em>just</em> the ones tracked by <a href="https://layoffs.fyi">layoffs.fyi</a>. Software engineering job listings have <a href="https://blog.pragmaticengineer.com/software-engineer-jobs-five-year-low/">plummeted to a 5-year low</a>. This is during a period of time that nobody even describes as a recession. The same venture capitalists who funded the AI boom keep insisting that these trends are about macroeconomic abstractions like interest rates, a stark contrast to their rhetoric the rest of the time, when they insist that they are alpha males who make their own decisions based on their strong convictions and brave stances against woke culture. It is, in fact, the case that they are just greedy people who invested a ton of money into trying to put a lot of good people out of work, and they succeeded in doing so.</p>
<p>There is no reason why AI tools like this <em>couldn't</em> be used in the way that they're often described, where they increase productivity and enable workers to do more and generate more value. But instead we have the wealthiest people in the world telling the wealthiest companies in the world, while they generate record profits, to lay off workers who could be creating cool things for customers, and then blaming it on everyone but themselves.</p>
<h2>The past as prison</h2>
<p>Then there’s the second problem raised by vibe coding: You can’t make anything truly radical with it. By definition, LLMs are trained on what has come before. In addition to being already-discovered territory, existing code is buggy and broken and sloppy and, as anyone who has ever written code knows, absolutely embarrassing to look at. Worse, many of the people who are using vibe coding tools are increasingly those who <em>don’t</em> understand the code that is being generated by these systems. This means the people generating all of this newly-vibed code won’t even know when the output is insecure, or will perform poorly, or includes exploits that let others take over their system, or when it is simply incoherent nonsense that <em>looks</em> like code but doesn’t do anything.</p>
<p>All of those factors combine to encourage people to think of vibe coding tools as a sort of “black box” that just spits out an app <em>for</em> you. Even the giant tech companies are starting to encourage this mindset, tacitly endorsing the idea that people don’t need to know what their systems are doing under the hood. But obviously, somebody needs to know whether a system is <em>actually</em> secure. Somebody needs to know if a system is actually doing the tasks it says that it’s doing. The Big AI companies that make the most popular LLMs on the market today routinely design their products to induce emotional dependency in users by giving them positive feedback and encouragement, even when that requires generating false responses. Put more simply: they make the bot lie to you to make you feel good so you use the AI more. That’s terrible in a million ways, but one of them is that it sure does generate some bad code.</p>
<p>And a vibe coding tool absolutely won’t make something truly <em>new</em>. The most radical, disruptive, interesting, surprising, weird, fun innovations in technology have happened because people with a strange compulsion to do something cool had enough knowledge to get their code out into the world. The World Wide Web itself was <em>not</em> a huge technological leap over what came before — it took off because of a huge leap in <em>insight</em> into human nature and human behavior, that happened to be captured in code. The actual bits and bytes? They were mostly just plain text, much of which was in formats that had already been around for many years prior to Tim Berners-Lee assembling it all into the first web browser. That kind of surprising innovation could probably never be vibe coded, even though all of the raw materials might be scooped up by an LLM, because even if the human writing the prompt had that counterintuitive stroke of genius, the system would still be hemmed in by the constraints of the works it had been trained on. The past is a prison when you’re inventing the future.</p>
<p>What’s more, if you were going to use a vibe coding tool to make a truly radical new technology, do you think today’s Big AI companies would let their systems create that app? The same companies that made a platform that just put hundreds of thousands of coders out of work? The same companies that make a platform that tells your kids to end their own lives? The same companies whose cronies in the White House are saying there should <em>never be any laws</em> reining them in? Those folks are going to help you make new tech that threatens to disrupt their power? I don’t think so.</p>
<h2>Putting power in people’s hands</h2>
<p>I’m deeply torn about what the future of LLMs for coding should be. I’ve spent decades of my life trying to make it easier for everyone to make software. I’ve seen, firsthand, the power of using AI tools to help coders — especially those new to coding — build their confidence in being able to create something new. I love that potential, and in many ways, it’s the most positive and optimistic possibility around LLMs that I’ve seen. It’s the thing that makes me think that maybe there is a part of all the AI hype that is not pure bullshit. Especially if we can find a version of these tools that’s genuinely open source and free and has been trained on people’s code with their consent and cooperation, perhaps in collaboration with some educational institutions, I’d be delighted to see that shared with the world in a thoughtful way.</p>
<p>But I also have seen the majority of the working coders I know (and the <em>non</em>-working coders I know, including myself) rush to integrate the commercial coding assistants from the Big AI companies into their workflow without necessarily giving proper consideration to the long-term implications of that choice. What happens when we’ve developed our dependencies on that assistance? How will people introduce <em>new</em> technologies like new programming languages and frameworks if we all consider the LLMs to be the canonical way of writing our code, and the training models don’t know the new tech exists? How does our imagination shrink when we consider our options of what we create with code to be choosing between the outputs of the LLM rather than starting from the blank slate of our imagination? How will we build the next generation of coders skilled enough to catch the glaring errors that LLMs create in their code?</p>
<p>There’s never been this stark a contrast between the negatives and positives of a new technology being so tightly coupled before when it comes to enabling developers. Generally change comes to coders incrementally. Historically, there was always a (wonderful!) default skepticism to coding culture, where anything that reeked of marketing or hype was looked at with a huge amount of doubt until there was a significant amount of proof to back it up.</p>
<p>But in recent years, as with everything else, the culture wars have come for tech. There’s now a cohort in the coding world that has adopted a cult of personality around a handful of big tech tycoons despite the fact that these men are deeply corrosive to society. Or perhaps <em>because</em> they are. As a result, there’s a built-in constituency for any new AI tool, regardless of its negative externalities, which gives them a sense of momentum even where there may not be any.</p>
<p>It’s worth us examining what’s really going on, and articulating explicitly what we’re trying to enable. Who are we trying to empower? What does success look like? What do we want people to be able to build? What do we <em>not</em> want people to be able to make? What price is too high to pay? What convenience is not worth the cost?</p>
<h2>What tools do we choose?</h2>
<p>I do, still, believe deeply in the power of technology to empower people. I believe firmly that you have to understand how to create technology if you want to understand how to control it. And I still believe that we have to democratize the power to create and control technology to as many people as possible so that technology can be something people can use as a tool, rather than something that happens _to_them.</p>
<p>We are now in a complex phase, though, where the promise of democratizing access to creating technology is suddenly fraught in a way that it has never been before. The answer can’t possibly be that technology remains inaccessible and difficult for those outside of a privileged class, and easy for those who are already comfortable in the existing power structure.</p>
<p>A lot is still very uncertain, but I come back to one key question that helps me frame the discussion of what’s next: What’s the most radical app that we could build? And which tools will enable me to build it? Even if all we can do is start having a more complicated conversation about what we’re doing when we’re vibe coding, we’ll be making progress towards a more empowered future.</p>
