---
author: Cathy Gellis
cover_image: >-
  https://www.techdirt.com/wp-content/themes/techdirt/assets/images/td-rect-logo-white.png
date: '2025-12-01T18:39:46.150Z'
dateFolder: 2025/12/01
description: >-
  Below is the brief, in Cox Communications v. Sony Music Entertainment, I have
  been waiting my career to write, to finally tell the Supreme Court that when
  it comes to platform liability for their u…
isBasedOn: >-
  https://www.techdirt.com/2025/09/05/something-good-the-supreme-court-could-do-finally-fix-the-first-amendment-problems-with-platform-liability-for-copyright-infringement/
link: >-
  https://www.techdirt.com/2025/09/05/something-good-the-supreme-court-could-do-finally-fix-the-first-amendment-problems-with-platform-liability-for-copyright-infringement/
slug: >-
  2025-12-01-httpswwwtechdirtcom20250905something-good-the-supreme-court-could-do-finally-fix-the-first-amendment-problems-with-platform-liability-for-copyright-infringement
tags:
  - the web
  - free speech
  - law and order
title: >-
  Something Good The Supreme Court Could Do: Finally Fix The First Amendment
  Problems With Platform Liability For Copyright Infringement
---
<h3>from the <i>modest-ask</i> dept</h3>
<p>Below is the brief, in <a href="https://www.supremecourt.gov/search.aspx?filename=/docket/docketfiles/html/public/24-171.html"><i>Cox Communications v. Sony Music Entertainment</i></a>, I have been waiting my <a href="https://www.techdirt.com/2024/11/15/jawboning-in-plain-sight-the-unconstitutional-censorship-tolerated-by-the-dmca/">career</a> to write, to finally tell the Supreme Court that when it comes to platform liability for their users’ alleged copyright infringement, we’ve been doing it wrong.</p>
<p>While I’ve already had a chance to tell the Supreme Court that <a href="https://www.techdirt.com/2023/05/26/the-supreme-court-may-have-not-read-our-brief-about-the-first-amendment-and-copyright-but-you-can/">copyright and the First Amendment have to play nice together</a>, and that <a href="https://www.techdirt.com/2023/01/19/dear-supreme-court-judicial-curtailing-of-section-230-will-make-the-internet-worse/">liability protection for platforms is important if any are going to be able to facilitate online expression</a>, this brief finally brought those two ideas together before this Court. And not a moment too soon, because there have been issues with platform liability and the First Amendment in the copyright context for some time. The notice-and-takedown regime of the DMCA, for instance, has <a href="https://www.techdirt.com/2010/04/06/why-the-dmca-is-an-unconstitutional-restriction-on-free-speech/">long had significant prior restraint problems</a>, where expression ends up being punished before there’s ever been any sort of judicial finding that such punishment is warranted (and all too often there isn’t).</p>
<p>And the problems have only gotten worse, particularly in the wake of another recent case involving the same platform defendant this case involves. In that earlier case of <a href="https://www.techdirt.com/2018/08/24/recognizing-it-had-no-chance-cox-settles-bmg-copyright-trolling-case/"><i>BMG v. Cox</i></a> from a few years ago, the protective value of the DMCA was dramatically weakened when Cox was found to have lost its safe harbor protection by not terminating its users quickly enough, and based solely on the accusation that they were infringing, without there ever being a judicial finding warranting that extreme sanction either—a sanction that the Supreme Court in <a href="https://www.supremecourt.gov/opinions/16pdf/15-1194_08l1.pdf">Packingham</a> suggested was too extreme even for child sex abusers, that arguably the language of the DMCA itself does not require, and that exacerbates the prior restraint problem by being an extrajudicial punitive consequence for expression that directly and purposefully prevents future expression.</p>
<p>As a result, here we are, with broadband providers like Cox Communications drowning in takedown demands (which, by the way, aren’t even supposed to be a thing for their sort of conduit platform, because there’s nothing to take down!) and forced to refuse speakers and speech, even though the reason for providing platforms with safe harbor protection in the first place was to make sure that platforms could be in the business of facilitating the online expression it now must refuse.</p>
<p>That <i>BMG</i> case settled a few years ago, but that closure did not end Cox’s troubles. Soon Sony also sued it under a similar legal theory: that Cox was contributorily and willfully liable for the infringement their users allegedly committed because Cox didn’t do enough to terminate accused users. And that case has now found its way to the Supreme Court, which for the first time since the <a href="https://scholar.google.com/scholar_case?case=8647956476676426155&amp;q=grokster&amp;hl=en&amp;as_sdt=2006"><i>Grokster</i></a> decision nearly twenty years ago will consider how secondary liability for copyright infringement plays out in the Internet platform space.</p>
<p>But this time when it considers these questions the Court will have a fresh, new decision to help guide its analysis: <a href="https://www.techdirt.com/2024/05/31/unanimous-scotus-to-states-no-strong-arming-third-parties-to-silence-critics/"><i>NRA v. Vullo</i></a>. This <i>Vullo</i> case was not an Internet case – it was about whether an insurance regulator could stick it to the NRA, whose speech she didn’t like, by going after the insurance companies she regulated if they continued to do business with the NRA. Nope, said the unanimous Court last year, you don’t get to go after a speaker you don’t like by pressuring a middleman.</p>
<p>And yet, with platform liability, that’s exactly what happens every time there’s any sort of law requiring platforms to do anything with respect to users and their expression, including share liability for it. It is what we are seeing with the DMCA, where in order <em>not</em> to be liable for its users’ alleged wrongful use of the communications medium Cox provides, Cox was effectively forced to take hostile action against its users and terminate them, based on nothing more than a mere accusation of wrongfulness and not any sort of judicial finding.</p>
<p>It’s an arrangement that violates the First Amendment rights of everyone: the users, and even the platforms themselves, which the Court has also acknowledged exist last year in the <a href="https://scholar.google.com/scholar_case?case=12448501308638983685&amp;q=moody+v+netchoice+llc&amp;hl=en&amp;as_sdt=2006"><i>Moody v. NetChoice</i></a> case. And so, with this brief, we finally got a chance to tell the Court there is this significant Constitutional problem, not just because it is a problem here, in this copyright context, but also because if this sort of liability model is allowed in the copyright space, it is unlikely to stay limited to the copyright space. Regulating online speech by squeezing the platforms facilitating it has become the go-to strategy for far too many regulators. With this case, however, maybe the Supreme Court can finally tell them to stop, because, as the Copia Institute explained in its brief, it’s just not something the Constitution allows.</p>
<figure><p class="rw-outer-content"><span>Some content could not be imported from the original document.</span> <a href="https://embed.documentcloud.org/documents/26084991-24-171-brief-of-amicus/?embed=1">View content ↗ </a></p></figure>
