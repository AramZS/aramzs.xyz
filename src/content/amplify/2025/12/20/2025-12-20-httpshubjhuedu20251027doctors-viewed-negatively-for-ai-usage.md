---
author: Maggie Ward
cover_image: >-
  https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1300/public/2025-10/GettyImages-2217159727.jpg
date: '2025-12-20T17:30:28.459Z'
dateFolder: 2025/12/20
description: >-
  Hopkins researchers find that despite pressure on clinicians to be early
  adopters of AI, many face skepticism from peers for using it
isBasedOn: 'https://hub.jhu.edu/2025/10/27/doctors-viewed-negatively-for-ai-usage/'
link: 'https://hub.jhu.edu/2025/10/27/doctors-viewed-negatively-for-ai-usage/'
slug: 2025-12-20-httpshubjhuedu20251027doctors-viewed-negatively-for-ai-usage
tags:
  - ai
  - healthcare
title: 'Doctors who use AI viewed negatively by their peers, study shows'
---
<figure><img alt="A group of medical professionals walk down a hallway. Their faces are not visible." sizes="(min-width: 1680px) 1440px, (min-width: 1280px) 1194px, (min-width: 1024px) 1062px, (min-width: 863px) 850px, (min-width: 768px) 863px, (min-width: 640px) 768px, (min-width: 412px) 640px, (min-width: 375px) 412px, 375px" src="https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2880/public/2025-10/GettyImages-2217159722.jpg" srcset="https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_medium/public/2025-10/GettyImages-2217159722.jpg 420w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_630/public/2025-10/GettyImages-2217159722.jpg 630w, https://api.hub.jhu.edu/factory/sites/default/files/styles/full_width/public/2025-10/GettyImages-2217159722.jpg 825w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1030/public/2025-10/GettyImages-2217159722.jpg 1030w, https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_large/public/2025-10/GettyImages-2217159722.jpg 1194w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1300/public/2025-10/GettyImages-2217159722.jpg 1300w, https://api.hub.jhu.edu/factory/sites/default/files/styles/hub_xlarge/public/2025-10/GettyImages-2217159722.jpg 1440w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1600/public/2025-10/GettyImages-2217159722.jpg 1600w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_1800/public/2025-10/GettyImages-2217159722.jpg 1800w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2000/public/2025-10/GettyImages-2217159722.jpg 2000w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2400/public/2025-10/GettyImages-2217159722.jpg 2400w, https://api.hub.jhu.edu/factory/sites/default/files/styles/soft_crop_2880/public/2025-10/GettyImages-2217159722.jpg 2880w"/><figcaption>A group of medical professionals walk down a hallway. Their faces are not visible.</figcaption></figure>
<h2>Johns Hopkins researchers find that despite pressure on clinicians to be early adopters of AI, many face skepticism from peers for using it</h2>
<p>Doctors who use artificial intelligence at work risk having their colleagues deem them less competent for it, according to a recent Johns Hopkins University study.</p>
<p>While generative AI holds significant promise for advancing health care, a new study finds its use in medical decision-making impacts how physicians are perceived by their colleagues. The research shows that doctors who primarily rely on generative AI for decision-making face considerable skepticism from fellow clinicians, who correlate their use of AI with a lack of clinical skill and overall competence, resulting in a diminished perceived quality of patient care.</p>
<p><a href="https://research.jhu.edu/major-initiatives/discovery-awards/2022-awardees/#:~:text=Purposeful%20Design">Funded by a 2022 Johns Hopkins Discovery Award</a>, the research included a diverse group of clinicians from a major hospital system, involving attending physicians, residents, fellows, and advanced practice providers. Results of the study were published in August in [<em>Nature Digital Medicine</em>](Nature Digital Medicine).</p>
<h3>Stigma stunts better care</h3>
<p>The findings may indicate a social barrier to AI adoption in health care settings, which could slow advances that might improve patient care.</p>
<p>"AI is already unmistakably part of medicine," says <a href="https://carey.jhu.edu/faculty/faculty-directory/tinglong-dai-phd">Tinglong Dai</a>, professor of business at the <a href="https://carey.jhu.edu/">Johns Hopkins Carey Business School</a> and co-corresponding author of the study. "What surprised us is that doctors who use it in making medical decisions can be perceived by their peers as less capable. That kind of stigma, not the technology itself, may be an obstacle to better care."</p>
<p>The study, conducted by researchers at Johns Hopkins University, involved a randomized experiment where 276 practicing clinicians evaluated different scenarios: a physician using no AI, one using AI as a primary decision-making tool, and another using it for verification. The research found that as physicians were more dependent on AI, they faced an increasing "competence penalty," meaning they were viewed more skeptically by their peers than those physicians who did not rely on AI.</p>
<p>"In the age of AI, human psychology remains the ultimate variable," says <a href="https://carey.jhu.edu/faculty/faculty-directory/haiyang-yang-phd">Haiyang Yang</a>, first author of the study and academic program director of the Masters of Science in Management program at the Carey Business School. "The way people perceive AI use can matter just as much as, or even more than, the performance of the technology itself."</p>
<h3>Skipping AI equaled more respect</h3>
<p>According to the study, peer perception suffers for doctors who rely on AI. Framing generative AI as a "second opinion" or a verification tool partially improved negative perceptions from peers, but it did not fully eliminate them. Not using GenAI, however, resulted in the most favorable peer perceptions.</p>
<p>The findings align with theories that suggest perceived dependence on an external source like AI can be seen as a weakness by clinicians.</p>
<p>"As AI becomes part of the future of medicine, it's important to recognize its potential to complement—not replace—clinical judgment, ultimately strengthening decision making and improving patient care."</p>
<p>Ironically, while GenAI's visible use can undermine a physician's perceived clinical expertise among peers, the study also found that clinicians still recognize AI as a beneficial tool for enhancing precision in clinical assessment. The research showed that clinicians still generally acknowledge the value of GenAI for improving the accuracy of clinical assessments, and they view institutionally customized GenAI as even more useful.</p>
<p>The collaborative nature of the study led to thoughtful suggestions for GenAI implementation in health care settings, which are crucial to balance innovation with maintaining professional trust and physician reputation, the researchers note.</p>
<p>"Physicians place a high value on clinical expertise, and as AI becomes part of the future of medicine, it's important to recognize its potential to complement—not replace—clinical judgment, ultimately strengthening decision making and improving patient care," said <a href="https://carey.jhu.edu/faculty/risa-michelle-wolf-md">Risa Wolf</a>, co-corresponding author of the research and associate professor of pediatric endocrinology at Johns Hopkins School of Medicine with a joint appointment at the Carey Business School.</p>
