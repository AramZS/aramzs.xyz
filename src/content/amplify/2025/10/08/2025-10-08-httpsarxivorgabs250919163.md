---
author: 'Chantal Shaib, Tuhin Chakrabarty, Diego Garcia-Olano, Byron C. Wallace'
cover_image: 'https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png'
date: '2025-10-08T20:12:08.991Z'
dateFolder: 2025/10/08
description: >-
  AI "slop" is an increasingly popular term used to describe low-quality
  AI-generated text, but there is currently no agreed upon definition of this
  term nor a means to measure its occurrence. In this work, we develop a
  taxonomy of "slop" through interviews with experts in NLP, writing, and
  philosophy, and propose a set of interpretable dimensions for its assessment
  in text. Through span-level annotation, we find that binary "slop" judgments
  are (somewhat) subjective, but such determinations nonetheless correlate with
  latent dimensions such as coherence and relevance. Our framework can be used
  to evaluate AI-generated text in both detection and binary preference tasks,
  potentially offering new insights into the linguistic and stylistic factors
  that contribute to quality judgments.
isBasedOn: 'https://arxiv.org/abs/2509.19163'
link: 'https://arxiv.org/abs/2509.19163'
slug: 2025-10-08-httpsarxivorgabs250919163
tags:
  - ai
title: Measuring AI "Slop" in Text
---
<p>[Submitted on 23 Sep 2025]</p>
<p>Authors:<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shaib,+C">Chantal Shaib</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chakrabarty,+T">Tuhin Chakrabarty</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Garcia-Olano,+D">Diego Garcia-Olano</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wallace,+B+C">Byron C. Wallace</a></p>
<p>View a PDF of the paper titled Measuring AI "Slop" in Text, by Chantal Shaib and 3 other authors</p>
<p><a href="https://arxiv.org/pdf/2509.19163">View PDF</a> <a href="https://arxiv.org/html/2509.19163v1">HTML (experimental)</a></p>
<blockquote> Abstract:AI "slop" is an increasingly popular term used to describe low-quality AI-generated text, but there is currently no agreed upon definition of this term nor a means to measure its occurrence. In this work, we develop a taxonomy of "slop" through interviews with experts in NLP, writing, and philosophy, and propose a set of interpretable dimensions for its assessment in text. Through span-level annotation, we find that binary "slop" judgments are (somewhat) subjective, but such determinations nonetheless correlate with latent dimensions such as coherence and relevance. Our framework can be used to evaluate AI-generated text in both detection and binary preference tasks, potentially offering new insights into the linguistic and stylistic factors that contribute to quality judgments. </blockquote>
<table><tbody><tr> <td>Subjects:</td> <td> Computation and Language (cs.CL)</td> </tr><tr> <td>Cite as:</td> <td><a href="https://arxiv.org/abs/2509.19163">arXiv:2509.19163</a> [cs.CL]</td> </tr> <tr> <td></td> <td>(or  <a href="https://arxiv.org/abs/2509.19163v1">arXiv:2509.19163v1</a> [cs.CL] for this version) </td> </tr> <tr> <td></td> <td> <a href="https://doi.org/10.48550/arXiv.2509.19163">https://doi.org/10.48550/arXiv.2509.19163</a>    arXiv-issued DOI via DataCite (pending registration)<br/> </td> </tr></tbody></table>
