---
author: 'Ismail Alihan Hadimlioglu, Siddharth Linga'
cover_image: 'https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png'
date: '2025-10-02T15:19:33.564Z'
dateFolder: 2025/10/02
description: >-
  This paper presents Face2Feel, a novel user interface (UI) model that
  dynamically adapts to user emotions and preferences captured through computer
  vision. This adaptive UI framework addresses the limitations of traditional
  static interfaces by integrating digital image processing, face recognition,
  and emotion detection techniques. Face2Feel analyzes user expressions
  utilizing a webcam or pre-installed camera as the primary data source to
  personalize the UI in real-time. Although dynamically changing user interfaces
  based on emotional states are not yet widely implemented, their advantages and
  the demand for such systems are evident. This research contributes to the
  development of emotion-aware applications, particularly in recommendation
  systems and feedback mechanisms. A case study, "Shresta: Emotion-Based Book
  Recommendation System," demonstrates the practical implementation of this
  framework, the technologies employed, and the system's usefulness.
  Furthermore, a user survey conducted after presenting the working model
  reveals a strong demand for such adaptive interfaces, emphasizing the
  importance of user satisfaction and comfort in human-computer interaction. The
  results showed that nearly 85.7\% of the users found these systems to be very
  engaging and user-friendly. This study underscores the potential for
  emotion-driven UI adaptation to improve user experiences across various
  applications.
isBasedOn: 'https://arxiv.org/abs/2510.00489'
link: 'https://arxiv.org/abs/2510.00489'
slug: 2025-10-02-httpsarxivorgabs251000489
tags:
  - privacy
  - science
title: 'Face2Feel: Emotion-Aware Adaptive User Interface'
---
<p>[Submitted on 1 Oct 2025]</p>
<p>Authors:<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hadimlioglu,+I+A">Ismail Alihan Hadimlioglu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Linga,+S">Siddharth Linga</a></p>
<p>View a PDF of the paper titled Face2Feel: Emotion-Aware Adaptive User Interface, by Ismail Alihan Hadimlioglu and Siddharth Linga</p>
<p><a href="https://arxiv.org/pdf/2510.00489">View PDF</a> <a href="https://arxiv.org/html/2510.00489v1">HTML (experimental)</a></p>
<blockquote> Abstract:This paper presents Face2Feel, a novel user interface (UI) model that dynamically adapts to user emotions and preferences captured through computer vision. This adaptive UI framework addresses the limitations of traditional static interfaces by integrating digital image processing, face recognition, and emotion detection techniques. Face2Feel analyzes user expressions utilizing a webcam or pre-installed camera as the primary data source to personalize the UI in real-time. Although dynamically changing user interfaces based on emotional states are not yet widely implemented, their advantages and the demand for such systems are evident. This research contributes to the development of emotion-aware applications, particularly in recommendation systems and feedback mechanisms. A case study, "Shresta: Emotion-Based Book Recommendation System," demonstrates the practical implementation of this framework, the technologies employed, and the system's usefulness. Furthermore, a user survey conducted after presenting the working model reveals a strong demand for such adaptive interfaces, emphasizing the importance of user satisfaction and comfort in human-computer interaction. The results showed that nearly 85.7\% of the users found these systems to be very engaging and user-friendly. This study underscores the potential for emotion-driven UI adaptation to improve user experiences across various applications. </blockquote>
<table> <tbody><tr> <td>Comments:</td> <td>8 pages, 8 figures</td> </tr> <tr> <td>Subjects:</td> <td> Human-Computer Interaction (cs.HC)</td> </tr><tr> <td>Cite as:</td> <td><a href="https://arxiv.org/abs/2510.00489">arXiv:2510.00489</a> [cs.HC]</td> </tr> <tr> <td></td> <td>(or  <a href="https://arxiv.org/abs/2510.00489v1">arXiv:2510.00489v1</a> [cs.HC] for this version) </td> </tr> <tr> <td></td> <td> <a href="https://doi.org/10.48550/arXiv.2510.00489">https://doi.org/10.48550/arXiv.2510.00489</a>    arXiv-issued DOI via DataCite (pending registration)<br/> </td> </tr></tbody></table>
