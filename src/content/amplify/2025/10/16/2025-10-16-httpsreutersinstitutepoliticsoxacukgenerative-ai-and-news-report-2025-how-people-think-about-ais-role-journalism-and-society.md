---
author: Blue Print
cover_image: >-
  https://reutersinstitute.politics.ox.ac.uk/sites/default/files/styles/feature_box/public/2025-10/untitled_design_4_0.jpg.jpeg?itok=GGMUF6UY
date: '2025-10-16T04:23:51.068Z'
dateFolder: 2025/10/16
description: >-
  Our survey in six countries (Argentina, Denmark, France, Japan, the UK, and
  the US) explored how people use generative AI in their everyday lives, what
  they think its impact will be on different areas of society, and what they
  think about its use in news and journalism specifically.
isBasedOn: >-
  https://reutersinstitute.politics.ox.ac.uk/generative-ai-and-news-report-2025-how-people-think-about-ais-role-journalism-and-society
link: >-
  https://reutersinstitute.politics.ox.ac.uk/generative-ai-and-news-report-2025-how-people-think-about-ais-role-journalism-and-society
slug: >-
  2025-10-16-httpsreutersinstitutepoliticsoxacukgenerative-ai-and-news-report-2025-how-people-think-about-ais-role-journalism-and-society
tags:
  - ai
  - tech
  - media
  - journalism
title: >-
  Generative AI and news report 2025: How people think about AI’s role in
  journalism and society
---
<figure><img alt="A man looks at his phone as he walks past Argentina's Central Bank in Buenos Aires" src="https://reutersinstitute.politics.ox.ac.uk/sites/default/files/2025-10/untitled_design_4.jpg"/><figcaption>A man looks at his phone as he walks past Argentina's Central Bank in Buenos Aires, December 18, 2024. REUTERS/Francisco Loureiro</figcaption></figure>
<h3>Executive summary and key findings</h3>
<p>Our survey in six countries (Argentina, Denmark, France, Japan, the UK, and the US) explored how people use generative AI in their everyday lives, what they think its impact will be on different areas of society, and what they think about its use in news and journalism specifically. It is a follow-up to the survey that we conducted in the same six countries in 2024 (Fletcher and Nielsen 2024). Based on the results of this survey, and the previous one, we find the following.</p>
<p><strong>Findings on the awareness and use of generative AI</strong></p>
<p>The public’s use of generative AI has increased substantially in the last year. The proportion who say they have ever used a standalone generative AI system such as ChatGPT jumped from 40% to 61%, and weekly usage nearly doubled from 18% to 34%. ChatGPT is the single most popular AI system with 22% weekly usage, though adoption varies significantly by age. Information-seeking has become the primary use-case for AI, more than doubling to 24% weekly usage and surpassing media creation, while specialised uses like news consumption remain limited at 6%. Trust is concentrated among major brands, with ChatGPT leading the field again, though most users remain occasional rather than regular adopters.</p>
<p>In more detail, we find:</p>
<ul> <li>Awareness has surged year-on-year. The share of people across countries who have heard of at least one of 13 AI tools rose from 78% (2024) to 90% (2025); only 10% say they have heard of none. ChatGPT remains the most well-known brand, with pronounced country variation for others.</li> <li>Use is expanding rapidly – especially weekly use – though not uniformly. Across countries, the proportion of people who say they have ever used any AI system rose from 40% (2024) to 61% (2025); weekly use nearly doubled from 18% to 34%.</li> <li>Again, ChatGPT dominates active use. On average, 22% report using ChatGPT in the last week, well ahead of other tools. Since May 2024, the core user base for every major system has roughly doubled. Yet most people are not regular users: for the four most popular systems, many use them only monthly or once or twice ever, and large shares have never used or not heard of them.</li> <li>Use of generative AI skews younger. In the 18–24 category, 59% used any generative AI in the last week, as opposed to 20% among those aged 55 and over, although this age gap is driven mainly by ChatGPT. Age differences are smaller for Google’s Gemini, and minimal for Copilot, Meta AI, and Grok – likely because they’re embedded in widely used products.</li> <li>Information-seeking is now the lead use-case across countries. Weekly use of AI for getting information more than doubled (from 11% to 24%), overtaking creating media (up 7 percentage points to 21%). Social interaction is nascent but notable (7% overall; 13% of 18–24s versus 4% of 55+).</li> <li>While specific information-retrieval tasks are broadening, with answering factual questions rising from 6% to 11%, media creation remains niche except for images. Image generation rose from 5% to 9% weekly; video (3%) and audio (2%) were basically flat; coding use was also flat, suggesting early adopters were already on board in 2024.</li> <li>Getting news via a generative AI system has doubled but remains a minority activity. Weekly use rose from 3% to 6%, driven mainly by users in Japan and Argentina; it is strongest in Argentina and the USA and among 18–24s (8%) compared to 55+ (5%), and higher for degree-holders. Among AI-for-news users, ‘latest news’ (54%) and help with summarising, evaluating, or rewriting are most common. Younger users lean more towards using AI to help them navigate the news: 48% of 18–24s used AI to make a story easier to understand compared to 27% of 55+ (a 21 percentage point gap).</li> <li>Trust is concentrated in a few brands. On average, 29% say they trust ChatGPT, ahead of Gemini (18%), Copilot (12%), and Meta AI (12%); most other brands are trusted by fewer than 10%, mostly due to low awareness. In most countries ChatGPT is more trusted than distrusted, with the exception of the UK.</li> </ul>
<p><strong>Findings on public views on AI-generated search answers</strong></p>
<p>AI-generated search answers have become commonplace in the six countries studied. User engagement with these AI answers is mixed, as only one third say they consistently click through to source links while 28% rarely or never do so, with younger users more likely to engage further.it is Trust levels are moderate at 50% among those who encounter AI answers, with users valuing their speed and information aggregation capabilities – although trust becomes conditional in high-stakes areas like health and politics, where many verify answers through traditional sources.</p>
<p>In more detail, we find:</p>
<ul> <li>People regularly see AI-generated search answers. Across countries, 54% say they saw an AI-generated answer to one of their searches in the last week. Reported weekly encounters are highest in Argentina (70%), followed by the UK (64%) and the USA (61%), and lowest in France (29%), where Google’s AI overview feature had not been rolled out at the time of fieldwork.</li> <li>Self-reported click-through behaviour is mixed. Among those who saw AI answers, about one third (33%) say they always or often click links in the overview, 37% say they do so sometimes, and 28% rarely or never click through. Younger people are more likely to say they click through, although it is important to acknowledge that self-reported behaviour may differ from actual behaviour for some respondents.</li> <li>Among those who have encountered AI answers, 50% say they trust them, with a significant minority remaining neutral. While there is little difference by gender, younger adults show slightly more outright trust. Respondents emphasised their speed and convenience and the fact that AI aggregates vast amounts of information as reasons to trust them.</li> <li>Trust in AI answers in search is conditional, especially in high-stakes domains. Many say they verify answers, especially for health or politics, treating AI as a first pass before checking non-AI sources.</li> </ul>
<p><strong>Findings on public opinion about the use of generative AI in different sectors</strong></p>
<p>The public widely perceives generative AI as already prevalent across sectors, with 41% believing it’s used ‘always or often’ on average, rising to 68% for search engines, and 51% for news media. Public sentiment toward AI’s impact is mixed but slightly optimistic regarding how AI will improve their interactions with various sectors, though this varies significantly by domain. While optimists outnumber pessimists for sectors like healthcare, science, and search engines, the reverse is true for news media, government, and especially politicians and political parties. Personal versus societal expectations diverge, with optimists outnumbering pessimists regarding individual benefits in four of six countries, but pessimists dominate when considering societal impact in three countries, including the United States, with women consistently showing lower expectations for both personal and societal benefits from AI.</p>
<p>In more detail, we find:</p>
<ul> <li>There is a widespread public perception that generative AI is already everywhere, at least to some extent – the number of respondents who believe generative AI is used always or often in different sectors is 41% on average across countries and sectors, far exceeding those who say it is used rarely or never (15%). The figure is much higher for news media (51%) and, especially, social media companies (67%) and search engine companies (68%).</li> <li>Asked how much better or worse they think different actors’ use of generative AI will make people’s experience of interacting with them, a majority of the public express a judgement, even as many answer ‘neither better nor worse’ or simply that they don’t know. On average across all countries and sectors, 29% are optimistic and 22% pessimistic.</li> <li>Generally, there are more optimists than pessimists – especially for sectors like healthcare, science, and search engines. Only three sectors see the pessimists outnumber the optimists – news media, government, and, especially, politicians and political parties.</li> <li>Compared to the average share of respondents who say they believe generative AI is used always or often in a given sector and the average share of respondents who say they believe the use of generative AI will make their experience of interacting with a given sector better, we can identify sectors that stand out – sectors where people think generative AI is particularly widely used and where many expect this will improve their experience include search and social media. Sectors where expectations are particularly low include government use and use by politicians and political parties.</li> <li>Asked if they think that generative AI will make their life better or worse, and whether it will make society better or worse, the optimists outnumber the pessimists in four of the six countries covered in terms of people’s own lives, but when it comes to society there are significantly more pessimists than optimists in three of the six countries, including the US.</li> <li>Expectations around AI also differ along socio-economic variables. Female respondents are significantly less likely to expect that generative AI will make their lives better. They are also significantly less likely to say they expect it to make society better, and more likely to expect it will make it worse.</li> </ul>
<p><strong>Findings on public opinion about the use of generative AI in journalism and news</strong></p>
<p>A significant ‘comfort gap’ exists between AI- and human-led news production, with only 12% of respondents comfortable with fully AI-generated news compared to 62% for entirely human-made content, although acceptance increases with human oversight and when humans lead with AI assistance. Public comfort aligns with perceived usage patterns, as people are most accepting of back-end applications like grammar editing and translation, while showing more resistance to front-facing uses like artificial presenters. Expectations about AI’s impact on news remain mixed, with people anticipating benefits like cheaper production and faster updates while also having concerns about reduced transparency and trustworthiness, whereas only 33% believe journalists routinely check AI outputs before publication. Despite a growing awareness of AI use in news, most people (60%) don’t yet regularly encounter audience-facing AI features, and only 19% see AI labelling daily, despite 77% consuming news daily, suggesting a disconnect between AI implementation and public visibility.</p>
<p>In more detail, we find:</p>
<ul> <li>There is a clear ‘comfort gap’ between AI- and human-led news. On average, only 12% are comfortable with news made entirely by AI; this rises to 21% with a ‘human in the loop’, 43% when a human leads with some AI help, and 62% for entirely human-made news (an increase of 4 percentage points since 2024). This gap can be found across demographics and countries.</li> <li>People continue to be most comfortable with back-end uses of AI in news. Comfort is higher for editing spelling and grammar (55%) or translation (53%), and lower for rewriting content for different audiences (30%), creating a realistic image when no photo exists (26%), and artificial presenter/authors (19%).</li> <li>More people think newsrooms use AI. The proportion of people saying journalists ‘always’ or ‘often’ use generative AI are up by at least 3 percentage points across tasks.</li> <li>People’s perceptions of where AI is used broadly align with their own preferences for where it should be used. People believe journalists most often use AI for tasks they’re most comfortable with (e.g. grammar editing: 55% are comfortable and 51% think it’s used regularly) and rarely for tasks they’re least comfortable with (artificial presenters: 19% are comfortable and 20% think it’s used regularly).</li> <li>People continue to have mixed expectations about what AI will do to news. As with last year, many assume AI will make news cheaper to produce (+39 percentage point difference between those that said more and those that said less) and more up to date (+22), but less transparent (−8) and less trustworthy (−19); views have hardened since 2024 (no decreases). People in Japan and Argentina are generally more positive about AI’s impact on news qualities, while people in the UK are more negative.</li> <li>People have limited confidence in routine human oversight of AI in news. Only 33% think journalists ‘always’ or ‘often’ check AI outputs before publishing – this is higher in Japan (42%) and Argentina (44%), and lower in the UK (25%) – with small shifts since 2024. Trust in news strongly correlates with this: 57% of those who ‘strongly trust’ news think such checks happen, as opposed to just 19% among strong distrusters.</li> <li>The public across countries expects responsible use to vary by outlet. Forty-three per cent foresee large differences in how responsible different news outlets will be in their use of AI, compared to 28% who expect small differences.</li> <li>Most people don’t yet recall seeing audience-facing AI features offered by news outlets. Sixty per cent say they do not regularly see AI features on news sites or apps. Most common are AI summaries (19%) and AI chatbots (16%).</li> <li>Seeing AI labelling on news is infrequent relative to daily news use. Only 19% see AI labels daily and 28% weekly – a low number considering that 77% say they use news daily.</li> <li>Only a minority assumes that AI is used in news without labelling. About 15% say they often or always suspect AI was used without labelling (Argentina 30%; US 17%; approximately 10% in Japan and Europe). Clear communication of AI policies remains important.</li> </ul>
<p>We also note that across most of our attitudinal measures, both concerning AI in news and AI in general, respondents in Japan and Argentina tend to be more positive and optimistic about the potential impact of generative AI than respondents in Denmark, France, the UK, and the USA.</p>
