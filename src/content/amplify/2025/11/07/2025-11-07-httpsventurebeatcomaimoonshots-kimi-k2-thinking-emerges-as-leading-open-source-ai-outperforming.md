---
author: Carl Franzen
cover_image: >-
  https://images.ctfassets.net/jdtwqhzvc2n1/1HGuj3BsedMoBgz8md53tP/b48cd315b64ffaf658892d572c61d188/cfr0z3n_fisheye_view_surreal_bold_deep_color_vibrant_high_contr_5795af91-597f-4686-8f07-ff43e6922e8c.png?w=300&q=30
date: '2025-11-07T13:47:07.879Z'
dateFolder: 2025/11/07
description: Even as concern and skepticism grows over U. S.
isBasedOn: >-
  https://venturebeat.com/ai/moonshots-kimi-k2-thinking-emerges-as-leading-open-source-ai-outperforming
link: >-
  https://venturebeat.com/ai/moonshots-kimi-k2-thinking-emerges-as-leading-open-source-ai-outperforming
slug: >-
  2025-11-07-httpsventurebeatcomaimoonshots-kimi-k2-thinking-emerges-as-leading-open-source-ai-outperforming
tags:
  - ai
title: >-
  Moonshot's Kimi K2 Thinking emerges as leading open source AI, outperforming
  GPT-5, Claude Sonnet 4.5 on key benchmarks
---
<figure><img alt="Man with moon head and toga and muscular arms typing on keyboard surrounded by monitors, blue purple tone graphic novel style AI art" data-nimg="1" sizes="50vw" src="https://venturebeat.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F1HGuj3BsedMoBgz8md53tP%2Fb48cd315b64ffaf658892d572c61d188%2Fcfr0z3n_fisheye_view_surreal_bold_deep_color_vibrant_high_contr_5795af91-597f-4686-8f07-ff43e6922e8c.png%3Fw%3D1000%26q%3D100&amp;w=3840&amp;q=75" srcset="https://venturebeat.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F1HGuj3BsedMoBgz8md53tP%2Fb48cd315b64ffaf658892d572c61d188%2Fcfr0z3n_fisheye_view_surreal_bold_deep_color_vibrant_high_contr_5795af91-597f-4686-8f07-ff43e6922e8c.png%3Fw%3D1000%26q%3D100&amp;w=384&amp;q=75%20384w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F1HGuj3BsedMoBgz8md53tP%2Fb48cd315b64ffaf658892d572c61d188%2Fcfr0z3n_fisheye_view_surreal_bold_deep_color_vibrant_high_contr_5795af91-597f-4686-8f07-ff43e6922e8c.png%3Fw%3D1000%26q%3D100&amp;w=512&amp;q=75%20512w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F1HGuj3BsedMoBgz8md53tP%2Fb48cd315b64ffaf658892d572c61d188%2Fcfr0z3n_fisheye_view_surreal_bold_deep_color_vibrant_high_contr_5795af91-597f-4686-8f07-ff43e6922e8c.png%3Fw%3D1000%26q%3D100&amp;w=640&amp;q=75%20640w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F1HGuj3BsedMoBgz8md53tP%2Fb48cd315b64ffaf658892d572c61d188%2Fcfr0z3n_fisheye_view_surreal_bold_deep_color_vibrant_high_contr_5795af91-597f-4686-8f07-ff43e6922e8c.png%3Fw%3D1000%26q%3D100&amp;w=750&amp;q=75%20750w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F1HGuj3BsedMoBgz8md53tP%2Fb48cd315b64ffaf658892d572c61d188%2Fcfr0z3n_fisheye_view_surreal_bold_deep_color_vibrant_high_contr_5795af91-597f-4686-8f07-ff43e6922e8c.png%3Fw%3D1000%26q%3D100&amp;w=828&amp;q=75%20828w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F1HGuj3BsedMoBgz8md53tP%2Fb48cd315b64ffaf658892d572c61d188%2Fcfr0z3n_fisheye_view_surreal_bold_deep_color_vibrant_high_contr_5795af91-597f-4686-8f07-ff43e6922e8c.png%3Fw%3D1000%26q%3D100&amp;w=1080&amp;q=75%201080w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F1HGuj3BsedMoBgz8md53tP%2Fb48cd315b64ffaf658892d572c61d188%2Fcfr0z3n_fisheye_view_surreal_bold_deep_color_vibrant_high_contr_5795af91-597f-4686-8f07-ff43e6922e8c.png%3Fw%3D1000%26q%3D100&amp;w=1200&amp;q=75%201200w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F1HGuj3BsedMoBgz8md53tP%2Fb48cd315b64ffaf658892d572c61d188%2Fcfr0z3n_fisheye_view_surreal_bold_deep_color_vibrant_high_contr_5795af91-597f-4686-8f07-ff43e6922e8c.png%3Fw%3D1000%26q%3D100&amp;w=1920&amp;q=75%201920w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F1HGuj3BsedMoBgz8md53tP%2Fb48cd315b64ffaf658892d572c61d188%2Fcfr0z3n_fisheye_view_surreal_bold_deep_color_vibrant_high_contr_5795af91-597f-4686-8f07-ff43e6922e8c.png%3Fw%3D1000%26q%3D100&amp;w=2048&amp;q=75%202048w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F1HGuj3BsedMoBgz8md53tP%2Fb48cd315b64ffaf658892d572c61d188%2Fcfr0z3n_fisheye_view_surreal_bold_deep_color_vibrant_high_contr_5795af91-597f-4686-8f07-ff43e6922e8c.png%3Fw%3D1000%26q%3D100&amp;w=3840&amp;q=75%203840w"/><figcaption>Man with moon head and toga and muscular arms typing on keyboard surrounded by monitors, blue purple tone graphic novel style AI art</figcaption></figure>
<p>Even as <a href="https://www.tomshardware.com/tech-industry/openai-walks-back-statement-it-wants-a-government-backstop-for-its-massive-loans-company-says-government-playing-its-part-critical-for-industrial-ai-capacity-increases">concern and skepticism</a> grows over U.S. AI startup OpenAI's buildout strategy and high spending commitments, Chinese open source AI providers are escalating their competition and one has even caught up to OpenAI's flagship, paid proprietary model GPT-5 in key third-party performance benchmarks with a new, free model.</p>
<p>The Chinese AI startup <a href="https://moonshotai.github.io/Kimi-K2/thinking.html">Moonshot AI’s new Kimi K2 Thinking model</a>, released today, has vaulted past both proprietary and open-weight competitors to claim the top position in reasoning, coding, and agentic-tool benchmarks.</p>
<p>Despite being fully open-source, the model now outperforms OpenAI’s GPT-5, Anthropic’s Claude Sonnet 4.5 (Thinking mode), and xAI's Grok-4 on several standard evaluations — an inflection point for the competitiveness of open AI systems.</p>
<p>Developers can access the model via <a href="https://platform.moonshot.ai">platform.moonshot.ai</a> and <a href="https://kimi.com">kimi.com</a>; weights and code are hosted on <a href="https://huggingface.co/moonshotai/Kimi-K2-Thinking/tree/main">Hugging Face</a>. The open release includes APIs for chat, reasoning, and multi-tool workflows.</p>
<p>Users can try out Kimi K2 Thinking directly through its own <a href="https://www.kimi.com/">ChatGPT-like website competitor</a> and on <a href="https://huggingface.co/spaces/moonshotai/Kimi-VL-A3B-Thinking">a Hugging Face space as well. </a></p>
<h3><b>Modified Standard Open Source License</b></h3>
<p>Moonshot AI has formally released Kimi K2 Thinking under a <a href="https://huggingface.co/moonshotai/Kimi-K2-Thinking/blob/main/LICENSE">Modified MIT License</a> on Hugging Face.</p>
<p>The license grants full commercial and derivative rights — meaning individual researchers and developers working on behalf of enterprise clients can access it freely and use it in commercial applications — but adds one restriction:</p>
<p><i>"If the software or any derivative product serves </i><b><i>over 100 million monthly active users or generates over $20 million USD per month in revenue,</i></b><i> the deployer must prominently display 'Kimi K2' on the product’s user interface."</i></p>
<p>For most research and enterprise applications, this clause functions as a light-touch attribution requirement while preserving the freedoms of standard MIT licensing.</p>
<p>It makes K2 Thinking one of the most permissively licensed frontier-class models currently available.</p>
<h3><b>A New Benchmark Leader</b></h3>
<p>Kimi K2 Thinking is a Mixture-of-Experts (MoE) model built around one trillion parameters, of which 32 billion activate per inference.</p>
<p>It combines long-horizon reasoning with structured tool use, executing up to 200–300 sequential tool calls without human intervention.</p>
<p>According to Moonshot’s published test results, K2 Thinking achieved:</p>
<ul><li><p><b>44.9 %</b> on <i>Humanity’s Last Exam (HLE)</i>, a state-of-the-art score;</p></li><li><p><b>60.2 %</b> on <i>BrowseComp</i>, an agentic web-search and reasoning test;</p></li><li><p><b>71.3 %</b> on <i>SWE-Bench Verified</i> and <b>83.1 %</b> on <i>LiveCodeBench v6</i>, key coding evaluations;</p></li><li><p><b>56.3 %</b> on <i>Seal-0</i>, a benchmark for real-world information retrieval.</p></li></ul>
<figure><img alt="Screenshot of Kimi K2 Thinking benchmark results" data-nimg="1" sizes="(max-width: 950px) 200vw, 100vw" src="https://venturebeat.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F2qbeTm5hCcVRfSRBpGIo31%2F33962f9b090d75dc5fe9b391832e5fec%2FScreenshot_2025-11-06_at_1.11.50%C3%A2__PM.png%3Fw%3D1000%26q%3D100&amp;w=3840&amp;q=75" srcset="https://venturebeat.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F2qbeTm5hCcVRfSRBpGIo31%2F33962f9b090d75dc5fe9b391832e5fec%2FScreenshot_2025-11-06_at_1.11.50%C3%A2__PM.png%3Fw%3D1000%26q%3D100&amp;w=640&amp;q=75%20640w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F2qbeTm5hCcVRfSRBpGIo31%2F33962f9b090d75dc5fe9b391832e5fec%2FScreenshot_2025-11-06_at_1.11.50%C3%A2__PM.png%3Fw%3D1000%26q%3D100&amp;w=750&amp;q=75%20750w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F2qbeTm5hCcVRfSRBpGIo31%2F33962f9b090d75dc5fe9b391832e5fec%2FScreenshot_2025-11-06_at_1.11.50%C3%A2__PM.png%3Fw%3D1000%26q%3D100&amp;w=828&amp;q=75%20828w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F2qbeTm5hCcVRfSRBpGIo31%2F33962f9b090d75dc5fe9b391832e5fec%2FScreenshot_2025-11-06_at_1.11.50%C3%A2__PM.png%3Fw%3D1000%26q%3D100&amp;w=1080&amp;q=75%201080w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F2qbeTm5hCcVRfSRBpGIo31%2F33962f9b090d75dc5fe9b391832e5fec%2FScreenshot_2025-11-06_at_1.11.50%C3%A2__PM.png%3Fw%3D1000%26q%3D100&amp;w=1200&amp;q=75%201200w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F2qbeTm5hCcVRfSRBpGIo31%2F33962f9b090d75dc5fe9b391832e5fec%2FScreenshot_2025-11-06_at_1.11.50%C3%A2__PM.png%3Fw%3D1000%26q%3D100&amp;w=1920&amp;q=75%201920w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F2qbeTm5hCcVRfSRBpGIo31%2F33962f9b090d75dc5fe9b391832e5fec%2FScreenshot_2025-11-06_at_1.11.50%C3%A2__PM.png%3Fw%3D1000%26q%3D100&amp;w=2048&amp;q=75%202048w,%20/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fjdtwqhzvc2n1%2F2qbeTm5hCcVRfSRBpGIo31%2F33962f9b090d75dc5fe9b391832e5fec%2FScreenshot_2025-11-06_at_1.11.50%C3%A2__PM.png%3Fw%3D1000%26q%3D100&amp;w=3840&amp;q=75%203840w"/><figcaption>Screenshot of Kimi K2 Thinking benchmark results Credit: Moonshot AI</figcaption></figure>
<p>Across these tasks, K2 Thinking consistently outperforms GPT-5’s corresponding scores and <a href="https://venturebeat.com/ai/minimax-m2-is-the-new-king-of-open-source-llms-especially-for-agentic-tool">surpasses the previous open-weight leader MiniMax-M2</a>—released just weeks earlier by Chinese rival MiniMax AI.</p>
<h3><b>Open Model Outperforms Proprietary Systems</b></h3>
<p>GPT-5 and Claude Sonnet 4.5 Thinking remain the leading proprietary “thinking” models.</p>
<p>Yet in the same benchmark suite, <b>K2 Thinking’s agentic reasoning scores exceed both</b>: for instance, on BrowseComp the open model’s 60.2 % decisively leads GPT-5’s 54.9 % and Claude 4.5’s 24.1 %.</p>
<p>K2 Thinking also edges GPT-5 in <i>GPQA Diamond</i> (85.7 % vs 84.5 %) and matches it on mathematical reasoning tasks such as <i>AIME 2025</i> and <i>HMMT 2025</i>.</p>
<p>Only in certain heavy-mode configurations—where GPT-5 aggregates multiple trajectories—does the proprietary model regain parity.</p>
<p>That Moonshot’s fully open-weight release can meet or exceed GPT-5’s scores marks a turning point. The gap between closed frontier systems and publicly available models has effectively collapsed for high-end reasoning and coding.</p>
<h3><b>Surpassing MiniMax-M2: The Previous Open-Source Benchmark</b></h3>
<p>When <a href="https://venturebeat.com/ai/minimax-m2-is-the-new-king-of-open-source-llms-especially-for-agentic-tool">VentureBeat profiled MiniMax-M2</a> just a week and a half ago, it was hailed as the “new king of open-source LLMs,” achieving top scores among open-weight systems:</p>
<ul><li><p><i>τ²-Bench 77.2</i></p></li><li><p><i>BrowseComp 44.0</i></p></li><li><p><i>FinSearchComp-global 65.5</i></p></li><li><p><i>SWE-Bench Verified 69.4</i></p></li></ul>
<p>Those results placed MiniMax-M2 near GPT-5-level capability in agentic tool use. Yet<b> Kimi K2 Thinking now eclipses them by wide margins.</b></p>
<p>Its BrowseComp result of 60.2 % exceeds M2’s 44.0 %, and its SWE-Bench Verified 71.3 % edges out M2’s 69.4 %. Even on financial-reasoning tasks such as FinSearchComp-T3 (47.4 %), K2 Thinking performs comparably while maintaining superior general-purpose reasoning.</p>
<p>Technically, both models adopt sparse Mixture-of-Experts architectures for compute efficiency, but Moonshot’s network activates more experts and deploys advanced quantization-aware training (INT4 QAT).</p>
<p>This design doubles inference speed relative to standard precision without degrading accuracy—critical for long “thinking-token” sessions reaching 256 k context windows.</p>
<h3><b>Agentic Reasoning and Tool Use</b></h3>
<p>K2 Thinking’s defining capability lies in its explicit reasoning trace. The model outputs an auxiliary field, reasoning_content, revealing intermediate logic before each final response. This transparency preserves coherence across long multi-turn tasks and multi-step tool calls.</p>
<p>A reference implementation published by Moonshot demonstrates how the model autonomously conducts a “daily news report” workflow: invoking date and web-search tools, analyzing retrieved content, and composing structured output—all while maintaining internal reasoning state.</p>
<p>This end-to-end autonomy enables the model to plan, search, execute, and synthesize evidence across hundreds of steps, mirroring the emerging class of “agentic AI” systems that operate with minimal supervision.</p>
<h3><b>Efficiency and Access</b></h3>
<p>Despite its trillion-parameter scale, K2 Thinking’s runtime cost remains modest. Moonshot lists usage at:</p>
<ul><li><p><b>$0.15 / 1 M tokens (cache hit)</b></p></li><li><p><b>$0.60 / 1 M tokens (cache miss)</b></p></li><li><p><b>$2.50 / 1 M tokens output</b></p></li></ul>
<p>These rates are competitive even against MiniMax-M2’s $0.30 input / $1.20 output pricing—and an order of magnitude below GPT-5 ($1.25 input / $10 output).</p>
<h3><b>Comparative Context: Open-Weight Acceleration</b></h3>
<p>The rapid succession of M2 and K2 Thinking illustrates how quickly open-source research is catching frontier systems. MiniMax-M2 demonstrated that open models could approach GPT-5-class agentic capability at a fraction of the compute cost. Moonshot has now advanced that frontier further, pushing open weights beyond parity into outright leadership.</p>
<p>Both models rely on sparse activation for efficiency, but K2 Thinking’s higher activation count (32 B vs 10 B active parameters) yields stronger reasoning fidelity across domains. Its test-time scaling—expanding “thinking tokens” and tool-calling turns—provides measurable performance gains without retraining, a feature not yet observed in MiniMax-M2.</p>
<h3><b>Technical Outlook</b></h3>
<p>Moonshot reports that K2 Thinking supports <b>native INT4 inference</b> and <b>256 k-token contexts</b> with minimal performance degradation. Its architecture integrates quantization, parallel trajectory aggregation (“heavy mode”), and Mixture-of-Experts routing tuned for reasoning tasks.</p>
<p>In practice, these optimizations allow K2 Thinking to sustain complex planning loops—code compile–test–fix, search–analyze–summarize—over hundreds of tool calls. This capability underpins its superior results on BrowseComp and SWE-Bench, where reasoning continuity is decisive.</p>
<h3><b>Enormous Implications for the AI Ecosystem</b></h3>
<p>The convergence of open and closed models at the high end signals a structural shift in the AI landscape. Enterprises that once relied exclusively on proprietary APIs can now deploy open alternatives matching GPT-5-level reasoning while retaining full control of weights, data, and compliance.</p>
<p>Moonshot’s open publication strategy follows the precedent set by DeepSeek R1, Qwen3, GLM-4.6 and MiniMax-M2 but extends it to full agentic reasoning.</p>
<p>For academic and enterprise developers, K2 Thinking provides both transparency and interoperability—the ability to inspect reasoning traces and fine-tune performance for domain-specific agents.</p>
<p>The arrival of K2 Thinking signals that Moonshot — a <a href="https://techcrunch.com/2024/02/21/moonshot-ai-funding-china/">young startup founded in 2023</a> with investment from some of China's biggest apps and tech companies — is here to play in an intensifying competition, and comes amid growing scrutiny of the financial sustainability of AI’s largest players.</p>
<p>Just a day ago, OpenAI CFO Sarah Friar sparked controversy after <a href="https://www.wsj.com/tech/ai/openai-isnt-yet-working-toward-an-ipo-cfo-says-58037472?gaa_at=eafs&amp;gaa_n=AWEtsqfPSJ91IQIG678OHyyBAwXqBLDfUb01-yZGSGU-uiYZq5Oudu3hFs6HuIdk-2A%3D&amp;gaa_ts=690cdeaf&amp;gaa_sig=vcfYpYv-Y0bP8WOkElUbVMCF-MAssgO9v2J34nzp5c7Mr0hs2x6WddR6gK12PW2xhfZiNCQrUUQCrRizxbFkMA%3D%3D">suggesting at WSJ Tech Live</a> event that the U.S. government might eventually need to provide a “backstop” for the company’s more than $1.4 trillion in compute and data-center commitments — a comment widely interpreted as a call for taxpayer-backed loan guarantees.</p>
<p>Although <a href="https://www.cnbc.com/2025/11/06/openai-cfo-sarah-friar-says-company-is-not-seeking-government-backstop.html">Friar later clarified that OpenAI</a> was not seeking direct federal support, the episode reignited debate about the scale and concentration of AI capital spending.</p>
<p>With OpenAI, Microsoft, Meta, and Google all racing to secure long-term chip supply, critics warn of an unsustainable investment bubble and “AI arms race” driven more by strategic fear than commercial returns — one that could "blow up" and take down the entire global economy with it if there is hesitation or market uncertainty, as so many trades and valuations have now been made in anticipation of continued hefty AI investment and massive returns.</p>
<p>Against that backdrop, Moonshot AI’s and MiniMax’s open-weight releases put more pressure on U.S. proprietary AI firms and their backers to justify the size of the investments and paths to profitability.</p>
<p>If an enterprise customer can just as easily get comparable or better performance from a free, open source Chinese AI model than they do with paid, proprietary AI solutions like OpenAI's GPT-5, Anthropic's Claude Sonnet 4.5, or Google's Gemini 2.5 Pro — why would they continue paying to access the proprietary models? Already, Silicon Valley stalwarts like Airbnb have raised eyebrows for admitting to heavily <a href="https://www.scmp.com/tech/tech-trends/article/3329921/airbnb-picks-alibabas-qwen-over-chatgpt-win-chinese-open-source-ai">using Chinese open source alternatives like Alibaba's Qwen over OpenAI's proprietary offerings</a>.</p>
<p>For investors and enterprises, these developments suggest that high-end AI capability is no longer synonymous with high-end capital expenditure. The most advanced reasoning systems may now come not from companies building gigascale data centers, but from research groups optimizing architectures and quantization for efficiency.</p>
<p>In that sense, K2 Thinking’s benchmark dominance is not just a technical milestone—it’s a strategic one, arriving at a moment when the AI market’s biggest question has shifted from <i>how powerful models can become</i> to <i>who can afford to sustain them</i>.</p>
<h3><b>What It Means for Enterprises Going Forward</b></h3>
<p>Within weeks of MiniMax-M2’s ascent, Kimi K2 Thinking has overtaken it—along with GPT-5 and Claude 4.5—across nearly every reasoning and agentic benchmark.</p>
<p>The model demonstrates that open-weight systems can <b>now meet or surpass proprietary frontier models</b> in both capability and efficiency.</p>
<p>For the AI research community, K2 Thinking represents more than another open model: it is evidence that the frontier has become collaborative.</p>
<p>The best-performing reasoning model available today is not a closed commercial product but an open-source system accessible to anyone.</p>
