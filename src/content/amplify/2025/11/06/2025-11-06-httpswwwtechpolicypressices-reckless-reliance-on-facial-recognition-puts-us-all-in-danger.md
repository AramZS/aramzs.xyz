---
author: Jake Laperruque
cover_image: >-
  https://cdn.sanity.io/images/3tzzh18d/production/2912a5a41655a980eb7df8ba207a388abf6b5d61-1200x675.png
date: '2025-11-06T13:49:00.916Z'
dateFolder: 2025/11/06
description: >-
  Jake Laperruque raises the alarm on ICE’s reckless use of facial recognition
  and its risks for wrongful detainment.
isBasedOn: >-
  https://www.techpolicy.press/ices-reckless-reliance-on-facial-recognition-puts-us-all-in-danger/
link: >-
  https://www.techpolicy.press/ices-reckless-reliance-on-facial-recognition-puts-us-all-in-danger/
slug: >-
  2025-11-06-httpswwwtechpolicypressices-reckless-reliance-on-facial-recognition-puts-us-all-in-danger
tags:
  - politics
  - baselines
  - immigration
  - law and order
title: ICE’s Reckless Reliance on Facial Recognition Puts Us All In Danger
---
<p>Perspective</p>
<figure><img alt=" " data-nimg="1" src="https://cdn.sanity.io/images/3tzzh18d/production/2912a5a41655a980eb7df8ba207a388abf6b5d61-1200x675.png"/><figcaption><a href="https://www.shutterstock.com/image-photo/face-recognition-personal-identification-technologies-street-1783490738">Shutterstock</a></figcaption></figure>
<p>Could errors from an AI surveillance tool cause Immigration and Customs Enforcement (ICE) to grab and detain you? The agency’s use of facial recognition — and alarming new details on its reckless procedures for doing so — make that sci-fi-sounding nightmare an all too real risk for anyone walking down the street.</p>
<p>This year, ICE began <a href="https://www.404media.co/ice-is-using-a-new-facial-recognition-app-to-identify-people-leaked-emails-show/">deploying facial recognition in the field</a> for the first time, a departure from past practices where it was only used in investigatory settings. Use of facial recognition during field operations (rather than in-office) inherently creates risks given the technology’s temperamental and error-prone nature. The accuracy of facial recognition systems can vary significantly based on lighting, angle, distance, camera quality, system settings, and numerous other factors; some algorithms are even less accurate based on individuals’ <a href="https://www.bbc.com/news/technology-50865437">skin color</a>. For this reason, it's imperative that any law enforcement use of facial recognition subjects potential matches to rigorous human review and independent confirmation.</p>
<p>But ICE is taking the opposite approach. According to recent reporting by<em> <a href="https://www.404media.co/ice-and-cbp-agents-are-scanning-peoples-faces-on-the-street-to-verify-citizenship/">404 Media</a></em>, ICE is treating field matches from its facial recognition systems as definitive identifications. Not only is it willing to treat these scans alone as sufficient for an identification, according to House Homeland Security Committee Ranking Member Bennie Thompson (D-MS), ICE has indicated that “an ICE officer may ignore evidence of American citizenship — including a birth certificate — if the [facial recognition] app says the person is an alien.”</p>
<p>This reported use of facial recognition is grossly irresponsible. And it's not just privacy and civil liberties advocates like myself who say this. Refusing to treat matches as the sole basis for law enforcement actions is one of the most basic and commonly agreed upon principles for deploying facial recognition, including by police. According to then <a href="https://www.nyc.gov/site/nypd/news/pr0313/press-release---nypd-facial-recognition-policy?utm_source=chatgpt.com">New York City Police Commissioner Dermot Shea</a>, “A facial recognition match is merely a lead; it is not probable cause.” Miami Assistant Chief of Police Armando Aguilar describes their department’s rule that matches do not constitute probable cause to arrest as its <a href="https://www.judiciary.senate.gov/imo/media/doc/2024-01-24_pm_-_testimony_-_aguilar.pdf">most important policy</a> on facial recognition, and <a href="https://www.bbc.com/news/technology-65057011">states</a>, “We don't make an arrest because an algorithm tells us to.” Philadelphia Police Department <a href="https://www.phillypolice.com/wp-content/uploads/2024/11/D5.32-REV-8-29-23-REDACTED.pdf?utm_source=chatgpt.com">policy states</a>, “Even if the Facial Recognition and Facial Comparison results in a potential Candidate, this is NOT indicative of a positive identification.” <a href="https://pars.lasd.org/Viewer/Manuals/12254/Content/18128?searchQuery=Deadly%20Force&amp;showHistorical=True#!">Los Angeles</a>, <a href="https://www.nytimes.com/2024/06/29/technology/detroit-facial-recognition-false-arrests.html">Detroit</a>, <a href="https://www.orlando.gov/files/sharedassets/public/v/5/documents/opd/policies-and-procedures/police-operations/1147.3-facial-recognition.pdf?utm_source=chatgpt.com">Orlando</a>, and many other police departments similarly bar facial recognition from serving as a definitive identification. Over half a dozen states have enshrined this principle <a href="https://www.techpolicy.press/status-of-state-laws-on-facial-recognition-surveillance-continued-progress-and-smart-innovations/">into law</a>.</p>
<p>Even the Department of Homeland Security’s <a href="https://perma.cc/BTG6-BTQN">own policies</a> prohibit using facial recognition as a definitive identification for enforcement actions such as detainments. Either ICE officials are violating that policy, or the department’s rules on facial recognition have been secretly replaced with new rules that are dangerous and indefensibly lax.</p>
<p>Privacy advocates and police often disagree on how and whether facial recognition should be used (and far too often, police <a href="https://www.washingtonpost.com/business/interactive/2025/police-artificial-intelligence-facial-recognition/?utm_source=chatgpt.com">don’t live up to standards they pledge to adhere to</a>), but this is one area of clear consensus on the responsible way to treat the technology. It should never be the sole basis for an identification resulting in arrests or other law enforcement actions. ICE’s apparent use of the technology cavalierly ignores that consensus.</p>
<p>The harms that will result from this misuse of facial recognition are obvious. If ICE officials ignore universally accepted standards and treat matches as definitive identifications — whereby efforts to otherwise confirm identity and legal status are shrugged off as unnecessary, or even disregarded when they provide contradictory information — <a href="https://www.propublica.org/article/immigration-dhs-american-citizens-arrested-detained-against-will">citizens and lawful residents</a> will inevitably come up as “matches” and be improperly detained.</p>
<p>This irresponsible use of facial recognition paints a stark picture of how dangerous the “<a href="https://www.lawdork.com/p/the-kavanaugh-stop-50-days-later">Kavanaugh stops</a>” authorized by the Supreme Court earlier this year are, and how dubious the reasoning behind them is. In justifying ICE stops based at least in part on racial profiling, Justice Bret Kavanaugh claimed, “If the person is a US citizen or otherwise lawfully in the United States, that individual will be free to go after the brief encounter.” It turns out you can’t rely on your citizenship or legal status to save you — whether you’re grabbed off the street and held in ICE detention could be determined by the whims of erratic AI software.</p>
