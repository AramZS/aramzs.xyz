---
author: Aisvarya Chandrasekar
cover_image: 'https://www.cjr.org/wp-content/uploads/2025/10/AP25295636405516-scaled.jpg'
date: '2025-11-02T02:29:36.639Z'
dateFolder: 2025/11/01
description: >-
  OpenAI’s Atlas and Perplexity’s Comet present a new challenge for media
  companies that want to limit AI access.
isBasedOn: >-
  https://www.cjr.org/analysis/how-ai-browsers-sneak-past-blockers-and-paywalls.php
link: >-
  https://www.cjr.org/analysis/how-ai-browsers-sneak-past-blockers-and-paywalls.php
slug: >-
  2025-11-01-httpswwwcjrorganalysishow-ai-browsers-sneak-past-blockers-and-paywallsphp
tags:
  - ai
  - media
title: How AI Browsers Sneak Past Blockers and Paywalls
---
<figure><img alt="" src="https://www.cjr.org/wp-content/uploads/2025/10/AP25295636405516-scaled.jpg"/><figcaption>Photo Illustration by Nikolas Kokovlis/NurPhoto via AP</figcaption></figure>
<p>Last week, OpenAI released <a href="https://openai.com/index/introducing-chatgpt-atlas/">Atlas</a>, which joins a growing wave of AI browsers, including Perplexity’s <a href="https://www.perplexity.ai/hub/blog/comet-is-now-available-to-everyone-worldwide">Comet</a> and Microsoft’s <a href="https://blogs.windows.com/msedgedev/2025/10/23/meet-copilot-mode-in-edge-your-ai-browser/">Copilot mode</a> in Edge, that aim to transform how people interact with the Web. These AI browsers differ from Chrome or Safari in that they have “agentic capabilities,” or tools designed to execute complex, multistep tasks <a href="https://openai.com/index/introducing-chatgpt-agent/">such as</a> “look at my calendar and brief me for upcoming client meetings based on recent news.”</p>
<p>AI browsers present new problems for media outlets, because agentic systems are making it even more difficult for publishers to know and control how their articles are being used. For instance, when we asked Atlas and Comet to retrieve the full text of a nine-thousand-word subscriber-exclusive <a href="https://www.technologyreview.com/2025/10/16/1125159/ethics-embryo-screening-reproduction-baby/">article</a> in the <em>MIT Technology Review</em>, the browsers were able to do it. When we issued the same prompt in ChatGPT’s and Perplexity’s standard interfaces, both responded that they could not access the article because the <em>Review</em> had blocked the companies’ crawlers.</p>
<figure><a data-slb-active="1" data-slb-asset="1995518961" data-slb-group="116468" data-slb-internal="0" data-src="https://www.cjr.org/wp-content/uploads/2025/10/image-6-scaled.jpg" data-thumb="https://www.cjr.org/wp-content/uploads/2025/10/image-6-scaled.jpg" href="https://www.cjr.org/wp-content/uploads/2025/10/image-6-scaled.jpg"><img alt="" sizes="(max-width: 2560px) 100vw, 2560px" src="https://www.cjr.org/wp-content/uploads/2025/10/image-6-scaled.jpg" srcset="https://www.cjr.org/wp-content/uploads/2025/10/image-6-scaled.jpg 2560w, https://www.cjr.org/wp-content/uploads/2025/10/image-6-800x413.jpg 800w"/></a><figcaption>OpenAI’s Atlas was able to retrieve the full text of a subscriber-exclusive article from the MIT Technology Review.</figcaption></figure>
<p>Atlas and Comet were able to read the article for two reasons. The first is that, to a website, Atlas’s AI agent is indistinguishable from a person using a standard Chrome browser. When automated systems like crawlers and scrapers visit a website, they identify themselves using a digital ID that tells the site what kind of software is making the request and what its purpose is. Publishers can selectively block certain crawlers using the Robots Exclusion Protocol—and indeed many do.</p>
<p>But as TollBit’s most recent <a href="https://tollbit.com/bots/25q2/">State of the Bots</a> report states, “The next wave of AI visitors [are] increasingly looking like humans.” Because AI browsers like Comet and Atlas appear in site logs as normal Chrome sessions, blocking them might also prevent legitimate human users from accessing a site. This makes it much more difficult for publishers to detect, block, or monitor these AI agents.</p>
<p>Furthermore, the <em>MIT Technology Review</em>, like many publishers including <em>National Geographic</em> and the <em>Philadelphia Inquirer</em>, uses a client-side overlay paywall: the text loads on the page but is hidden behind a pop-up that asks a user to subscribe or log in. While this content is invisible to humans, AI agents like Atlas and Comet can still read it. Other outlets like the <em>Wall Street Journal</em> and <em>Bloomberg</em> use server-side paywalls, which don’t send the full text to the browser until a user’s credentials are verified. Once a user is logged in, the AI browser can read and interact with the article on their behalf.</p>
<figure><a data-slb-active="1" data-slb-asset="377004042" data-slb-group="116468" data-slb-internal="0" data-src="https://www.cjr.org/wp-content/uploads/2025/10/Insta-Green-Presentation-1.jpg" data-thumb="https://www.cjr.org/wp-content/uploads/2025/10/Insta-Green-Presentation-1.jpg" href="https://www.cjr.org/wp-content/uploads/2025/10/Insta-Green-Presentation-1.jpg"><img alt="" sizes="(max-width: 1551px) 100vw, 1551px" src="https://www.cjr.org/wp-content/uploads/2025/10/Insta-Green-Presentation-1.jpg" srcset="https://www.cjr.org/wp-content/uploads/2025/10/Insta-Green-Presentation-1.jpg 1551w, https://www.cjr.org/wp-content/uploads/2025/10/Insta-Green-Presentation-1-800x516.jpg 800w"/></a><figcaption>Atlas’s agent was able to reconstruct a blocked PCMag article by collecting information from different sources.</figcaption></figure>
<p>OpenAI <a href="https://openai.com/index/introducing-chatgpt-atlas/">says</a> that, by default, it does not train its large language models on the content users encounter in Atlas unless they opt in to “browser memories.” Pages that have blocked OpenAI’s scraper will still not be used for training, but “ChatGPT will remember key details from content you browse.” As Geoffrey Fowler of the <em>Washington Post</em> <a href="https://www.washingtonpost.com/technology/2025/10/22/chatgpt-atlas-browser/">wrote</a> last week, “the details of what Atlas will or won’t remember get confusing fast.” It remains unclear how much OpenAI is learning from paywalled content that users are unlocking for the agents to read.</p>
<p>We did find that Atlas seems to avoid reading content from media companies that are currently suing OpenAI. (We did not observe the same with Comet.) However, when we prompted Atlas to interact with these publications, it employed various work-arounds to try to satisfy our requests.</p>
<p>For instance, when we prompted Atlas to summarize an article from <em>PCMag</em>, whose parent company Ziff Davis <a href="https://www.reuters.com/business/publisher-ziff-davis-sues-openai-copyright-infringement-2025-04-24/">sued</a> OpenAI for copyright infringement in April, the agent produced a composite summary, drawing on tweets about the article, syndicated versions, citations in other outlets, and related coverage across the Web. Online research expert Henk van Ess first <a href="https://substack.com/sign-in?redirect=%2Fp%2Fhow-ai-bots-quietly-dismantle-paywalls&amp;for_pub=henkvaness&amp;justTrying=true">documented</a> this behavior in July, observing that AI agents can reverse-engineer an article using “digital breadcrumbs.”</p>
<figure><a data-slb-active="1" data-slb-asset="993352043" data-slb-group="116468" data-slb-internal="0" data-src="https://www.cjr.org/wp-content/uploads/2025/10/Insta-Green-Presentation.jpg" data-thumb="https://www.cjr.org/wp-content/uploads/2025/10/Insta-Green-Presentation.jpg" href="https://www.cjr.org/wp-content/uploads/2025/10/Insta-Green-Presentation.jpg"><img alt="" sizes="(max-width: 1704px) 100vw, 1704px" src="https://www.cjr.org/wp-content/uploads/2025/10/Insta-Green-Presentation.jpg" srcset="https://www.cjr.org/wp-content/uploads/2025/10/Insta-Green-Presentation.jpg 1704w, https://www.cjr.org/wp-content/uploads/2025/10/Insta-Green-Presentation-800x440.jpg 800w"/></a><figcaption>Atlas avoids accessing New York Times content, instead generating a summary of related reporting from other outlets.</figcaption></figure>
<p>When we asked Atlas to summarize an article from the <em>New York Times</em>, which is also <a href="https://nytco-assets.nytimes.com/2023/12/NYT_Complaint_Dec2023.pdf">suing</a> OpenAI, it took a different approach. Instead of reconstructing the article, it generated a summary based on reporting from four alternative outlets—<em>The</em> <em>Guardian</em>, the <em>Washington Post</em>, Reuters, and the Associated Press—three of which have licensing agreements with OpenAI.</p>
<p>By reframing the user’s request from a specific article to a general topic, the agent reshapes what that user ultimately reads. Even when a media outlet is able to prevent the agent from accessing its content, it faces a catch-22: the agent simply suggests alternative coverage.</p>
<p>AI browsers are still new, and we don’t know whether they will replace existing ways of searching the Web. But whether or not these tools achieve widespread adoption, one thing is clear: traditional defenses such as paywalls and crawler blockers are no longer enough to prevent AI systems from accessing and repurposing news articles without consent. If agents <em>are</em> the <a href="https://www.niemanlab.org/2024/12/get-ready-for-the-ai-driven-world-of-news/">future</a> of news consumption, publishers will need greater visibility into, and control over, how and when their content is accessed and used.</p>
<p><em>Has America ever needed a media defender more than now? Help us by <a href="https://members.cjr.org/member/?a=interior-hasamerica&amp;utm_source=cjr-org&amp;utm_medium=cjr-interior&amp;utm_campaign=m-land">joining CJR today</a>.</em></p>
