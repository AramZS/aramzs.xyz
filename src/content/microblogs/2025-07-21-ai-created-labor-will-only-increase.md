---
title: AI-created labor will only increase
description: By relying on it to do the actual work the end result creates more problems and work than if AI hadn't been used at all.
growthStage: ephemeral
tags:
  - ai
  - ai-created-labor
featured: false
canonical: https://bsky.app/profile/chronotope.aramzs.xyz/post/3lui3nblv6c2b
date: '2025-07-21T16:00:00.000-04:00'
---

I think AI's [continued failure in legal cases](https://arstechnica.com/tech-policy/2025/07/its-frighteningly-likely-many-us-courts-will-overlook-ai-errors-expert-says/) is a great example of the core adoption challenge. At best it is a tool that can assist experts but by relying on it to do the actual work the end result creates more problems and work than if AI hadn't been used at all.

Law is arguably one of the best situations for LLM assistance. All the source material is open and available. It involves an enormous reference set that can be difficult to search effectively using standard tools. There is a high value customer base....

But most lawyers don't appear to be using a law-trained AI, instead a general one or something built on top of a general one. ChatGPT's illusion of efficacy means companies don't invest in the an explicitly legal model & firms don't seem to be funding one. The result: an unsuited tool adopted badly

The wrong training material. The wrong users. The wrong understanding of what it does. A lack of training on proper use. A bad marketing campaign making bad promises pushing the wrong users to use the wrong tool in the wrong way.

It's crazy because a much more limited LLM with more limited training data, a different output model, and more explicit instructions for use likely could do a lot to help the legal system at a much lower climate footprint. But OpenAI has fucked all expectations of how such a tool should work & look

As a result of OpenAI and others marketing instead of technology doing something useful for sociaty it's made it significantly worse to be involved in the legal system and created more work for everyone involved who now have to check legal documents like they're undergrad homework.

LegalLLM could have been a slam dunk, but because tech bros refused to consider the uniqueness of the use case or handle it with a specific tool instead of a generalized one it will be a brick hanging around the neck of the industry forever. And I mean forever...

Without deploying a separate moderating technology that basically is a separate legal LLM or search engine, ChatGPT will never stop adding fake law cases to documents. I would bet money on it. The tech for a general system will make it forever impossible, no matter how good it gets at other stuff.

Unlike other use cases, the more data that gets added to the model that isn't legal documents the more the way it connects words together will lead it to inaccurate citations. We will have this problem forever or until the consequences get so bad that lawyer are truly afraid to use it.

On the tech side, the 'makes more work' part is apparent more immediately [from the work dealing with crawlers](https://thenewstack.io/how-the-free-software-foundation-battles-the-llm-bots/).
