---
annotationType: Highlight
blockquote: >-
  Overall, the chatbots often failed to retrieve the correct articles.
  Collectively, they provided incorrect answers to more than 60 percent of
  queries. Across different platforms, the level of inaccuracy varied, with
  Perplexity answering 37 percent of the queries incorrectly, while Grok 3 had a
  much higher error rate, answering 94 percent of the queries incorrectly.
cite:
  name: Klaudia Jaźwińska and Aisvarya Chandrasekar
  href: false
createdDate: '2025-03-11 07:49:44+00:00'
date: '2025-03-11T07:49:44.000Z'
handedFrom: Pocket
id: 258abd3eedb1e894c2778311e042bda5
location: null
notes: []
pageNum: null
publish: true
publishDate: '2025-04-18T03:38:44.785Z'
referringUri: false
slug: overall-chatbots-often-failed-to-258ab
sourceSlug: we-compared-eight-ai-search-engines-theyre-all-bad-at-citing-news
sourceTitle: We Compared Eight AI Search Engines. They’re All Bad at Citing News.
tags:
  - media
  - journalism
  - ai
title: >-
  Overall, the chatbots often failed to retrieve the correct articles.... - We
  Compared Eight AI Search Engines. They’re All Bad at Citing News.
type: quote
---

> Overall, the chatbots often failed to retrieve the correct articles. Collectively, they provided incorrect answers to more than 60 percent of queries. Across different platforms, the level of inaccuracy varied, with Perplexity answering 37 percent of the queries incorrectly, while Grok 3 had a much higher error rate, answering 94 percent of the queries incorrectly.
